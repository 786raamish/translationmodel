{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MACHINE TRANSLATION - ASSIGNMENT4\n",
        "### BY: Muhammad Raamish Alam (20k-1326) and Ashar Ansari (20k-1409)\n",
        "\n",
        "### SUBMITTED TO: Sir Raza Abbas\n",
        "### SUBJECT: NLP (DS-5007)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wz7Rb-OS4tFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcTTiQatiSzF",
        "outputId": "aecb14bb-73e2-4f01-8170-8bf9a1f93ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NOTE: (LINK TO THE FILES REQUIRED TO RUN THIS NOTEBOOK below)\n",
        "### https://drive.google.com/drive/folders/167z1uolenvlvA7OESxfKcsUNC-w480WY?usp=share_link"
      ],
      "metadata": {
        "id": "RvXjYvIs2M1_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_SFwF8qYmwO"
      },
      "source": [
        "# FRENCH TO ENGLISH (DEFAULT CODE TAKEN FROM GITHUB):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFzXX1DkYidF"
      },
      "source": [
        "Neural Translation Model in PyTorch\n",
        "by Mac Brennan\n",
        "Translation Model Summary\n",
        "\n",
        "This project will be broken up into several parts as follows:\n",
        "\n",
        "Part 1: Preparing the words\n",
        "\n",
        "Inspecting the Dataset\n",
        "Using Word Embeddings\n",
        "Organizing the Data\n",
        "Part 2: Building the Model\n",
        "\n",
        "Bi-Directional Encoder\n",
        "Building Attention\n",
        "Decoder with Attention\n",
        "Part 3: Training the Model\n",
        "\n",
        "Training Function\n",
        "Training Loop\n",
        "Part 4: Evaluation\n",
        "\n",
        "This project closely follows the PyTorch Sequence to Sequence tutorial, while attempting to go more in depth with both the model implementation and the explanation. Thanks to Sean Robertson and PyTorch for providing such great tutorials.\n",
        "\n",
        "If you are working through this notebook, it is strongly recommended that Jupyter Notebook Extensions is installed so you can turn on collapsable headings. It makes the notebook much easier to navigate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfGfbIPiYlYt"
      },
      "outputs": [],
      "source": [
        "# Before we get started we will load all the packages we will need\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "# Use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Hcm0X8ZCsc",
        "outputId": "b3084d1c-6089-49ce-d11b-803646c18aa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ2BYdNuZFlC"
      },
      "source": [
        "**Inspecting the Dataset**\n",
        "The dataset that will be used is a text file of english sentences and the corresponding french sentences.\n",
        "\n",
        "Each sentence is on a new line. The sentences will be split into a list.\n",
        "\n",
        "**Load the data**\n",
        "The data will be stored in two lists where each item is a sentence. The lists are:\n",
        "\n",
        "english_sentences\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "french_sentences\n",
        "Download the first dataset from the projects' github repo. Place it in the same folder as the notebook or create a data folder in the notebook's folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JWcxsMDZMHG"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/machinetranslation/small_vocab_en', \"r\") as f:\n",
        "    data1 = f.read()\n",
        "with open('/content/drive/MyDrive/machinetranslation/small_vocab_fr', \"r\") as f:\n",
        "    data2 = f.read()\n",
        "    \n",
        "# The data is just in a text file with each sentence on its own line\n",
        "english_sentences = data1.split('\\n')\n",
        "french_sentences = data2.split('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElRJXUKdB7Ma",
        "outputId": "5fd89806-a9cd-4aec-b6ad-dcb95bc3c539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English sentences: 137861 \n",
            "Number of French sentences: 137861 \n",
            "\n",
            "Example/Target pair:\n",
            "\n",
            "  california is usually quiet during march , and it is usually hot in june .\n",
            "  california est généralement calme en mars , et il est généralement chaud en juin .\n"
          ]
        }
      ],
      "source": [
        "print('Number of English sentences:', len(english_sentences), \n",
        "      '\\nNumber of French sentences:', len(french_sentences),'\\n')\n",
        "print('Example/Target pair:\\n')\n",
        "print('  '+english_sentences[2])\n",
        "print('  '+french_sentences[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgcSWfkkaBZP"
      },
      "source": [
        "Number of English sentences: 137861 \n",
        "Number of French sentences: 137861 \n",
        "\n",
        "Example/Target pair:\n",
        "\n",
        "  california is usually quiet during march , and it is usually hot in june .\n",
        "  california est généralement calme en mars , et il est généralement chaud en juin .\n",
        "\n",
        "**Vocabulary**\n",
        "Let's take a closer look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujFNsdpvaEwW",
        "outputId": "72a74171-8d44-4e7f-fd19-91eee8a2ffe6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['california',\n",
              " 'is',\n",
              " 'usually',\n",
              " 'quiet',\n",
              " 'during',\n",
              " 'march',\n",
              " ',',\n",
              " 'and',\n",
              " 'it',\n",
              " 'is',\n",
              " 'usually',\n",
              " 'hot',\n",
              " 'in',\n",
              " 'june',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "english_sentences[2].split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nALiSVuuaIXx",
        "outputId": "93907c93-3b08-41dc-b094-592c13047b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest english sentence in our dataset is: 17\n"
          ]
        }
      ],
      "source": [
        "max_en_length = 0\n",
        "for sentence in english_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_en_length = max(max_en_length, length)\n",
        "print(\"The longest english sentence in our dataset is:\", max_en_length) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLWCiM7saMYe",
        "outputId": "2692cd1c-2291-4a1b-d90a-5ca01356b2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest french sentence in our dataset is: 23\n"
          ]
        }
      ],
      "source": [
        "max_fr_length = 0\n",
        "for sentence in french_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_fr_length = max(max_fr_length, length)\n",
        "print(\"The longest french sentence in our dataset is:\", max_fr_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwfrCTEhaO3W"
      },
      "outputs": [],
      "source": [
        "max_seq_length = max(max_fr_length, max_en_length) + 1\n",
        "seq_length = max_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9caEJYZaRhm"
      },
      "outputs": [],
      "source": [
        "en_word_count = {}\n",
        "fr_word_count = {}\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in en_word_count:\n",
        "            en_word_count[word] +=1\n",
        "        else:\n",
        "            en_word_count[word] = 1\n",
        "            \n",
        "for sentence in french_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in fr_word_count:\n",
        "            fr_word_count[word] +=1\n",
        "        else:\n",
        "            fr_word_count[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch_TLT5RaUJ4"
      },
      "outputs": [],
      "source": [
        "# Add end of sentence token to word count dict\n",
        "en_word_count[''] = len(english_sentences)\n",
        "fr_word_count[''] = len(english_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrR_CtrOaWa7",
        "outputId": "85e00ba4-6ce7-4aff-85b3-a9b20d8ba5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique English words: 228\n",
            "Number of unique French words: 356\n"
          ]
        }
      ],
      "source": [
        "print('Number of unique English words:', len(en_word_count))\n",
        "print('Number of unique French words:', len(fr_word_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-zNota5aZf0"
      },
      "outputs": [],
      "source": [
        "def get_value(items_tuple):\n",
        "    return items_tuple[1]\n",
        "\n",
        "# Sort the word counts to see what words or most/least common\n",
        "sorted_en_words= sorted(en_word_count.items(), key=get_value, reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-xieYRTabnH",
        "outputId": "34f24cbc-4410-419b-8696-b83bd9e7ffb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('is', 205858),\n",
              " (',', 140897),\n",
              " ('', 137861),\n",
              " ('.', 129039),\n",
              " ('in', 75525),\n",
              " ('it', 75137),\n",
              " ('during', 74933),\n",
              " ('the', 67628),\n",
              " ('but', 63987),\n",
              " ('and', 59850)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sorted_en_words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOIdg0q9augm"
      },
      "outputs": [],
      "source": [
        "sorted_fr_words = sorted(fr_word_count.items(), key=get_value, reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AbdW16vauxu",
        "outputId": "513de44c-aeba-4f90-8a12-5770dd434a33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('est', 196809),\n",
              " ('', 137861),\n",
              " ('.', 135619),\n",
              " (',', 123135),\n",
              " ('en', 105768),\n",
              " ('il', 84079),\n",
              " ('les', 65255),\n",
              " ('mais', 63987),\n",
              " ('et', 59851),\n",
              " ('la', 49861)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sorted_fr_words[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0eVrHZIazCS"
      },
      "source": [
        "So the dataset is pretty small, we may want to get a bigger data set, but we'll see how this one does.\n",
        "\n",
        "**Alternate Dataset**\n",
        "Skip this section for now. You can come back and try training on this second dataset later. It is more diverse so it takes longer to train.\n",
        "\n",
        "Download the French-English dataset from here, Although you could train the model on any of the other language pairs. However, you would need different word embeddings or they would need to be trained from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YFsWrzKa1T9"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/machinetranslation/fra.txt', \"r\") as f:\n",
        "    data1 = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psjjTiFBcX8m"
      },
      "outputs": [],
      "source": [
        "pairs = data1.split('\\n')\n",
        "english_sentences = []\n",
        "french_sentences = []\n",
        "for i, pair in enumerate(pairs):\n",
        "    pair_split = pair.split('\\t')\n",
        "    if len(pair_split)!= 2:\n",
        "        continue\n",
        "    english = pair_split[0].lower()\n",
        "    french = pair_split[1].lower()\n",
        "    \n",
        "    # Remove punctuation and limit sentence length\n",
        "    max_sent_length = 10\n",
        "    punctuation_table = english.maketrans({i:None for i in string.punctuation})\n",
        "    english = english.translate(punctuation_table)\n",
        "    french = french.translate(punctuation_table)\n",
        "    if len(english.split()) > max_sent_length or len(french.split()) > max_sent_length:\n",
        "        continue\n",
        "       \n",
        "    english_sentences.append(english) \n",
        "    french_sentences.append(french) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2b85dJAcbVD",
        "outputId": "50a21b7d-f326-4bdd-fcd2-4dba62f7166c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137861 137861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she',\n",
              " 'dislikes',\n",
              " 'strawberries',\n",
              " ',',\n",
              " 'grapefruit',\n",
              " ',',\n",
              " 'and',\n",
              " 'grapes',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "print(len(english_sentences), len(french_sentences))\n",
        "english_sentences[10000].split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF_L39khcyfh",
        "outputId": "f17abc8b-530c-4543-c1f6-c4ef38cc19a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elle',\n",
              " \"n'aime\",\n",
              " 'les',\n",
              " 'fraises',\n",
              " ',',\n",
              " 'le',\n",
              " 'pamplemousse',\n",
              " 'et',\n",
              " 'les',\n",
              " 'raisins',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "french_sentences[10000].split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEgyobWNgW_O",
        "outputId": "ee50ff77-0a5e-411f-fdff-6201d38042e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['paris', 'is', 'sometimes', 'nice', 'during', 'may', ',', 'but', 'it', 'is', 'never', 'mild', 'in', 'summer', '.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['paris',\n",
              " 'est',\n",
              " 'parfois',\n",
              " 'agréable',\n",
              " 'au',\n",
              " 'mois',\n",
              " 'de',\n",
              " 'mai',\n",
              " ',',\n",
              " 'mais',\n",
              " 'il',\n",
              " 'est',\n",
              " 'doux',\n",
              " 'jamais',\n",
              " 'en',\n",
              " 'été',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "print(english_sentences[-100].split())\n",
        "french_sentences[-100].split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz6KxIsKgZUh",
        "outputId": "494bc8b2-814f-4fe7-e045-a9c91b611b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest english sentence in our dataset is: 17\n"
          ]
        }
      ],
      "source": [
        "max_en_length = 0\n",
        "for sentence in english_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_en_length = max(max_en_length, length)\n",
        "print(\"The longest english sentence in our dataset is:\", max_en_length)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP2l7gbvgbws",
        "outputId": "9cbe960f-e3c6-49a9-a866-ff06e5528f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest french sentence in our dataset is: 23\n"
          ]
        }
      ],
      "source": [
        "max_fr_length = 0\n",
        "for sentence in french_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_fr_length = max(max_fr_length, length)\n",
        "print(\"The longest french sentence in our dataset is:\", max_fr_length)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVdFDW7mge6Z"
      },
      "outputs": [],
      "source": [
        "max_seq_length = max(max_fr_length, max_en_length) + 1\n",
        "seq_length = max_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhqF0E8Rghk7"
      },
      "outputs": [],
      "source": [
        "en_word_count = {}\n",
        "fr_word_count = {}\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in en_word_count:\n",
        "            en_word_count[word] +=1\n",
        "        else:\n",
        "            en_word_count[word] = 1\n",
        "            \n",
        "for sentence in french_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in fr_word_count:\n",
        "            fr_word_count[word] +=1\n",
        "        else:\n",
        "            fr_word_count[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgOT5Er_gjiw"
      },
      "outputs": [],
      "source": [
        "en_word_count[''] = len(english_sentences)\n",
        "fr_word_count[''] = len(english_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LATsAuw2glx8",
        "outputId": "eb25ad23-09fa-4c4e-fa75-4cdb1d58d25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique English words: 228\n",
            "Number of unique French words: 356\n"
          ]
        }
      ],
      "source": [
        "print('Number of unique English words:', len(en_word_count))\n",
        "print('Number of unique French words:', len(fr_word_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToTH2fiogsix"
      },
      "outputs": [],
      "source": [
        "fr_word2idx = {k:v+3 for v, k in enumerate(fr_word_count.keys())}\n",
        "en_word2idx = {k:v+3 for v, k in enumerate(en_word_count.keys())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhcTWAqBg0RG"
      },
      "outputs": [],
      "source": [
        "fr_word2idx[''] = 0\n",
        "fr_word2idx[''] = 1\n",
        "fr_word2idx[''] = 2\n",
        "\n",
        "en_word2idx[''] = 0\n",
        "en_word2idx[''] = 1\n",
        "en_word2idx[''] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DxrsCexg1x3",
        "outputId": "0f08e362-312b-4f0f-902b-6b00d31db111"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(fr_word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tnN3I7tvOKV"
      },
      "outputs": [],
      "source": [
        "def get_value(items_tuple):\n",
        "    return items_tuple[1]\n",
        "\n",
        "sorted_en_words= sorted(en_word_count.items(), key=get_value, reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMEyNSUSvP3i",
        "outputId": "f4de52ff-15b9-4ba5-e298-ec5110e5a926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('would', 48),\n",
              " (\"aren't\", 36),\n",
              " ('been', 36),\n",
              " ('weather', 33),\n",
              " ('does', 24),\n",
              " ('has', 24),\n",
              " (\"isn't\", 24),\n",
              " ('am', 24),\n",
              " ('where', 12),\n",
              " ('have', 12)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sorted_en_words[-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNGUWmsxvSIh"
      },
      "source": [
        "**Using Word Embeddings**\n",
        "\n",
        "Here we are building an embedding matrix of pretrained word vectors. The word embeddings used here were downloaded from the fastText repository. These embeddings have 300 dimensions. To start we will add a few token embeddings for our specific case. We want a token to signal the start of the sentence, A token for words that we do not have an embedding for, and a token to pad sentences so all the sentences we use have the same length. This will allow us to train the model on batches of sentences that are different lengths, rather than one at a time.\n",
        "\n",
        "After this step we will have a dictionary and an embedding matrix for each language. The dictionary will map words to an index value in the embedding matrix where its' corresponding embedding vector is stored.\n",
        "\n",
        "**Load Embeddings for the English data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9OVCR_RvU-C",
        "outputId": "58ec4cfd-ce61-4092-c8e0-cf4119fc83e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings load from .npy file\n"
          ]
        }
      ],
      "source": [
        "# The data file containing the embeddings is very large so once we have the embeddings we want\n",
        "# we will save them as a numpy array. This way we can load this much faster then having to re read from\n",
        "# the large embedding file\n",
        "if os.path.exists('/content/drive/MyDrive/machinetranslation/en_words.npy') and os.path.exists('/content/drive/MyDrive/machinetranslation/en_vectors.npy'):\n",
        "    en_words = np.load('/content/drive/MyDrive/machinetranslation/en_words.npy')\n",
        "    en_vectors = np.load('/content/drive/MyDrive/machinetranslation/en_vectors.npy')\n",
        "    print('Embeddings load from .npy file')\n",
        "else:\n",
        "    # make a dict with the top 100,000 words\n",
        "    en_words = ['', # Padding Token\n",
        "                '', # Start of sentence token\n",
        "                ''# Unknown word token\n",
        "               ]\n",
        "\n",
        "    en_vectors = list(np.random.uniform(-0.1, 0.1, (3, 300)))\n",
        "    en_vectors[0] *= 0 # make the padding vector zeros\n",
        "\n",
        "    with open('cc.en.300.vec', \"r\",encoding='utf-8') as f:\n",
        "        f.readline()\n",
        "        for _ in range(100000):\n",
        "            en_vecs = f.readline()\n",
        "            word = en_vecs.split()[0]\n",
        "            vector = np.float32(en_vecs.split()[1:])\n",
        "\n",
        "            # skip lines that don't have 300 dim\n",
        "            if len(vector) != 300:\n",
        "                continue\n",
        "\n",
        "            if word not in en_words:\n",
        "                en_words.append(word)\n",
        "                en_vectors.append(vector)\n",
        "        print(word, vector[:10]) # Last word embedding read from the file\n",
        "        en_words = np.array(en_words)\n",
        "        en_vectors = np.array(en_vectors)\n",
        "    # Save the arrays so we don't have to load the full word embedding file\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/en_words.npy', en_words)\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/en_vectors.npy', en_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WP0nD6y2-jP"
      },
      "outputs": [],
      "source": [
        "en_word2idx = {word:index for index, word in enumerate(en_words)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glWVPO5sJpky",
        "outputId": "3b8a0795-d761-4cb3-b430-bd325d4802ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index for word hemophilia: 95160 \n",
            "vector for word hemophilia:\n",
            " [ 0.0937 -0.0607 -0.0306  0.0111  0.0004 -0.0865  0.0584 -0.0324 -0.0312\n",
            "  0.0476]\n"
          ]
        }
      ],
      "source": [
        "hemophilia_idx = en_word2idx['hemophilia']\n",
        "print('index for word hemophilia:', hemophilia_idx, \n",
        "      '\\nvector for word hemophilia:\\n',en_vectors[hemophilia_idx][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfXbwF1lJtx4"
      },
      "source": [
        "The word embedding for hemophilia matches the one read from the file, so it looks like everything worked properly.\n",
        "\n",
        "Load Embeddings for the Frech data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkR6N0Y5JwR5",
        "outputId": "0705fdac-86c9-45a0-9347-84c31f6c5255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings load from .npy file\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists('/content/drive/MyDrive/machinetranslation/fr_words.npy') and os.path.exists('/content/drive/MyDrive/machinetranslation/fr_vectors.npy'):\n",
        "    fr_words = np.load('/content/drive/MyDrive/machinetranslation/fr_words.npy')\n",
        "    fr_vectors = np.load('/content/drive/MyDrive/machinetranslation/fr_vectors.npy')\n",
        "    print('Embeddings load from .npy file')\n",
        "else:\n",
        "    # make a dict with the top 100,000 words\n",
        "    fr_words = ['',\n",
        "                '',\n",
        "                '']\n",
        "\n",
        "    fr_vectors = list(np.random.uniform(-0.1, 0.1, (3, 300)))\n",
        "    fr_vectors[0] = np.zeros(300) # make the padding vector zeros\n",
        "\n",
        "    with open('data/wiki.fr.vec', \"r\") as f:\n",
        "        f.readline()\n",
        "        for _ in range(100000):\n",
        "            fr_vecs = f.readline()\n",
        "            word = fr_vecs.split()[0]\n",
        "            try:\n",
        "                vector = np.float32(fr_vecs.split()[1:])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "             # skip lines that don't have 300 dim\n",
        "            if len(vector) != 300:\n",
        "                continue\n",
        "\n",
        "            if word not in fr_words:\n",
        "                fr_words.append(word)\n",
        "                fr_vectors.append(vector)\n",
        "        print(word, vector[:10])\n",
        "        fr_words = np.array(fr_words)\n",
        "        fr_vectors = np.array(fr_vectors)\n",
        "    # Save the arrays so we don't have to load the full word embedding file\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/fr_words.npy', fr_words)\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/fr_vectors.npy', fr_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVgvFWhdKN1S"
      },
      "outputs": [],
      "source": [
        "fr_word2idx = {word:index for index, word in enumerate(fr_words)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJvubm_qKQ6p",
        "outputId": "f35ffe3b-3ab0-405e-968c-83c6df9c747f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index for word chabeuil: 658 \n",
            "vector for word chabeuil:\n",
            " [ 0.044  -0.0238  0.0517 -0.0402 -0.0736  0.0118  0.0141 -0.0279  0.0613\n",
            " -0.0012]\n"
          ]
        }
      ],
      "source": [
        "chabeuil_idx = fr_word2idx['parfois']\n",
        "print('index for word chabeuil:', chabeuil_idx, \n",
        "      '\\nvector for word chabeuil:\\n',fr_vectors[chabeuil_idx][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9GPaMmfKTcK",
        "outputId": "4753dafb-62ea-41b9-c729-be03eb09c984"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "658"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "fr_word2idx[\"parfois\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAi4mhH_KWT7"
      },
      "source": [
        "The word embedding for chabeuil matches as well so everything worked correctly for the french vocab.\n",
        "\n",
        "Ok, so we have all the pieces needed to take words and convert them into word embeddings. These word embeddings already have a lot of useful information about how words relate since we loaded the pre-trained word embeddings. Now we can build the translation model with the embedding matrices built in.\n",
        "\n",
        "Setting up PyTorch Dataset and Dataloader\n",
        "Rather than organizing all the data from a file and storing it in a list or some other data structure, PyTorch allows us to create a dataset object. To get an example from a dataset we just index the dataset object like we would a list. However, all our processing can be contained in the objects initialization or indexing process.\n",
        "\n",
        "This will also make training easier when we want to iterate through batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYSM0pGfKXLp"
      },
      "outputs": [],
      "source": [
        "class French2EnglishDataset(Dataset):\n",
        "    '''\n",
        "        French and associated English sentences.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, fr_sentences, en_sentences, fr_word2idx, en_word2idx, seq_length):\n",
        "        self.fr_sentences = fr_sentences\n",
        "        self.en_sentences = en_sentences\n",
        "        self.fr_word2idx = fr_word2idx\n",
        "        self.en_word2idx = en_word2idx\n",
        "        self.seq_length = seq_length\n",
        "        self.unk_en = set()\n",
        "        self.unk_fr = set()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(french_sentences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "            Returns a pair of tensors containing word indices\n",
        "            for the specified sentence pair in the dataset.\n",
        "        '''\n",
        "        \n",
        "        # init torch tensors, note that 0 is the padding index\n",
        "        french_tensor = torch.zeros(self.seq_length, dtype=torch.long)\n",
        "        english_tensor = torch.zeros(self.seq_length, dtype=torch.long)\n",
        "        \n",
        "        # Get sentence pair\n",
        "        french_sentence = self.fr_sentences[idx].split()\n",
        "        english_sentence = self.en_sentences[idx].split()\n",
        "        \n",
        "        # Add  tags\n",
        "        french_sentence.append('')\n",
        "        english_sentence.append('')\n",
        "        \n",
        "        # Load word indices\n",
        "        for i, word in enumerate(french_sentence):\n",
        "            if word in fr_word2idx and fr_word_count[word] > 5:\n",
        "                french_tensor[i] = fr_word2idx[word]\n",
        "            else:\n",
        "                french_tensor[i] = fr_word2idx['']\n",
        "                self.unk_fr.add(word)\n",
        "        \n",
        "        for i, word in enumerate(english_sentence):\n",
        "            if word in en_word2idx and en_word_count[word] > 5:\n",
        "                english_tensor[i] = en_word2idx[word]\n",
        "            else:\n",
        "                english_tensor[i] = en_word2idx['']\n",
        "                self.unk_en.add(word)\n",
        "            \n",
        "        sample = {'french_tensor': french_tensor, 'french_sentence': self.fr_sentences[idx],\n",
        "                  'english_tensor': english_tensor, 'english_sentence': self.en_sentences[idx]}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRZ9oIYLKchZ"
      },
      "outputs": [],
      "source": [
        "french_english_dataset = French2EnglishDataset(french_sentences,\n",
        "                                               english_sentences,\n",
        "                                               fr_word2idx,\n",
        "                                               en_word2idx,\n",
        "                                               seq_length = seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3XY-1Dt0Ior",
        "outputId": "88689f3a-14f3-4d9b-d936-1b0a7d38e475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.French2EnglishDataset at 0x7f1f5387dbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "french_english_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A34aoYPeKfSR"
      },
      "source": [
        "Example output of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovNzaTS2Kf5h"
      },
      "outputs": [],
      "source": [
        "test_sample = french_english_dataset[-10] # get 10th to last item in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmpy3ltqKicy",
        "outputId": "de2e0245-cf8e-414a-faaa-5456c9facf1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input example:\n",
            "Sentence: californie est jamais agréable en octobre , et il est parfois pluvieux à l' automne .\n",
            "Tensor: tensor([    2,    20,   350,   727,    13,   314,     3,     8,    38,    20,\n",
            "          658, 29282,    10,    22,  3100,     5,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "\n",
            "Target example:\n",
            "Sentence: california is never nice during october , and it is sometimes rainy in autumn .\n",
            "Tensor: tensor([27779,    12,   239,   502,   228, 43967,     3,     6,    22,    12,\n",
            "          959, 12024,    11,  9059,     5,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "print('Input example:')\n",
        "print('Sentence:', test_sample['french_sentence'])\n",
        "print('Tensor:', test_sample['french_tensor'])\n",
        "\n",
        "print('\\nTarget example:')\n",
        "print('Sentence:', test_sample['english_sentence'])\n",
        "print('Tensor:', test_sample['english_tensor'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1BtnQgKmMr",
        "outputId": "acfb7b71-19c4-41ad-b4bc-fe3396f9f106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Check that both tensors end with the end of sentence token\n",
        "print(fr_word2idx[''])\n",
        "en_word2idx['']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym1O5zniKowy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fb9a09-98e9-4e5e-f157-0077816fc79d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Build dataloader to check how the batching works\n",
        "dataloader = DataLoader(french_english_dataset, batch_size=5,\n",
        "                        shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7dEyNIVKqz2",
        "outputId": "26d6193a-5bcc-49f7-b4af-1a888f2ec163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([5, 24]) torch.Size([5, 24])\n",
            "1 torch.Size([5, 24]) torch.Size([5, 24])\n",
            "2 torch.Size([5, 24]) torch.Size([5, 24])\n",
            "3 torch.Size([5, 24]) torch.Size([5, 24])\n"
          ]
        }
      ],
      "source": [
        "# Prints out 10 batches from the dataloader\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['french_tensor'].shape,\n",
        "          sample_batched['english_tensor'].shape)\n",
        "    if i_batch == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLNZShERKu95",
        "outputId": "baf50dd3-11e8-4876-84cd-f220cfb18eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Sentence: votre fruit préféré est l'orange , mais leur favori est la fraise .\n",
            "English Sentence: your favorite fruit is the orange , but their favorite is the strawberry . \n",
            "\n",
            "French Sentence: paris est généralement enneigée en hiver , et il est parfois beau en août .\n",
            "English Sentence: paris is usually snowy during winter , and it is sometimes beautiful in august . \n",
            "\n",
            "French Sentence: nos fruits le plus aimé est la mangue , mais votre plus aimé est la fraise .\n",
            "English Sentence: our most loved fruit is the mango , but your most loved is the strawberry . \n",
            "\n",
            "French Sentence: la chaux est son fruit moins aimé , mais la fraise est mon moins aimé.\n",
            "English Sentence: the lime is his least liked fruit , but the strawberry is my least liked . \n",
            "\n",
            "French Sentence: la france est jamais agréable en mars , et il est généralement calme en octobre .\n",
            "English Sentence: france is never nice during march , and it is usually quiet in october . \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in dataloader:\n",
        "    batch = i\n",
        "    break\n",
        "\n",
        "for i in range(5):\n",
        "    print('French Sentence:', batch['french_sentence'][i])\n",
        "    print('English Sentence:', batch['english_sentence'][i],'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-pnMsZjKy5i"
      },
      "source": [
        "Part 2: Building the Model\n",
        "Bi-Directional Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNwns8GmK1Ey"
      },
      "outputs": [],
      "source": [
        "class EncoderBiLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, pretrained_embeddings):\n",
        "        super(EncoderBiLSTM, self).__init__()\n",
        "        \n",
        "        # Model Parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.vocab_size = pretrained_embeddings.shape[0]\n",
        "        self.num_layers = 2\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0\n",
        "        self.bidirectional = True\n",
        "        \n",
        "        \n",
        "        # Construct the layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        \n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings)) #Load the pretrained embeddings\n",
        "        self.embedding.weight.requires_grad = False #Freeze embedding layer\n",
        "        \n",
        "        self.lstm = nn.LSTM(self.embedding_dim,\n",
        "                            self.hidden_size,\n",
        "                            self.num_layers,\n",
        "                            batch_first = True,\n",
        "                            dropout=self.dropout,\n",
        "                            bidirectional=self.bidirectional)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in LSTM to the Identity matrix\n",
        "        # This improves training and prevents exploding gradients\n",
        "        # PyTorch LSTM has the 4 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.hidden_size)\n",
        "        self.lstm.weight_hh_l0.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l0_reverse.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1_reverse.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = self.lstm(embedded, hidden)\n",
        "        return output\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        \n",
        "        hidden_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                   batch_size,\n",
        "                                   self.hidden_size, \n",
        "                                   device=device)\n",
        "        \n",
        "        cell_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                 batch_size,\n",
        "                                 self.hidden_size, \n",
        "                                 device=device)\n",
        "        \n",
        "        return (hidden_state, cell_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZlLHlAWK5GC"
      },
      "outputs": [],
      "source": [
        "class EncoderBiGRU(nn.Module):\n",
        "    def __init__(self, hidden_size, pretrained_embeddings):\n",
        "        super(EncoderBiGRU, self).__init__()\n",
        "        \n",
        "        # Model parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.vocab_size = pretrained_embeddings.shape[0]\n",
        "        self.num_layers = 2\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0\n",
        "        self.bidirectional = True\n",
        "        \n",
        "        \n",
        "        # Construct the layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.gru = nn.GRU(self.embedding_dim,\n",
        "                            self.hidden_size,\n",
        "                            self.num_layers,\n",
        "                            batch_first = True,\n",
        "                            dropout=self.dropout,\n",
        "                            bidirectional=self.bidirectional)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in GRU to the Identity matrix\n",
        "        # PyTorch GRU has 3 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.hidden_size)\n",
        "        self.gru.weight_hh_l0.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l0_reverse.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1_reverse.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = self.gru(embedded, hidden)\n",
        "        return output\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        \n",
        "        hidden_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                   batch_size,\n",
        "                                   self.hidden_size, \n",
        "                                   device=device)\n",
        "        \n",
        "        return hidden_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMDf9MbSK9La"
      },
      "source": [
        "Testing the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SomUYEYJK9sK",
        "outputId": "2b63ed5f-f7f8-425a-ef14-000d7a405f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final output of the BiLSTM Encoder on our test input is: \n",
            "\n",
            " torch.Size([1, 3, 10])\n",
            "\n",
            "\n",
            "Encoder output tensor: \n",
            "\n",
            " tensor([[[ 0.0599, -0.1044,  0.0657,  0.0311, -0.2248,  0.0563, -0.2278,\n",
            "           0.1971, -0.0417, -0.1968],\n",
            "         [ 0.1167, -0.1134,  0.0629,  0.1260, -0.2703,  0.0198, -0.2375,\n",
            "           0.1154, -0.0542, -0.1961],\n",
            "         [ 0.1543, -0.1325,  0.0824,  0.1933, -0.2979, -0.0028, -0.1934,\n",
            "           0.0562, -0.0525, -0.1150]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Test the encoder on a sample input, input tensor has dimensions (batch_size, seq_length)\n",
        "# all the variable have test_ in front of them so they don't reassign variables needed later on with the real models\n",
        "\n",
        "test_batch_size = 1\n",
        "test_seq_length = 3\n",
        "test_hidden_size = 5\n",
        "test_encoder = EncoderBiLSTM(test_hidden_size, fr_vectors).to(device)\n",
        "test_hidden = test_encoder.initHidden(test_batch_size)\n",
        "\n",
        "# Create an input tensor of random indices\n",
        "test_inputs = torch.randint(0, 50, (test_batch_size, test_seq_length), dtype=torch.long, device=device)\n",
        "\n",
        "test_encoder_output, test_encoder_hidden = test_encoder.forward(test_inputs, test_hidden)\n",
        "\n",
        "print(\"The final output of the BiLSTM Encoder on our test input is: \\n\\n\", test_encoder_output.shape)\n",
        "\n",
        "print('\\n\\nEncoder output tensor: \\n\\n', test_encoder_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2as94pfLCbR",
        "outputId": "56fd71a4-664e-4846-d94d-e05db90c770a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.0571, -0.1702,  0.1533, -0.0264, -0.3548]],\n",
              " \n",
              "         [[ 0.4842,  0.0035, -0.1056, -0.1594,  0.5656]],\n",
              " \n",
              "         [[ 0.1543, -0.1325,  0.0824,  0.1933, -0.2979]],\n",
              " \n",
              "         [[ 0.0563, -0.2278,  0.1971, -0.0417, -0.1968]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>),\n",
              " tensor([[[-0.1447, -0.7790,  0.3262, -0.0550, -0.6853]],\n",
              " \n",
              "         [[ 0.6348,  0.0069, -0.1743, -0.6984,  0.9001]],\n",
              " \n",
              "         [[ 0.3526, -0.2785,  0.1612,  0.4309, -0.7605]],\n",
              " \n",
              "         [[ 0.0966, -0.4072,  0.5151, -0.0974, -0.5175]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "test_encoder_hidden# Tuple where first item is the hidden states, second item is the cell states.\n",
        "\n",
        "# The lstm has 2 layers, each layer has a forward and backward pass giving 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSCIlNkELGNB",
        "outputId": "2e2e8ff8-41e3-4576-d2e5-147bb9b80801"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0571, -0.1702,  0.1533, -0.0264, -0.3548]],\n",
              "\n",
              "        [[ 0.1543, -0.1325,  0.0824,  0.1933, -0.2979]]], device='cuda:0',\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "test_encoder_hidden[0][::2] # Hidden states from forward pass for both lstm layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlyVRYSfLJu6"
      },
      "outputs": [],
      "source": [
        "test_encoder_gru = EncoderBiGRU(test_hidden_size, fr_vectors).to(device)\n",
        "test_hidden = test_encoder_gru.initHidden(test_batch_size)\n",
        "o,h = test_encoder_gru(test_inputs, test_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXDELlgMLLGH",
        "outputId": "6fdf8aa5-c65e-4c73-df79-f3f0cb28efa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0208, -0.2721, -0.1884,  0.3554, -0.2360,  0.3337, -0.8175,\n",
              "          -0.5709, -0.1416,  0.3853],\n",
              "         [ 0.0621, -0.3112, -0.1262,  0.5191, -0.3053,  0.3391, -0.6659,\n",
              "          -0.4525, -0.1236,  0.2777],\n",
              "         [ 0.1131, -0.2446, -0.0146,  0.5367, -0.4151,  0.2985, -0.3940,\n",
              "          -0.2399, -0.0561,  0.1428]]], device='cuda:0',\n",
              "       grad_fn=<CudnnRnnBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFWY8drCLN36",
        "outputId": "98102138-cbae-4ea0-b5f7-32f4e2e688bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.5496, -0.8217,  0.1444,  0.1502,  0.2609]],\n",
            "\n",
            "        [[-0.0076,  0.5358,  0.6264, -0.1254, -0.1857]],\n",
            "\n",
            "        [[ 0.1131, -0.2446, -0.0146,  0.5367, -0.4151]],\n",
            "\n",
            "        [[ 0.3337, -0.8175, -0.5709, -0.1416,  0.3853]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0076,  0.5358,  0.6264, -0.1254, -0.1857]],\n",
              "\n",
              "        [[ 0.3337, -0.8175, -0.5709, -0.1416,  0.3853]]], device='cuda:0',\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "print(h)\n",
        "h[1::2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BvktMiiLXS5"
      },
      "source": [
        "Attention\n",
        "Let's take a moment test how attention is being modeled. Weighted sum of sequence items from encoder output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sidykUiJLY0t",
        "outputId": "da2eedcd-65b5-42ae-e190-cbb2f66b7d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:\n",
            " tensor([[[1., 0., 0.]]], device='cuda:0')\n",
            "\n",
            "First sequence item in Encoder output: \n",
            " tensor([[ 0.0599, -0.1044,  0.0657,  0.0311, -0.2248,  0.0563, -0.2278,  0.1971,\n",
            "         -0.0417, -0.1968]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "\n",
            "Encoder Output after attention is applied: \n",
            " tensor([ 0.0599, -0.1044,  0.0657,  0.0311, -0.2248,  0.0563, -0.2278,  0.1971,\n",
            "        -0.0417, -0.1968], device='cuda:0', grad_fn=<SqueezeBackward2>)\n",
            "\n",
            " torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# Initialize attention weights to one, note the dimensions\n",
        "attn_weights = torch.ones((test_batch_size, test_seq_length),device=device)\n",
        "\n",
        "# Set all weights except the weights associated with the first sequence item equal to zero\n",
        "# This would represent full attention on the first word in the sequence\n",
        "attn_weights[:, 1:] = 0\n",
        "\n",
        "attn_weights.unsqueeze_(1) # Add dimension for batch matrix multiplication\n",
        "\n",
        "# BMM(Batch Matrix Multiply) muliplies the [1 x seq_length] matrix by the [seq_length x hidden_size] matrix for\n",
        "# each batch. This produces a single vector(for each batch) of length(encoder_hidden_size) that is the weighted\n",
        "# sum of the encoder hidden vectors for each item in the sequence.\n",
        "attn_applied = torch.bmm(attn_weights, test_encoder_output)\n",
        "attn_applied.squeeze_() # Remove extra dimension\n",
        "\n",
        "print('Attention weights:\\n', attn_weights)\n",
        "print('\\nFirst sequence item in Encoder output: \\n', test_encoder_output[:,0,:])\n",
        "print('\\nEncoder Output after attention is applied: \\n', attn_applied)\n",
        "print('\\n', attn_applied.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb6-QMuwLeSa"
      },
      "source": [
        "Decoder with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U8XvoGrLezm"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderLSTM(nn.Module):\n",
        "    def __init__(self, decoder_hidden_size, pretrained_embeddings, seq_length):\n",
        "        super(AttnDecoderLSTM, self).__init__()\n",
        "        # Embedding parameters\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.output_vocab_size = pretrained_embeddings.shape[0]\n",
        "        \n",
        "        # LSTM parameters\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.num_layers = 2 # Potentially add more layers to LSTM later\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0 # Potentially add dropout later\n",
        "        \n",
        "        # Attention parameters\n",
        "        self.seq_length = seq_length\n",
        "        self.encoder_hidden_dim = 2*decoder_hidden_size\n",
        "        \n",
        "        # Construct embedding layer for output language\n",
        "        self.embedding = nn.Embedding(self.output_vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False # we don't want to train the embedding weights\n",
        "        \n",
        "        # Construct layer that calculates attentional weights\n",
        "        self.attn = nn.Linear((self.decoder_hidden_size + self.embedding_dim), self.seq_length)\n",
        "        \n",
        "        # Construct layer that compresses the combined matrix of the input embeddings\n",
        "        # and the encoder inputs after attention has been applied\n",
        "        self.attn_with_input = nn.Linear(self.embedding_dim + self.encoder_hidden_dim, self.embedding_dim)\n",
        "        \n",
        "        # LSTM for Decoder\n",
        "        self.lstm = nn.LSTM(self.embedding_dim,\n",
        "                            self.decoder_hidden_size,\n",
        "                            self.num_layers,\n",
        "                            dropout=self.dropout)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in LSTM to the Identity matrix\n",
        "        # PyTorch LSTM has 4 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.decoder_hidden_size)\n",
        "        self.lstm.weight_hh_l0.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        \n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.decoder_hidden_size, self.output_vocab_size)\n",
        "    \n",
        "    def forward(self, input, hidden, encoder_output):\n",
        "        # Input word indices, should have dim(1, batch_size), output will be (1, batch_size, embedding_dim)\n",
        "        embedded = self.embedding(input)\n",
        "        \n",
        "        # Calculate Attention weights\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((hidden[0][1], embedded[0]), 1)), dim=1)\n",
        "        attn_weights = attn_weights.unsqueeze(1) # Add dimension for batch matrix multiplication\n",
        "        \n",
        "        # Apply Attention weights\n",
        "        attn_applied = torch.bmm(attn_weights, encoder_output)\n",
        "        attn_applied = attn_applied.squeeze(1) # Remove extra dimension, dim are now (batch_size, encoder_hidden_size)\n",
        "        \n",
        "        # Prepare LSTM input tensor\n",
        "        attn_combined = torch.cat((embedded[0], attn_applied), 1) # Combine embedding input and attn_applied,\n",
        "        lstm_input = F.relu(self.attn_with_input(attn_combined)) # pass through fully connected with ReLU\n",
        "        lstm_input = lstm_input.unsqueeze(0) # Add seq dimension so tensor has expected dimensions for lstm\n",
        "        \n",
        "        output, hidden = self.lstm(lstm_input, hidden) # Output dim = (1, batch_size, decoder_hidden_size)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1) # softmax over all words in vocab\n",
        "        \n",
        "        \n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDQCj46-LjJa"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderGRU(nn.Module):\n",
        "    def __init__(self, decoder_hidden_size, pretrained_embeddings, seq_length):\n",
        "        super(AttnDecoderGRU, self).__init__()\n",
        "        # Embedding parameters\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.output_vocab_size = pretrained_embeddings.shape[0]\n",
        "        \n",
        "        # GRU parameters\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.num_layers = 2 # Potentially add more layers to LSTM later\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0 # Potentially add dropout later\n",
        "        \n",
        "        # Attention parameters\n",
        "        self.seq_length = seq_length\n",
        "        self.encoder_hidden_dim = 2*decoder_hidden_size\n",
        "        \n",
        "        # Construct embedding layer for output language\n",
        "        self.embedding = nn.Embedding(self.output_vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False # we don't want to train the embedding weights\n",
        "        \n",
        "        # Construct layer that calculates attentional weights\n",
        "        self.attn = nn.Linear(self.decoder_hidden_size + self.embedding_dim, self.seq_length)\n",
        "        \n",
        "        # Construct layer that compresses the combined matrix of the input embeddings\n",
        "        # and the encoder inputs after attention has been applied\n",
        "        self.attn_with_input = nn.Linear(self.embedding_dim + self.encoder_hidden_dim, self.embedding_dim)\n",
        "        \n",
        "        # gru for Decoder\n",
        "        self.gru = nn.GRU(self.embedding_dim,\n",
        "                            self.decoder_hidden_size,\n",
        "                            self.num_layers,\n",
        "                            dropout=self.dropout)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in GRU to the Identity matrix\n",
        "        # PyTorch GRU has 3 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.decoder_hidden_size)\n",
        "        self.gru.weight_hh_l0.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        \n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.decoder_hidden_size, self.output_vocab_size)\n",
        "    \n",
        "    def forward(self, input, hidden, encoder_output):\n",
        "        # Input word indices, should have dim(1, batch_size), output will be (1, batch_size, embedding_dim)\n",
        "        embedded = self.embedding(input)\n",
        "        \n",
        "        # Calculate Attention weights\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((hidden[0], embedded[0]), 1)), dim=1)\n",
        "        attn_weights = attn_weights.unsqueeze(1) # Add dimension for batch matrix multiplication\n",
        "        \n",
        "        # Apply Attention weights\n",
        "        attn_applied = torch.bmm(attn_weights, encoder_output)\n",
        "        attn_applied = attn_applied.squeeze(1) # Remove extra dimension, dim are now (batch_size, encoder_hidden_size)\n",
        "        \n",
        "        # Prepare GRU input tensor\n",
        "\n",
        "        attn_combined = torch.cat((embedded[0], attn_applied), 1) # Combine embedding input and attn_applied,\n",
        "        gru_input = F.relu(self.attn_with_input(attn_combined)) # pass through fully connected with ReLU\n",
        "        gru_input = gru_input.unsqueeze(0) # Add seq dimension so tensor has expected dimensions for lstm\n",
        "        \n",
        "        output, hidden = self.gru(gru_input, hidden) # Output dim = (1, batch_size, decoder_hidden_size)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1) # softmax over all words in vocab\n",
        "        \n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piQ6HWqELnui"
      },
      "source": [
        "Testing the Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g472jSqpLoWS"
      },
      "outputs": [],
      "source": [
        "# Test the decoder on sample inputs to check that the dimensions of everything is correct\n",
        "test_decoder_hidden_size = 5\n",
        "\n",
        "test_decoder = AttnDecoderLSTM(test_decoder_hidden_size, en_vectors, test_seq_length).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OanOSnnyLsRK"
      },
      "outputs": [],
      "source": [
        "input_idx = torch.tensor([fr_word2idx['']]*test_batch_size, dtype=torch.long, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE0kRX6pLuHJ",
        "outputId": "d1a26df9-2fbd-4256-80dc-83f762b97bd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "input_idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3j6-Hx_LwOC"
      },
      "outputs": [],
      "source": [
        "input_idx = input_idx.unsqueeze_(0)\n",
        "test_decoder_hidden = (test_encoder_hidden[0][1::2].contiguous(), test_encoder_hidden[1][1::2].contiguous())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQx0zsbaLydy",
        "outputId": "1a0dbbc3-59f5-4a4e-e0f3-9818512ee164"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "input_idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p97rcU9L04B",
        "outputId": "520d7a11-1001-468f-9b5d-96874fa43f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100003])\n"
          ]
        }
      ],
      "source": [
        "output, hidden, attention = test_decoder.forward(input_idx, test_decoder_hidden, test_encoder_output)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCLXEQF1L3Y6",
        "outputId": "b754f515-52b7-4bfa-94fb-bdbf14706f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "test_decoder_hidden[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gm5EM1YL5fJ"
      },
      "source": [
        "Part 3: Training the Model\n",
        "Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VDEPVOyL6R5"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder,\n",
        "          encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \n",
        "    # Initialize encoder hidden state\n",
        "    encoder_hidden = encoder.initHidden(input_tensor.shape[0])\n",
        "    \n",
        "    # clear the gradients in the optimizers\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    # run forward pass through encoder on entire sequence\n",
        "    encoder_output, encoder_hidden = encoder.forward(input_tensor, encoder_hidden)\n",
        "    \n",
        "    # Initialize decoder input(Start of Sentence tag) and hidden state from encoder\n",
        "    decoder_input =  torch.tensor([en_word2idx['']]*input_tensor.shape[0], dtype=torch.long, device=device).unsqueeze(0)\n",
        "    \n",
        "    # Use correct initial hidden state dimensions depending on type of RNN\n",
        "    try:\n",
        "        encoder.lstm\n",
        "        decoder_hidden = (encoder_hidden[0][1::2].contiguous(), encoder_hidden[1][1::2].contiguous())\n",
        "    except AttributeError:\n",
        "        decoder_hidden = encoder_hidden[1::2].contiguous()\n",
        "    \n",
        "    # Initialize loss\n",
        "    loss = 0\n",
        "    \n",
        "    # Implement teacher forcing\n",
        "    use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Step through target output sequence\n",
        "        for di in range(seq_length):\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "            \n",
        "            # Feed target as input to next item in the sequence\n",
        "            decoder_input = target_tensor[di].unsqueeze(0)\n",
        "            loss += criterion(output, target_tensor[di])\n",
        "    else:\n",
        "        # Step through target output sequence\n",
        "        for di in range(seq_length):\n",
        "            \n",
        "            # Forward pass through decoder\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "            \n",
        "            # Feed output as input to next item in the sequence\n",
        "            decoder_input = output.topk(1)[1].view(1,-1).detach()\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss += criterion(output, target_tensor[di])\n",
        "    \n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Clip the gradients\n",
        "    nn.utils.clip_grad_norm_(encoder.parameters(), 25)\n",
        "    nn.utils.clip_grad_norm_(decoder.parameters(), 25)\n",
        "    \n",
        "    # Update the weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqtE7ashMNVN"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k16IsRwjMOhE"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, dataloader, epochs, print_every_n_batches=100, learning_rate=0.01):\n",
        "    \n",
        "    # keep track of losses\n",
        "    plot_losses = []\n",
        "\n",
        "    # Initialize Encoder Optimizer\n",
        "    encoder_parameters = filter(lambda p: p.requires_grad, encoder.parameters())\n",
        "    encoder_optimizer = optim.Adam(encoder_parameters, lr=learning_rate)\n",
        "    \n",
        "    # Initialize Decoder Optimizer\n",
        "    decoder_parameters = filter(lambda p: p.requires_grad, decoder.parameters())\n",
        "    decoder_optimizer = optim.Adam(decoder_parameters, lr=learning_rate)\n",
        "\n",
        "    # Specify loss function, ignore the  token index so it does not contribute to loss.\n",
        "    criterion = nn.NLLLoss(ignore_index=0)\n",
        "    \n",
        "    # Cycle through epochs\n",
        "    for epoch in range(epochs):\n",
        "        loss_avg = 0\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "        # Cycle through batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            \n",
        "            input_tensor = batch['french_tensor'].to(device)\n",
        "            target_tensor = batch['english_tensor'].transpose(1,0).to(device)\n",
        "            \n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder, decoder,\n",
        "                         encoder_optimizer, decoder_optimizer, criterion)\n",
        "            \n",
        "            loss_avg += loss\n",
        "            if i % print_every_n_batches == 0 and i != 0:\n",
        "                loss_avg /= print_every_n_batches\n",
        "                print(f'After {i} batches, average loss/{print_every_n_batches} batches: {loss_avg}')\n",
        "                plot_losses.append(loss)\n",
        "                loss_avg = 0\n",
        "    return plot_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upc4o50MMSJy"
      },
      "source": [
        "Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vcHzBdvMTjS"
      },
      "outputs": [],
      "source": [
        "# Set hyperparameters and construct dataloader\n",
        "hidden_size = 256\n",
        "batch_size = 16\n",
        "dataloader = DataLoader(french_english_dataset, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=4) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9o4AMfEMWxy"
      },
      "outputs": [],
      "source": [
        "# Construct encoder and decoder instances\n",
        "encoder_lstm = EncoderBiLSTM(hidden_size, fr_vectors).to(device)\n",
        "decoder_lstm = AttnDecoderLSTM(hidden_size, en_vectors, seq_length).to(device)\n",
        "\n",
        "encoder_gru = EncoderBiGRU(hidden_size, fr_vectors).to(device)\n",
        "decoder_gru = AttnDecoderGRU(hidden_size, en_vectors, seq_length).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ziq6Zo-RMaA6"
      },
      "outputs": [],
      "source": [
        "# from_scratch = True # Set to False if you have saved weights and want to load them\n",
        "\n",
        "# if not from_scratch:\n",
        "#     # Load weights from earlier model\n",
        "#     encoder_lstm_state_dict = torch.load('models/encoder1_lstm.pth')\n",
        "#     decoder_lstm_state_dict = torch.load('models/decoder1_lstm.pth')\n",
        "\n",
        "#     encoder_lstm.load_state_dict(encoder_lstm_state_dict)\n",
        "#     decoder_lstm.load_state_dict(decoder_lstm_state_dict)\n",
        "    \n",
        "#         # Load weights from earlier model\n",
        "#     encoder_gru_state_dict = torch.load('models/encoder1_gru.pth')\n",
        "#     decoder_gru_state_dict = torch.load('models/decoder1_gru.pth')\n",
        "\n",
        "#     encoder_gru.load_state_dict(encoder_gru_state_dict)\n",
        "#     decoder_gru.load_state_dict(decoder_gru_state_dict)\n",
        "# else:\n",
        "#     print('Training model from scratch.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Load weights from earlier model\n",
        "    encoder_lstm_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/encoder2_lstm.pth')\n",
        "    decoder_lstm_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/decoder2_lstm.pth')\n",
        "\n",
        "    encoder_lstm.load_state_dict(encoder_lstm_state_dict)\n",
        "    decoder_lstm.load_state_dict(decoder_lstm_state_dict)\n",
        "    \n",
        "        # Load weights from earlier model\n",
        "    encoder_gru_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/encoder2_gru.pth')\n",
        "    decoder_gru_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/decoder2_gru.pth')\n",
        "\n",
        "    encoder_gru.load_state_dict(encoder_gru_state_dict)\n",
        "    decoder_gru.load_state_dict(decoder_gru_state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaFpp02Ekf5P",
        "outputId": "3826eb07-d9b3-4a67-86bb-e6740e62f305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8o055n5pF3So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For dataset 1, models were trained for 3 epochs\n",
        "# For dataset 2, models were trained for 50 epochs\n",
        "\n",
        "learning_rate = 0.0001\n",
        "encoder_lstm.train() # Set model to training mode\n",
        "decoder_lstm.train() # Set model to training mode\n",
        "\n",
        "lstm_losses_cont = trainIters(encoder_lstm, decoder_lstm, dataloader, epochs=9, learning_rate = learning_rate)\n",
        "\n",
        "\n",
        "# For dataset 1, models were trained for 3 epochs\n",
        "# For dataset 2, models were trained for 50 epochs\n",
        "print('Training GRU based network.')\n",
        "learning_rate = 0.0001\n",
        "encoder_gru.train() # Set model to training mode\n",
        "decoder_gru.train() # Set model to training mode\n",
        "\n",
        "gru_losses = trainIters(encoder_gru, decoder_gru, dataloader, epochs=9, learning_rate = learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRq-pNFtMc4a",
        "outputId": "fba4839e-55cb-41f9-85a5-beb43ac41846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 2/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 3/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 4/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 5/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 6/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 7/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 8/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 9/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Training GRU based network.\n",
            "Epoch 1/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 2/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n",
            "After 900 batches, average loss/100 batches: nan\n",
            "After 1000 batches, average loss/100 batches: nan\n",
            "After 1100 batches, average loss/100 batches: nan\n",
            "After 1200 batches, average loss/100 batches: nan\n",
            "After 1300 batches, average loss/100 batches: nan\n",
            "After 1400 batches, average loss/100 batches: nan\n",
            "After 1500 batches, average loss/100 batches: nan\n",
            "After 1600 batches, average loss/100 batches: nan\n",
            "After 1700 batches, average loss/100 batches: nan\n",
            "After 1800 batches, average loss/100 batches: nan\n",
            "After 1900 batches, average loss/100 batches: nan\n",
            "After 2000 batches, average loss/100 batches: nan\n",
            "After 2100 batches, average loss/100 batches: nan\n",
            "After 2200 batches, average loss/100 batches: nan\n",
            "After 2300 batches, average loss/100 batches: nan\n",
            "After 2400 batches, average loss/100 batches: nan\n",
            "After 2500 batches, average loss/100 batches: nan\n",
            "After 2600 batches, average loss/100 batches: nan\n",
            "After 2700 batches, average loss/100 batches: nan\n",
            "After 2800 batches, average loss/100 batches: nan\n",
            "After 2900 batches, average loss/100 batches: nan\n",
            "After 3000 batches, average loss/100 batches: nan\n",
            "After 3100 batches, average loss/100 batches: nan\n",
            "After 3200 batches, average loss/100 batches: nan\n",
            "After 3300 batches, average loss/100 batches: nan\n",
            "After 3400 batches, average loss/100 batches: nan\n",
            "After 3500 batches, average loss/100 batches: nan\n",
            "After 3600 batches, average loss/100 batches: nan\n",
            "After 3700 batches, average loss/100 batches: nan\n",
            "After 3800 batches, average loss/100 batches: nan\n",
            "After 3900 batches, average loss/100 batches: nan\n",
            "After 4000 batches, average loss/100 batches: nan\n",
            "After 4100 batches, average loss/100 batches: nan\n",
            "After 4200 batches, average loss/100 batches: nan\n",
            "After 4300 batches, average loss/100 batches: nan\n",
            "After 4400 batches, average loss/100 batches: nan\n",
            "After 4500 batches, average loss/100 batches: nan\n",
            "After 4600 batches, average loss/100 batches: nan\n",
            "After 4700 batches, average loss/100 batches: nan\n",
            "After 4800 batches, average loss/100 batches: nan\n",
            "After 4900 batches, average loss/100 batches: nan\n",
            "After 5000 batches, average loss/100 batches: nan\n",
            "After 5100 batches, average loss/100 batches: nan\n",
            "After 5200 batches, average loss/100 batches: nan\n",
            "After 5300 batches, average loss/100 batches: nan\n",
            "After 5400 batches, average loss/100 batches: nan\n",
            "After 5500 batches, average loss/100 batches: nan\n",
            "After 5600 batches, average loss/100 batches: nan\n",
            "After 5700 batches, average loss/100 batches: nan\n",
            "After 5800 batches, average loss/100 batches: nan\n",
            "After 5900 batches, average loss/100 batches: nan\n",
            "After 6000 batches, average loss/100 batches: nan\n",
            "After 6100 batches, average loss/100 batches: nan\n",
            "After 6200 batches, average loss/100 batches: nan\n",
            "After 6300 batches, average loss/100 batches: nan\n",
            "After 6400 batches, average loss/100 batches: nan\n",
            "After 6500 batches, average loss/100 batches: nan\n",
            "After 6600 batches, average loss/100 batches: nan\n",
            "After 6700 batches, average loss/100 batches: nan\n",
            "After 6800 batches, average loss/100 batches: nan\n",
            "After 6900 batches, average loss/100 batches: nan\n",
            "After 7000 batches, average loss/100 batches: nan\n",
            "After 7100 batches, average loss/100 batches: nan\n",
            "After 7200 batches, average loss/100 batches: nan\n",
            "After 7300 batches, average loss/100 batches: nan\n",
            "After 7400 batches, average loss/100 batches: nan\n",
            "After 7500 batches, average loss/100 batches: nan\n",
            "After 7600 batches, average loss/100 batches: nan\n",
            "After 7700 batches, average loss/100 batches: nan\n",
            "After 7800 batches, average loss/100 batches: nan\n",
            "After 7900 batches, average loss/100 batches: nan\n",
            "After 8000 batches, average loss/100 batches: nan\n",
            "After 8100 batches, average loss/100 batches: nan\n",
            "After 8200 batches, average loss/100 batches: nan\n",
            "After 8300 batches, average loss/100 batches: nan\n",
            "After 8400 batches, average loss/100 batches: nan\n",
            "After 8500 batches, average loss/100 batches: nan\n",
            "After 8600 batches, average loss/100 batches: nan\n",
            "Epoch 3/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "After 500 batches, average loss/100 batches: nan\n",
            "After 600 batches, average loss/100 batches: nan\n",
            "After 700 batches, average loss/100 batches: nan\n",
            "After 800 batches, average loss/100 batches: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fETP4niRS7d"
      },
      "outputs": [],
      "source": [
        "# np.save('/content/sample_data/lstm2_losses.npy', lstm_losses_cont)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDKVOhAuS_Q-"
      },
      "outputs": [],
      "source": [
        "# np.save('/content/sample_data/gru2_losses.npy', gru_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "d626p8WiuWVw"
      },
      "outputs": [],
      "source": [
        "lstm_losses = np.load('/content/drive/MyDrive/machinetranslation/lstm2_losses.npy')\n",
        "gru_losses = np.load('/content/drive/MyDrive/machinetranslation/gru2_losses.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "eJfX5y96uWfG",
        "outputId": "0f59405b-56a8-4573-92f1-c21035269ea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1ebc3df940>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(lstm_losses)\n",
        "plt.plot(gru_losses)\n",
        "\n",
        "plt.title('Loss Plots for Dataset 1; Trained on 1 Epoch')\n",
        "plt.xlabel('Batches')\n",
        "plt.xticks([0,20,40,60,80],[0,2000,4000,6000,8000])\n",
        "plt.ylabel('Loss per Batch, MSE')\n",
        "plt.legend(['LSTM', 'GRU'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "inBptc2NuWij"
      },
      "outputs": [],
      "source": [
        "# # Save the model weights to continue later\n",
        "# torch.save(encoder_lstm.state_dict(), '/content/sample_data/encoder2_lstm.pth')\n",
        "# torch.save(decoder_lstm.state_dict(), '/content/sample_data/decoder2_lstm.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WWEkhwYtuWlq"
      },
      "outputs": [],
      "source": [
        "# torch.save(encoder_gru.state_dict(), '/content/sample_data/encoder2_gru.pth')\n",
        "# torch.save(decoder_gru.state_dict(), '/content/sample_data/decoder2_gru.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgSX2Nz-aA2"
      },
      "source": [
        "Part 4: Using the Model for Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "WvRgoODR-ahL"
      },
      "outputs": [],
      "source": [
        "# Build the idx to word dictionaries to convert predicted indices to words\n",
        "en_idx2word = {k:i for i, k in en_word2idx.items()}\n",
        "fr_idx2word = {k:i for i, k in fr_word2idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "vpj1sLVd-dxr"
      },
      "outputs": [],
      "source": [
        "def get_batch(dataloader):\n",
        "    for batch in dataloader:\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "CqwKwR4E-gaM"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_tensor, encoder, decoder):\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden = encoder.initHidden(1)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor.to(device), encoder_hidden)\n",
        "\n",
        "        decoder_input =  torch.tensor([fr_word2idx['']]*input_tensor.shape[0], dtype=torch.long, device=device).unsqueeze(0)\n",
        "        try:\n",
        "            encoder.lstm\n",
        "            decoder_hidden = (encoder_hidden[0][1::2].contiguous(), encoder_hidden[1][1::2].contiguous())\n",
        "        except AttributeError:\n",
        "            decoder_hidden = encoder_hidden[1::2].contiguous()\n",
        "\n",
        "        output_list = []\n",
        "        attn_weight_list = np.zeros((seq_length, seq_length))\n",
        "        for di in range(seq_length):\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "\n",
        "            decoder_input = output.topk(1)[1].detach()\n",
        "            output_list.append(output.topk(1)[1])\n",
        "            word = en_idx2word[output.topk(1)[1].item()]\n",
        "\n",
        "            attn_weight_list[di] += attn_weights[0,0,:].cpu().numpy()\n",
        "        return output_list, attn_weight_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "tTtdNjFK-iv0"
      },
      "outputs": [],
      "source": [
        "batch = get_batch(dataloader)\n",
        "input_tensor = batch['french_tensor'][11].unsqueeze_(0)\n",
        "output_list, attn = evaluate(input_tensor, encoder_lstm, decoder_lstm)\n",
        "gru_output_list, gru_attn = evaluate(input_tensor, encoder_gru, decoder_gru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_A0WB_SZ-2je",
        "outputId": "c71a5ac9-6f78-4426-ed80-716af22a63f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence:\n",
            " chine est relaxant en automne , et il est chaud en hiver . \n",
            "\n",
            "Target Sentence:\n",
            " china is relaxing during autumn , and it is hot in winter .\n",
            "\n",
            "LSTM model output:\n",
            " china is relaxing during autumn , and it is warm in winter . \n",
            "\n",
            "GRU model output:\n",
            " china is relaxing during autumn , and it is warm in winter . \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-f6011f4e1b75>:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  ax = fig.add_subplot(111)\n",
            "<ipython-input-97-f6011f4e1b75>:51: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  ax2 = fig.add_subplot(111)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'china'),\n",
              " Text(0, 0, 'is'),\n",
              " Text(0, 0, 'relaxing'),\n",
              " Text(0, 0, 'during'),\n",
              " Text(0, 0, 'autumn'),\n",
              " Text(0, 0, ','),\n",
              " Text(0, 0, 'and'),\n",
              " Text(0, 0, 'it'),\n",
              " Text(0, 0, 'is'),\n",
              " Text(0, 0, 'warm'),\n",
              " Text(0, 0, 'in'),\n",
              " Text(0, 0, 'winter'),\n",
              " Text(0, 0, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print('Input Sentence:')\n",
        "input_fr_output = ''\n",
        "for index in input_tensor[0]:\n",
        "    word = fr_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        input_fr_output += ' ' + word\n",
        "    else:\n",
        "        input_fr_output += ' ' + word\n",
        "        print(input_fr_output)\n",
        "        break\n",
        "\n",
        "print('\\nTarget Sentence:')\n",
        "targ_sen_fr = ' ' + batch['english_sentence'][11] + ''\n",
        "print(targ_sen_fr)\n",
        "input_len = len(batch['french_sentence'][11].split())\n",
        "\n",
        "print('\\nLSTM model output:')\n",
        "lstm_fr_output = ''\n",
        "for index in output_list:\n",
        "    word = en_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        lstm_fr_output += ' ' + word\n",
        "    else:\n",
        "        lstm_fr_output += ' ' + word\n",
        "        print(lstm_fr_output)\n",
        "        break\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.title('LSTM Model Attention\\n\\n\\n\\n\\n')\n",
        "ax = fig.add_subplot(111)\n",
        "ax.matshow(attn[:len(lstm_fr_output.split()), :input_len])\n",
        "ax.set_xticks(np.arange(0,input_len, step=1))\n",
        "ax.set_yticks(np.arange(0,len(lstm_fr_output.split())))\n",
        "ax.set_xticklabels(batch['french_sentence'][11].split(), rotation=90)\n",
        "ax.set_yticklabels(lstm_fr_output.split()+[''])\n",
        "\n",
        "\n",
        "gru_fr_output = ''\n",
        "print('\\nGRU model output:')\n",
        "for index in gru_output_list:\n",
        "    word = en_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        gru_fr_output += ' ' + word\n",
        "    else:\n",
        "        gru_fr_output += ' ' + word\n",
        "        print(gru_fr_output)\n",
        "        break\n",
        "        \n",
        "fig = plt.figure()\n",
        "plt.title('GRU Model Attention\\n\\n\\n\\n\\n')\n",
        "ax2 = fig.add_subplot(111)\n",
        "ax2.matshow(gru_attn[:len(gru_fr_output.split()), :input_len])\n",
        "ax2.set_xticks(np.arange(0,input_len, step=1))\n",
        "ax2.set_yticks(np.arange(0,len(gru_fr_output.split())))\n",
        "ax2.set_xticklabels(batch['french_sentence'][11].split(), rotation=90)\n",
        "ax2.set_yticklabels(gru_fr_output.split()+[''])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINDING BLEU SCRORE (FRENCH TO ENGLISH):"
      ],
      "metadata": {
        "id": "3JT0LJAcmW06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For LSTM:"
      ],
      "metadata": {
        "id": "nhbdtznXvQ9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two references for one document\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "references = [targ_sen_fr.split()]\n",
        "canidates = [lstm_fr_output.split()]"
      ],
      "metadata": {
        "id": "1BN8BW1Qmccd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = corpus_bleu(references, canidates)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "sruh2VZOPJw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadfa18c-589a-4dbe-fa42-59ea32e8a421"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1409851298103347e-231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR GRU:"
      ],
      "metadata": {
        "id": "vIKsneeavVLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "references = [targ_sen_fr.split()]\n",
        "canidates = [gru_fr_output.split()]"
      ],
      "metadata": {
        "id": "P-jMC21MvHub"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = corpus_bleu(references, canidates)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ6-80fVvAGu",
        "outputId": "9c62b985-32bd-43b8-dcfa-27b9ad3af8c9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1409851298103347e-231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# URDU TO ENGLISH:\n"
      ],
      "metadata": {
        "id": "rif2E4UNlxXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we get started we will load all the packages we will need\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "# Use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "su8J1yVxfdbJ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/machinetranslation/quran-en', \"r\",encoding=\"utf8\") as f:\n",
        "    data1 = f.read()\n",
        "with open('/content/drive/MyDrive/machinetranslation/quran-ur', \"r\",encoding=\"utf8\") as f:\n",
        "    data2 = f.read()\n",
        "    \n",
        "# The data is just in a text file with each sentence on its own line\n",
        "english_sentences = data1.split('\\n')\n",
        "urdu_sentences = data2.split('\\n')\n",
        "\n",
        "english_sentences\n",
        "urdu_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGivnKA2lxXS",
        "outputId": "20843a94-5f8e-446f-a8c7-de35ed4dba84"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffسب تعریفیں اللہ ہی کے لئے ہیں جو تمام جہانوں کی پرورش فرمانے والا ہے ۔',\n",
              " 'نہایت مہربان بہت رحم فرمانے والا ہے ۔',\n",
              " 'روزِ جزا کا مالک ہے ۔',\n",
              " 'اے اللہ ! ہم تیری ہی عبادت کرتے ہیں اور ہم تجھ ہی سے مدد چاہتے ہیں ۔',\n",
              " 'ہمیں سیدھا راستہ دکھا ۔',\n",
              " 'ان لوگوں کا راستہ جن پر تو نے انعام فرمایا ۔',\n",
              " 'ان لوگوں کا نہیں جن پر غضب کیا گیا ہے اور نہ ہی گمراہوں کا ۔',\n",
              " 'الف لام میم حقیقی معنی اﷲ اور رسول صلی اللہ علیہ وآلہ وسلم ہی بہتر جانتے ہیں ۔',\n",
              " 'یہ وہ عظیم کتاب ہے جس میں کسی شک کی گنجائش نہیں ، یہ پرہیزگاروں کے لئے ہدایت ہے ۔',\n",
              " 'جو غیب پر ایمان لاتے اور نماز کو تمام حقوق کے ساتھ قائم کرتے ہیں اور جو کچھ ہم نے انہیں عطا کیا ہے اس میں سے ہماری راہ میں خرچ کرتے ہیں ۔',\n",
              " 'اور وہ لوگ جو آپ کی طرف نازل کیا گیا اور جو آپ سے پہلے نازل کیا گیا سب پر ایمان لاتے ہیں ، اور وہ آخرت پر بھی کامل یقین رکھتے ہیں ۔',\n",
              " 'وہی اپنے رب کی طرف سے ہدایت پر ہیں اور وہی حقیقی کامیابی پانے والے ہیں ۔',\n",
              " 'بیشک جنہوں نے کفر اپنا لیا ہے ان کے لئے برابر ہے خواہ آپ انہیں ڈرائیں یا نہ ڈرائیں ، وہ ایمان نہیں لائیں گے ۔',\n",
              " 'اللہ نے ان کے اپنے اِنتخاب کے نتیجے میں ان کے دلوں اور کانوں پر مُہر لگا دی ہے اور ان کی آنکھوں پر پردہ پڑ گیا ہے اور ان کے لئے سخت عذاب ہے ۔',\n",
              " 'اور لوگوں میں سے بعض وہ بھی ہیں جو کہتے ہیں ہم اللہ پر اور یومِ قیامت پر ایمان لائے حالانکہ وہ ہرگز مومن نہیں ہیں ۔',\n",
              " 'وہ اللہ کو یعنی رسول صلی اللہ علیہ وآلہ وسلم کو اور ایمان والوں کو دھوکہ دینا چاہتے ہیں مگر فی الحقیقت وہ اپنے آپ کو ہی دھوکہ دے رہے ہیں اور انہیں اس کا شعور نہیں ہے ۔',\n",
              " 'ان کے دلوں میں بیماری ہے ، پس اللہ نے ان کی بیماری کو اور بڑھا دیا اور ان کے لئے دردناک عذاب ہے ۔ اس وجہ سے کہ وہ جھوٹ بولتے تھے ۔',\n",
              " 'اور جب ان سے کہا جاتا ہے کہ زمین میں فساد بپا نہ کرو ، تو کہتے ہیں : ہم ہی تو اصلاح کرنے والے ہیں ۔',\n",
              " 'آگاہ ہو جاؤ ! یہی لوگ حقیقت میں فساد کرنے والے ہیں مگر انہیں اس کا احساس تک نہیں ۔',\n",
              " 'اور جب ان سے کہا جاتا ہے کہ تم بھی ایمان لاؤ جیسے دوسرے لوگ ایمان لے آئے ہیں ، تو کہتے ہیں : کیا ہم بھی اسی طرح ایمان لے آئیں جس طرح وہ بیوقوف ایمان لے آئے ، جان لو ! بیوقوف درحقیقت وہ خود ہیں لیکن انہیں اپنی بیوقوفی اور ہلکے پن کا علم نہیں ۔',\n",
              " 'اور جب وہ منافق اہل ایمان سے ملتے ہیں تو کہتے ہیں : ہم بھی ایمان لے آئے ہیں ، اور جب اپنے شیطانوں سے تنہائی میں ملتے ہیں تو کہتے ہیں : ہم یقیناً تمہارے ساتھ ہیں ، ہم مسلمانوں کا تو محض مذاق اڑاتے ہیں ۔',\n",
              " 'اللہ انہیں ان کے مذاق کی سزا دیتا ہے اور انہیں ڈھیل دیتا ہے تاکہ وہ خود اپنے انجام تک جا پہنچیں سو وہ خود اپنی سرکشی میں بھٹک رہے ہیں ۔',\n",
              " 'یہی وہ لوگ ہیں جنہوں نے ہدایت کے بدلے گمراہی خریدی لیکن ان کی تجارت فائدہ مند نہ ہوئی اور وہ فائدہ مند اور نفع بخش سودے کی راہ جانتے ہی نہ تھے ۔',\n",
              " 'ان کی مثال ایسے شخص کی مانند ہے جس نے تاریک ماحول میں آگ جلائی اور جب اس نے گرد و نواح کو روشن کر دیا تو اللہ نے ان کا نور سلب کر لیا اور انہیں تاریکیوں میں چھوڑ دیا اب وہ کچھ نہیں دیکھتے ۔',\n",
              " 'یہ بہرے ، گونگے اور اندھے ہیں پس وہ راہِ راست کی طرف نہیں لوٹیں گے ۔',\n",
              " 'یا ان کی مثال اس بارش کی سی ہے جو آسمان سے برس رہی ہے جس میں اندھیریاں ہیں اور گرج اور چمک بھی ہے تو وہ کڑک کے باعث موت کے ڈر سے اپنے کانوں میں انگلیاں ٹھونس لیتے ہیں ، اور اللہ کافروں کو گھیرے ہوئے ہے ۔',\n",
              " 'یوں لگتا ہے کہ بجلی ان کی بینائی اُچک لے جائے گی ،',\n",
              " 'جب بھی ان کے لئے ماحول میں کچھ چمک ہوتی ہے تو اس میں چلنے لگتے ہیں',\n",
              " 'اور جب ان پر اندھیرا چھا جاتا ہے تو کھڑے ہو جاتے ہیں ،',\n",
              " 'اور اگر اللہ چاہتا تو ان کی سماعت اور بصارت بالکل سلب کر لیتا ،',\n",
              " 'بیشک اللہ ہر چیز پر قادر ہے ۔',\n",
              " 'اے لوگو ! اپنے رب کی عبادت کرو جس نے تمہیں پیدا کیا اور ان لوگوں کو بھی جو تم سے پیشتر تھے تاکہ تم پرہیزگار بن جاؤ ۔',\n",
              " 'جس نے تمہارے لئے زمین کو فرش اور آسمان کو عمارت بنایا اور آسمانوں کی طرف سے پانی برسایا پھر اس کے ذریعے تمہارے کھانے کے لئے انواع و اقسام کے پھل پیدا کئے ،',\n",
              " 'پس تم اللہ کے لئے شریک نہ ٹھہراؤ حالانکہ تم حقیقتِ حال جانتے ہو ۔',\n",
              " 'اور اگر تم اس کلام کے بارے میں شک میں مبتلا ہو جو ہم نے اپنے برگزیدہ بندے پر نازل کیا ہے تو اس جیسی کوئی ایک سورت ہی بنا لاؤ ، اور اس کام کے لئے بیشک اللہ کے سوا اپنے سب حمائتیوں کو بلا لو اگر تم اپنے شک اور انکار میں سچے ہو ۔',\n",
              " 'پھر اگر تم ایسا نہ کر سکو اور ہرگز نہ کر سکو گے تو اس آگ سے بچو جس کا ایندھن آدمی یعنی کافر اور پتھر یعنی ان کے بت ہیں ، جو کافروں کے لئے تیار کی گئی ہے ۔',\n",
              " 'اور اے حبیب ! آپ ان لوگوں کو خوشخبری سنا دیں جو ایمان لائے اور نیک عمل کرتے رہے کہ ان کے لئے بہشت کے باغات ہیں جن کے نیچے نہریں بہتی ہیں ،',\n",
              " 'جب انہیں ان باغات میں سے کوئی پھل کھانے کو دیا جائے گا تو اس کی ظاہری صورت دیکھ کر کہیں گے :',\n",
              " 'یہ تو وہی پھل ہے جو ہمیں دنیا میں پہلے دیا گیا تھا ،',\n",
              " 'حالانکہ انہیں صورت میں ملتے جلتے پھل دیئے گئے ہوں گے ،',\n",
              " 'ان کے لئے جنت میں پاکیزہ بیویاں بھی ہوں گی اور وہ ان میں ہمیشہ رہیں گے ۔',\n",
              " 'بیشک اللہ اس بات سے نہیں شرماتا کہ سمجھانے کے لئے کوئی بھی مثال بیان فرمائے خواہ مچھر کی ہو یا ایسی چیز کی جو حقارت میں اس سے بھی بڑھ کر ہو ،',\n",
              " 'تو جو لوگ ایمان لائے وہ خوب جانتے ہیں کہ یہ مثال ان کے رب کی طرف سے حق کی نشاندہی ہے ،',\n",
              " 'اور جنہوں نے کفر اختیار کیا وہ اسے سن کر یہ کہتے ہیں کہ ایسی تمثیل سے اللہ کو کیا سروکار ؟',\n",
              " 'اس طرح اللہ ایک ہی بات کے ذریعے بہت سے لوگوں کو گمراہ ٹھہراتا ہے اور بہت سے لوگوں کو ہدایت دیتا ہے',\n",
              " 'اور اس سے صرف انہی کو گمراہی میں ڈالتا ہے جو پہلے ہی نافرمان ہیں ۔',\n",
              " 'یہ نافرمان وہ لوگ ہیں جو اللہ کے عہد کو اس سے پختہ کرنے کے بعد توڑتے ہیں ، اور اس تعلق کو کاٹتے ہیں جس کو اللہ نے جوڑنے کا حکم دیا ہے اور زمین میں فساد بپا کرتے ہیں ، یہی لوگ نقصان اٹھانے والے ہیں ۔',\n",
              " 'تم کس طرح اللہ کا انکار کرتے ہو حالانکہ تم بے جان تھے اس نے تمہیں زندگی بخشی ، پھر تمہیں موت سے ہمکنار کرے گا اور پھر تمہیں زندہ کرے گا ، پھر تم اسی کی طرف لوٹائے جاؤ گے ۔',\n",
              " 'وہی ہے جس نے سب کچھ جو زمین میں ہے تمہارے لئے پیدا کیا ، پھر وہ کائنات کے بالائی حصوں کی طرف متوجہ ہوا تو اس نے انہیں درست کر کے ان کے سات آسمانی طبقات بنا دیئے ، اور وہ ہر چیز کا جاننے والا ہے ۔',\n",
              " 'اور وہ وقت یاد کریں جب آپ کے رب نے فرشتوں سے فرمایا کہ میں زمین میں اپنا نائب بنانے والا ہوں ، انہوں نے عرض کیا : کیا تُو زمین میں کسی ایسے شخص کو نائب بنائے گا جو اس میں فساد انگیزی کرے گا اور خونریزی کرے گا ؟ حالانکہ ہم تیری حمد کے ساتھ تسبیح کرتے رہتے ہیں اور ہمہ وقت پاکیزگی بیان کرتے ہیں ، اللہ نے فرمایا : میں وہ کچھ جانتا ہوں جو تم نہیں جانتے ۔',\n",
              " 'اور اللہ نے آدم علیہ السلام کو تمام اشیاء کے نام سکھا دیئے پھر انہیں فرشتوں کے سامنے پیش کیا ، اور فرمایا : مجھے ان اشیاء کے نام بتا دو اگر تم اپنے خیال میں سچے ہو ۔',\n",
              " 'فرشتوں نے عرض کیا : تیری ذات ہر نقص سے پاک ہے ہمیں کچھ علم نہیں مگر اسی قدر جو تو نے ہمیں سکھایا ہے ، بیشک تو ہی سب کچھ جاننے والا حکمت والا ہے ۔',\n",
              " 'اللہ نے فرمایا : اے آدم ! اب تم انہیں ان اشیاء کے ناموں سے آگاہ کرو ، پس جب آدم علیہ السلام نے انہیں ان اشیاء کے ناموں سے آگاہ کیا تو اللہ نے فرمایا : کیا میں نے تم سے نہیں کہا تھا کہ میں آسمانوں اور زمین کی سب مخفی حقیقتوں کو جانتا ہوں ، اور وہ بھی جانتا ہوں جو تم ظاہر کرتے ہو اور جو تم چھپاتے ہو ۔',\n",
              " 'اور وہ وقت بھی یاد کریں جب ہم نے فرشتوں سے فرمایا کہ آدم علیہ السلام کو سجدہ کرو تو سب نے سجدہ کیا سوائے ابلیس کے ، اس نے انکار اور تکبر کیا اور نتیجۃً کافروں میں سے ہو گیا ۔',\n",
              " 'اور ہم نے حکم دیا : اے آدم ! تم اور تمہاری بیوی اس جنت میں رہائش رکھو اور تم دونوں اس میں سے جو چاہو ، جہاں سے چاہو کھاؤ ، مگر اس درخت کے قریب نہ جانا ورنہ حد سے بڑھنے والوں میں شامل ہو جاؤ گے ۔',\n",
              " 'پھر شیطان نے انہیں اس جگہ سے ہلا دیا اور انہیں اس راحت کے مقام سے جہاں وہ تھے الگ کر دیا ، اور بالآخر ہم نے حکم دیا کہ تم نیچے اتر جاؤ ، تم ایک دوسرے کے دشمن رہو گے ۔ اب تمہارے لئے زمین میں ہی معیّنہ مدت تک جائے قرار ہے اور نفع اٹھانا مقدّر کر دیا گیا ہے ۔',\n",
              " 'پھر آدم علیہ السلام نے اپنے رب سے عاجزی اور معافی کے چند کلمات سیکھ لئے پس اللہ نے ان کی توبہ قبول فرما لی ، بیشک وہی بہت توبہ قبول کرنے والا مہربان ہے ۔',\n",
              " 'ہم نے فرمایا : تم سب جنت سے اتر جاؤ ، پھر اگر تمہارے پاس میری طرف سے کوئی ہدایت پہنچے تو جو بھی میری ہدایت کی پیروی کرے گا ، نہ ان پر کوئی خوف طاری ہوگا اور نہ وہ غمگین ہوں گے ۔',\n",
              " 'اور جو لوگ کفر کریں گے اور ہماری آیتوں کو جھٹلائیں گے تو وہی دوزخی ہوں گی ، وہ اس میں ہمیشہ رہیں گے ۔',\n",
              " 'اے اولادِ یعقوب ! میرے وہ انعام یاد کرو جو میں نے تم پر کئے اور تم میرے ساتھ کیا ہوا وعدہ پورا کرو میں تمہارے ساتھ کیا ہوا وعدہ پورا کروں گا ، اور مجھ ہی سے ڈرا کرو ۔',\n",
              " 'اور اس کتاب پر ایمان لاؤ جو میں نے اپنے رسول محمد صلی اللہ علیہ وآلہ وسلم پر اتاری ہے ، حالانکہ یہ اس کی اصلاً تصدیق کرتی ہے جو تمہارے پاس ہے اور تم ہی سب سے پہلے اس کے منکر نہ بنو اور میری آیتوں کو دنیا کی تھوڑی سی قیمت پر فروخت نہ کرو اور مجھ ہی سے ڈرتے رہو ۔',\n",
              " 'اور حق کی آمیزش باطل کے ساتھ نہ کرو اور نہ ہی حق کو جان بوجھ کر چھپاؤ ۔',\n",
              " 'اور نماز قائم رکھو اور زکوٰۃ دیا کرو اور رکوع کرنے والوں کے ساتھ مل کر رکوع کیا کرو ۔',\n",
              " 'کیا تم دوسرے لوگوں کو نیکی کا حکم دیتے ہو اور اپنے آپ کو بھول جاتے ہو حالانکہ تم اللہ کی کتاب بھی پڑھتے ہو ، تو کیا تم نہیں سوچتے ؟ ۔',\n",
              " 'اور صبر اور نماز کے ذریعے اللہ سے مدد چاہو ، اور بیشک یہ گراں ہے مگر ان عاجزوں پر ہرگز نہیں جن کے دل محبتِ الٰہی سے خستہ اور خشیتِ الٰہی سے شکستہ ہیں ۔',\n",
              " 'یہ وہ لوگ ہیں جو یقین رکھتے ہیں کہ وہ اپنے رب سے ملاقات کرنے والے ہیں اور وہ اسی کی طرف لوٹ کر جانے والے ہیں ۔',\n",
              " 'اے اولادِ یعقوب ! میرے وہ انعام یاد کرو جو میں نے تم پر کئے اور یہ کہ میں نے تمہیں اس زمانے میں سب لوگوں پر فضیلت دی ۔',\n",
              " 'اور اُس دن سے ڈرو جس دن کوئی جان کسی دوسرے کی طرف سے کچھ بدلہ نہ دے سکے گی',\n",
              " 'اور نہ اس کی طرف سے کسی ایسے شخص کی کوئی سفارش قبول کی جائے گی جسے اِذنِ اِلٰہی حاصل نہ ہوگا',\n",
              " 'اور نہ اس کی طرف سے جان چھڑانے کے لئے کوئی معاوضہ قبول کیا جائے گا',\n",
              " 'اور نہ اَمرِ الٰہی کے خلاف ان کی اِمداد کی جا سکے گی ۔',\n",
              " 'اور وہ وقت بھی یاد کرو جب ہم نے تمہیں قومِ فرعون سے نجات بخشی جو تمہیں انتہائی سخت عذاب دیتے تھے تمہارے بیٹوں کو ذبح کرتے اور تمہاری بیٹیوں کو زندہ رکھتے تھے ، اور اس میں تمہارے پروردگار کی طرف سے بڑی کڑی آزمائش تھی ۔',\n",
              " 'اور جب ہم نے تمہیں بچانے کے لئے دریا کو پھاڑ دیا سو ہم نے تمہیں اس طرح نجات عطا کی اور دوسری طرف ہم نے تمہاری آنکھوں کے سامنے قومِ فرعون کو غرق کر دیا ۔',\n",
              " 'اور وہ وقت بھی یاد کرو جب ہم نے موسیٰ علیہ السلام سے چالیس راتوں کا وعدہ فرمایا تھا پھر تم نے موسیٰ علیہ السلام کے چلّہءِ اعتکاف میں جانے کے بعد بچھڑے کو اپنا معبود بنا لیا اور تم واقعی بڑے ظالم تھے ۔',\n",
              " 'پھر ہم نے اس کے بعد بھی تمہیں معاف کر دیا تاکہ تم شکرگزار ہو جاؤ ۔',\n",
              " 'اور جب ہم نے موسیٰ علیہ السلام کو کتاب اور حق و باطل میں فرق کرنے والا معجزہ عطا کیا تاکہ تم راہِ ہدایت پاؤ ۔',\n",
              " 'اور جب موسیٰ علیہ السلام نے اپنی قوم سے کہا : اے میری قوم ! بیشک تم نے بچھڑے کو اپنا معبود بنا کر اپنی جانوں پر بڑا ظلم کیا ہے ، تو اب اپنے پیدا فرمانے والے حقیقی رب کے حضور توبہ کرو ،',\n",
              " 'پس آپس میں ایک دوسرے کو قتل کر ڈالو اس طرح کہ جنہوں نے بچھڑے کی پرستش نہیں کی اور اپنے دین پر قائم رہے ہیں وہ بچھڑے کی پرستش کر کے دین سے پھر جانے والوں کو سزا کے طور پر قتل کر دیں ،',\n",
              " 'یہی عمل تمہارے لئے تمہارے خالق کے نزدیک بہترین توبہ ہے ،',\n",
              " 'پھر اس نے تمہاری توبہ قبول فرما لی ،',\n",
              " 'یقینا وہ بڑا ہی توبہ قبول کرنے والا مہربان ہے ۔',\n",
              " 'اور جب تم نے کہا : اے موسیٰ ! ہم آپ پر ہرگز ایمان نہ لائیں گے یہاں تک کہ ہم اللہ کو آنکھوں کے سامنے بالکل آشکارا دیکھ لیں پس اس پر تمہیں کڑک نے آلیا جو تمہاری موت کا باعث بن گئی اور تم خود یہ منظر دیکھتے رہے ۔',\n",
              " 'پھر ہم نے تمہارے مرنے کے بعد تمہیں دوبارہ زندہ کیا تاکہ تم ہمارا شکر ادا کرو ۔',\n",
              " 'اور یاد کرو جب ہم نے تم پر وادئ تِیہ میں بادل کا سایہ کئے رکھا اور ہم نے تم پر مَنّ و سلوٰی اتارا کہ تم ہماری عطا کی ہوئی پاکیزہ چیزوں میں سے کھاؤ ، سو انہوں نے نافرمانی اور ناشکری کر کے ہمارا کچھ نہیں بگاڑا مگر اپنی ہی جانوں پر ظلم کرتے رہے ۔',\n",
              " 'اور یاد کرو جب ہم نے فرمایا : اس شہر میں داخل ہو جاؤ اور اس میں جہاں سے چاہو خوب جی بھر کے کھاؤ اور یہ کہ شہر کے دروازے میں سجدہ کرتے ہوئے داخل ہونا اور یہ کہتے جانا : اے ہمارے رب ! ہم سب خطاؤں کی بخشش چاہتے ہیں ، تو ہم تمہاری گزشتہ خطائیں معاف فرما دیں گے ، اور علاوہ اس کے نیکوکاروں کو مزید لطف و کرم سے نوازیں گے ۔',\n",
              " 'پھر ان ظالموں نے اس قول کو جو ان سے کہا گیا تھا ایک اور کلمہ سے بدل ڈالا سو ہم نے ان ظالموں پر آسمان سے بصورتِ طاعون سخت آفت اتار دی اس وجہ سے کہ وہ مسلسل حکم عدولی کر رہے تھے ۔',\n",
              " 'اور وہ وقت بھی یا دکرو جب موسیٰ علیہ السلام نے اپنی قوم کے لئے پانی مانگا تو ہم نے فرمایا : اپنا عصا اس پتھر پر مارو ، پھر اس پتھر سے بارہ چشمے پھوٹ پڑے ، واقعۃً ہر گروہ نے اپنا اپنا گھاٹ پہچان لیا ، ہم نے فرمایا : اﷲ کے عطا کردہ رزق میں سے کھاؤ اور پیو لیکن زمین میں فساد انگیزی نہ کرتے پھرو ۔',\n",
              " 'اور جب تم نے کہا : اے موسیٰ ! ہم فقط ایک کھانے یعنی منّ و سلویٰ پر ہرگز صبر نہیں کر سکتے تو آپ اپنے رب سے ہمارے حق میں دعا کیجئے کہ وہ ہمارے لئے زمین سے اگنے والی چیزوں میں سے ساگ اور ککڑی اور گیہوں اور مسور اور پیاز پیدا کر دے ،',\n",
              " 'موسیٰ علیہ السلام نے اپنی قوم سے فرمایا : کیا تم اس چیز کو جو ادنیٰ ہے بہتر چیز کے بدلے مانگتے ہو ؟ اگر تمہاری یہی خواہش ہے تو کسی بھی شہر میں جا اترو یقیناً وہاں تمہارے لئے وہ کچھ میسر ہو گا جو تم مانگتے ہو ،',\n",
              " 'اور ان پر ذلّت اور محتاجی مسلط کر دی گئی ، اور وہ اللہ کے غضب میں لوٹ گئے ، یہ اس وجہ سے ہوا کہ وہ اللہ کی آیتوں کا انکار کیا کرتے اور انبیاء کو ناحق قتل کرتے تھے ،',\n",
              " 'اور یہ اس وجہ سے بھی ہوا کہ وہ نافرمانی کیا کرتے اور ہمیشہ حد سے بڑھ جاتے تھے ۔',\n",
              " 'بیشک جو لوگ ایمان لائے اور جو یہودی ہوئے اور جو نصاریٰ اور صابی تھے ان میں سے جو بھی اللہ پر اور آخرت کے دن پر ایمان لایا اور اس نے اچھے عمل کئے ، تو ان کے لئے ان کے رب کے ہاں ان کا اجر ہے ، ان پر نہ کوئی خوف ہوگا اور نہ وہ رنجیدہ ہوں گے ۔',\n",
              " 'اور یاد کرو جب ہم نے تم سے پختہ عہد لیا اور تمہارے اوپر طور کو اٹھا کھڑا کیا ، کہ جو کچھ ہم نے تمہیں دیا ہے اسے مضبوطی سے پکڑے رہو اور جو کچھ اس کتاب تورات میں لکھا ہے اسے یاد رکھو تاکہ تم پرہیزگار بن جاؤ ۔',\n",
              " 'پھر اس عہد اور تنبیہ کے بعد بھی تم نے روگردانی کی ، پس اگر تم پر اللہ کا فضل اور اس کی رحمت نہ ہوتی تو تم یقینا تباہ ہو جاتے ۔',\n",
              " 'اور اے یہود ! تم یقیناً ان لوگوں سے خوب واقف ہو جنہوں نے تم میں سے ہفتہ کے دن کے احکام کے بارے میں سرکشی کی تھی تو ہم نے ان سے فرمایا کہ تم دھتکارے ہوئے بندر بن جاؤ ۔',\n",
              " 'پس ہم نے اس واقعہ کو اس زمانے اور اس کے بعد والے لوگوں کے لئے باعثِ عبرت اور پرہیزگاروں کے لئے مُوجبِ نصیحت بنا دیا ۔',\n",
              " 'اور وہ واقعہ بھی یاد کرو جب موسیٰ علیہ السلام نے اپنی قوم سے فرمایا کہ بیشک اللہ تمہیں حکم دیتا ہے کہ ایک گائے ذبح کرو ، تو وہ بولے : کیا آپ ہمیں مسخرہ بناتے ہیں ؟ موسیٰ علیہ السلام نے فرمایا : اللہ کی پناہ مانگتا ہوں اس سے کہ میں جاہلوں میں سے ہو جاؤں ۔',\n",
              " 'تب انہوں نے کہا : آپ ہمارے لئے اپنے رب سے دعا کریں کہ وہ ہم پر واضح کر دے کہ وہ گائے کیسی ہو ؟ موسیٰ علیہ السلام نے کہا : بیشک وہ فرماتا ہے کہ وہ گائے نہ تو بوڑھی ہو اور نہ بالکل کم عمر اَوسَر ، بلکہ درمیانی عمر کی راس ہو ، پس اب تعمیل کرو جس کا تمہیں حکم دیا گیا ہے ۔',\n",
              " 'وہ پھر بولے : اپنے رب سے ہمارے حق میں دعا کریں وہ ہمارے لئے واضح کر دے کہ اس کا رنگ کیسا ہو ؟ موسیٰ علیہ السلام نے کہا : وہ فرماتا ہے کہ وہ گائے زرد رنگ کی ہو ، اس کی رنگت خوب گہری ہو ایسی جاذبِ نظر ہو کہ دیکھنے والوں کو بہت بھلی لگے ۔',\n",
              " 'اب انہوں نے کہا : آپ ہمارے لئے اپنے رب سے درخواست کیجئے کہ وہ ہم پر واضح فرما دے کہ وہ کون سی گائے ہے ؟ کیونکہ ہم پر گائے مشتبہ ہو گئی ہے ، اور یقیناً اگر اللہ نے چاہا تو ہم ضرور ہدایت یافتہ ہو جائیں گے ۔',\n",
              " 'موسیٰ علیہ السلام نے کہا : اللہ تعالیٰ فرماتا ہے وہ کوئی گھٹیا گائے نہیں بلکہ یقینی طور پر ایسی اعلیٰ گائے ہو جس سے نہ زمین میں ہل چلانے کی محنت لی جاتی ہو اور نہ کھیتی کو پانی دیتی ہو ، بالکل تندرست ہو اس میں کوئی داغ دھبہ بھی نہ ہو ، انہوں نے کہا : اب آپ ٹھیک بات لائے ہیں ، پھر انہوں نے اس کو ذبح کیا حالانکہ وہ ذبح کرتے معلوم نہ ہوتے تھے ۔',\n",
              " 'اور جب تم نے ایک شخص کو قتل کر دیا پھر تم آپس میں اس کے الزام میں جھگڑنے لگے ، اور اللہ وہ بات ظاہر فرمانے والا تھا جسے تم چھپا رہے تھے ۔',\n",
              " 'پھر ہم نے حکم دیا کہ اس مُردہ پر اس گائے کا ایک ٹکڑا مارو ، اسی طرح اللہ مُردوں کو زندہ فرماتا ہے یا قیامت کے دن مُردوں کو زندہ کرے گا اور تمہیں اپنی نشانیاں دکھاتا ہے تاکہ تم عقل و شعور سے کام لو ۔',\n",
              " 'پھر اس کے بعد بھی تمہارے دل سخت ہوگئے چنانچہ وہ سختی میں پتھروں جیسے ہوگئے ہیں یا ان سے بھی زیادہ سخت ہو چکے ہیں',\n",
              " 'بیشک پتھروں میں تو بعض ایسے بھی ہیں جن سے نہریں پھوٹ نکلتی ہیں ، اور یقیناً ان میں سے بعض وہ پتھر بھی ہیں جو پھٹ جاتے ہیں تو ان سے پانی ابل پڑتا ہے ،',\n",
              " 'اور بیشک ان میں سے بعض ایسے بھی ہیں جو اللہ کے خوف سے گر پڑتے ہیں ،',\n",
              " 'افسوس ! تمہارے دلوں میں اس قدر نرمی ، خستگی اور شکستگی بھی نہیں رہی ، اور اللہ تمہارے کاموں سے بے خبر نہیں ۔',\n",
              " 'اے مسلمانو ! کیا تم یہ توقع رکھتے ہو کہ وہ یہودی تم پر یقین کر لیں گے جبکہ ان میں سے ایک گروہ کے لوگ ایسے بھی تھے کہ اللہ کا کلام تورات سنتے پھر اسے سمجھنے کے بعد خود بدل دیتے حالانکہ وہ خوب جانتے تھے کہ حقیقت کیا ہے اور وہ کیا کر رہے ہیں ۔',\n",
              " 'اور ان کا حال تو یہ ہو چکا ہے کہ جب اہلِ ایمان سے ملتے ہیں تو کہتے ہیں : ہم بھی تمہاری طرح حضرت محمد صلی اللہ علیہ وآلہ وسلم پر ایمان لے آئے ہیں ،',\n",
              " 'اور جب آپس میں ایک دوسرے کے ساتھ تنہائی میں ہوتے ہیں تو کہتے ہیں : کیا تم ان مسلمانوں سے نبی آخر الزمان صلی اللہ علیہ وآلہ وسلم کی رسالت اور شان کے بارے میں وہ باتیں بیان کر دیتے ہو جو اللہ نے تم پر تورات کے ذریعے ظاہر کی ہیں تاکہ اس سے وہ تمہارے رب کے حضور تمہیں پر حجت قائم کریں ، کیا تم اتنی عقل بھی نہیں رکھتے ؟ ۔',\n",
              " 'کیا وہ نہیں جانتے کہ اللہ کو وہ سب کچھ معلوم ہے جو وہ چھپاتے ہیں اور جو ظاہر کرتے ہیں ۔',\n",
              " 'اور ان یہود میں سے بعض ان پڑھ بھی ہیں جنہیں سوائے سنی سنائی جھوٹی امیدوں کے کتاب کے معنی و مفہوم کا کوئی علم ہی نہیں وہ کتاب کو صرف زبانی پڑھنا جانتے ہیں یہ لوگ محض وہم و گمان میں پڑے رہتے ہیں ۔',\n",
              " 'پس ایسے لوگوں کے لئے بڑی خرابی ہے جو اپنے ہی ہاتھوں سے کتاب لکھتے ہیں ، پھر کہتے ہیں کہ یہ اللہ کی طرف سے ہے تاکہ اس کے عوض تھوڑے سے دام کما لیں ، سو ان کے لئے اس کتاب کی وجہ سے ہلاکت ہے جو ان کے ہاتھوں نے تحریر کی اور اس معاوضہ کی وجہ سے تباہی ہے جو وہ کما رہے ہیں ۔',\n",
              " 'اور وہ یہود یہ بھی کہتے ہیں کہ ہمیں دوزخ کی آگ ہرگز نہیں چھوئے گی سوائے گنتی کے چند دنوں کے ، ذرا آپ ان سے پوچھیں : کیا تم اللہ سے کوئی ایسا وعدہ لے چکے ہو ؟ پھر تو وہ اپنے وعدے کے خلاف ہرگز نہ کرے گا یا تم اللہ پر یونہی وہ بہتان باندھتے ہو جو تم خود بھی نہیں جانتے ۔',\n",
              " 'ہاں واقعی جس نے برائی اختیار کی اور اس کے گناہوں نے اس کو ہر طرف سے گھیر لیا تو وہی لوگ دوزخی ہیں ، وہ اس میں ہمیشہ رہنے والے ہیں ۔',\n",
              " 'اور جو لوگ ایمان لائے اور انہوں نے نیک عمل کیے تو وہی لوگ جنّتی ہیں ، وہ اس میں ہمیشہ رہنے والے ہیں ۔',\n",
              " 'اور یاد کرو جب ہم نے اولادِ یعقوب سے پختہ وعدہ لیا کہ اللہ کے سوا کسی اور کی عبادت نہ کرنا ، اور ماں باپ کے ساتھ اچھا سلوک کرنا اور قرابت داروں اور یتیموں اور محتاجوں کے ساتھ بھی بھلائی کرنا',\n",
              " 'اور عام لوگوں سے بھی نرمی اور خوش خُلقی کے ساتھ نیکی کی بات کہنا اور نماز قائم رکھنا اور زکوٰۃ دیتے رہنا ،',\n",
              " 'پھر تم میں سے چند لوگوں کے سوا سارے اس عہد سے رُوگرداں ہو گئے اور تم حق سے گریز ہی کرنے والے ہو ۔',\n",
              " 'اور جب ہم نے تم سے یہ پختہ عہد بھی لیا کہ تم آپس میں ایک دوسرے کا خون نہیں بہاؤ گے اور نہ اپنے لوگوں کو اپنے گھروں اور بستیوں سے نکال کر جلاوطن کرو گے پھر تم نے اس امر کا اقرار کر لیا اور تم اس کی گواہی بھی دیتے ہو ۔',\n",
              " 'پھر تم ہی وہ لوگ ہو کہ اپنوں کو قتل کر رہے ہو اور اپنے ہی ایک گروہ کو ان کے وطن سے باہر نکال رہے ہو اور مستزاد یہ کہ ان کے خلاف گناہ اور زیادتی کے ساتھ ان کے دشمنوں کی مدد بھی کرتے ہو ،',\n",
              " 'اور اگر وہ قیدی ہو کر تمہارے پا س آجائیں تو ان کا فدیہ دے کر چھڑا لیتے ہو تاکہ وہ تمہارے احسان مند رہیں حالانکہ ان کا وطن سے نکالا جانا بھی تم پر حرام کر دیا گیا تھا ،',\n",
              " 'کیا تم کتاب کے بعض حصوں پر ایمان رکھتے ہو اور بعض کا انکار کرتے ہو ؟ پس تم میں سے جو شخص ایسا کرے اس کی کیا سزا ہو سکتی ہے سوائے اس کے کہ دنیا کی زندگی میں ذلّت اور رُسوائی ہو ،',\n",
              " 'اور قیامت کے دن بھی ایسے لوگ سخت ترین عذاب کی طرف لوٹائے جائیں گے ، اور اللہ تمہارے کاموں سے بے خبر نہیں ۔',\n",
              " 'یہی وہ لوگ ہیں جنہوں نے آخرت کے بدلے میں دنیا کی زندگی خرید لی ہے ، پس نہ ان پر سے عذاب ہلکا کیا جائے گا اور نہ ہی ان کو مدد دی جائے گی ۔',\n",
              " 'اور بیشک ہم نے موسیٰ علیہ السلام کو کتاب تورات عطا کی اور ان کے بعد ہم نے پے در پے بہت سے پیغمبر بھیجے ،',\n",
              " 'اور ہم نے مریم علیھا السلام کے فرزند عیسیٰ علیہ السلام کو بھی روشن نشانیاں عطا کیں اور ہم نے پاک روح کے ذریعے ان کی تائید اور مدد کی ،',\n",
              " 'تو کیا ہوا جب بھی کوئی پیغمبر تمہارے پاس وہ احکام لایا جنہیں تمہارے نفس پسند نہیں کرتے تھے تو تم وہیں اکڑ گئے اور بعضوں کو تم نے جھٹلایا اور بعضوں کو تم قتل کرنے لگے ۔',\n",
              " 'اور یہودیوں نے کہا : ہمارے دلوں پر غلاف ہیں ، ایسا نہیں بلکہ ان کے کفر کے باعث اللہ نے ان پر لعنت کر دی ہے سو وہ بہت ہی کم ایمان رکھتے ہیں ۔',\n",
              " 'اور جب ان کے پاس اللہ کی طرف سے وہ کتاب قرآن آئی جو اس کتاب تورات کی اصلاً تصدیق کرنے والی ہے جو ان کے پاس موجود تھی ، حالانکہ اس سے پہلے وہ خود نبی آخر الزمان حضرت محمد صلی اللہ علیہ وآلہ وسلم اور ان پر اترنے والی کتاب قرآن کے وسیلے سے کافروں پر فتح یابی کی دعا مانگتے تھے ،',\n",
              " 'سو جب ان کے پاس وہی نبی حضرت محمد صلی اللہ علیہ وآلہ وسلم اپنے اوپر نازل ہونے والی کتاب قرآن کے ساتھ تشریف لے آیا جسے وہ پہلے ہی سے پہچانتے تھے تو اسی کے منکر ہو گئے ، پس ایسے دانستہ انکار کرنے والوں پر اللہ کی لعنت ہے ۔',\n",
              " 'انہوں نے اپنی جانوں کا کیا برا سودا کیا کہ اللہ کی نازل کردہ کتاب کا انکار کر رہے ہیں ، محض اس حسد میں کہ اللہ اپنے فضل سے اپنے بندوں میں سے جس پر چاہتا ہے وحی نازل فرماتا ہے ، پس وہ غضب در غضب کے سزاوار ہوئے ، اور کافروں کے لئے ذلّت انگیز عذاب ہے ۔',\n",
              " 'اور جب ان سے کہا جاتا ہے : اس کتاب پر ایمان لاؤ جسے اللہ نے اب نازل فرمایا ہے ، تو کہتے ہیں : ہم صرف اس کتاب پر ایمان رکھتے ہیں جو ہم پر نازل کی گئی ، اور وہ اس کے علاوہ کا انکار کرتے ہیں ، حالانکہ وہ قرآن بھی حق ہے اور اس کتاب کی بھی تصدیق کرتا ہے جو ان کے پاس ہے ، آپ ان سے دریافت فرمائیں کہ پھر تم اس سے پہلے انبیاء کو کیوں قتل کرتے رہے ہو اگر تم واقعی اپنی ہی کتاب پر ایمان رکھتے ہو ۔',\n",
              " 'اور صورت حال یہ ہے کہ تمہارے پاس خود موسیٰ علیہ السلام کھلی نشانیاں لائے پھر تم نے ان کے پیچھے بچھڑے کو معبود بنا لیا اور تم حقیقت میں ہو ہی جفاکار ۔',\n",
              " 'اور جب ہم نے تم سے پختہ عہد لیا اور ہم نے تمہارے اوپر طور کو اٹھا کھڑا کیا یہ فرما کر کہ اس کتاب کو مضبوطی سے تھامے رکھو جو ہم نے تمہیں عطا کی ہے اور ہمارا حکم سنو ، تو تمہارے بڑوں نے کہا : ہم نے سن لیا مگر مانا نہیں ، اور ان کے دلوں میں ان کے کفر کے باعث بچھڑے کی محبت رچا دی گئی تھی ،',\n",
              " 'اے محبوب ! انہیں بتا دیں یہ باتیں بہت ہی بری ہیں جن کا حکم تمہیں تمہارا نام نہاد ایمان دے رہا ہے اگر تم واقعۃً ان پر ایمان رکھتے ہو ۔',\n",
              " 'آپ فرما دیں : اگر آخرت کا گھر اللہ کے نزدیک صرف تمہارے لئے ہی مخصوص ہے اور لوگوں کے لئے نہیں تو تم بے دھڑک موت کی آرزو کرو اگر تم اپنے خیال میں سچے ہو ۔',\n",
              " 'وہ ہرگز کبھی بھی اس کی آرزو نہیں کریں گے ان گناہوں اور مَظالِم کے باعث جو ان کے ہاتھ آگے بھیج چکے ہیں یا پہلے کر چکے ہیں اور اللہ ظالموں کو خوب جانتا ہے ۔',\n",
              " 'آپ انہیں یقیناً سب لوگوں سے زیادہ جینے کی ہوس میں مبتلا پائیں گے اور یہاں تک کہ مشرکوں سے بھی زیادہ ، ان میں سے ہر ایک چاہتا ہے کہ کاش اسے ہزار برس کی عمر مل جائے ، اگر اسے اتنی عمر مل بھی جائے ، تو بھی یہ اسے عذاب سے بچانے والی نہیں ہو سکتی ، اور اللہ ان کے اعمال کو خوب دیکھ رہا ہے ۔',\n",
              " 'آپ فرما دیں : جو شخص جبریل کا دشمن ہے وہ ظلم کر رہا ہے کیونکہ اس نے تو اس قرآن کو آپ کے دل پر اللہ کے حکم سے اتارا ہے جو اپنے سے پہلے کی کتابوں کی تصدیق کرنے والا ہے اور مؤمنوں کے لئے سراسر ہدایت اور خوشخبری ہے ۔',\n",
              " 'جو شخص اللہ کا اور اس کے فرشتوں اور اس کے رسولوں کا اور جبریل اور میکائیل کا دشمن ہوا تو یقیناً اللہ بھی ان کافروں کا دشمن ہے ۔',\n",
              " 'اور بیشک ہم نے آپ کی طرف روشن آیتیں اتاری ہیں اور ان نشانیوں کا سوائے نافرمانوں کے کوئی انکار نہیں کر سکتا ۔',\n",
              " 'اور کیا ایسا نہیں کہ جب بھی انہوں نے کوئی عہد کیا تو ان میں سے ایک گروہ نے اسے توڑ کر پھینک دیا ، بلکہ ان میں سے اکثر ایمان ہی نہیں رکھتے ۔',\n",
              " 'اور اسی طرح جب ان کے پاس اللہ کی جانب سے رسول حضرت محمد صلی اللہ علیہ وآلہ وسلم آئے جو اس کتاب کی اصلاً تصدیق کرنے والے ہیں جو ان کے پاس پہلے سے موجود تھی تو انہی اہلِ کتاب میں سے ایک گروہ نے اللہ کی اسی کتاب تورات کو پسِ پشت پھینک دیا ، گویا وہ اس کو جانتے ہی نہیں',\n",
              " 'حالانکہ اسی تورات نے انہیں نبی آخرالزماں حضرت محمد صلی اللہ علیہ وآلہ وسلم کی تشریف آوری کی خبر دی تھی ۔',\n",
              " 'اور وہ یہود تو اس چیز یعنی جادو کے پیچھے بھی لگ گئے تھے جو سلیمان علیہ السلام کے عہدِ حکومت میں شیاطین پڑھا کرتے تھے',\n",
              " 'حالانکہ سلیمان علیہ السلام نے کوئی کفر نہیں کیا',\n",
              " 'بلکہ کفر تو شیطانوں نے کیا',\n",
              " 'جو لوگوں کو جادو سکھاتے تھے اور اس جادو کے علم کے پیچھے بھی لگ گئے جو شہر بابل میں ہاروت اور ماروت نامی دو فرشتوں پر اتارا گیا تھا',\n",
              " 'وہ دونوں کسی کو کچھ نہ سکھاتے تھے یہاں تک کہ کہہ دیتے کہ ہم تو محض آزمائش کے لئے ہیں سو تم اس پر اعتقاد رکھ کر کافر نہ بنو ،',\n",
              " 'اس کے باوجود وہ یہودی ان دونوں سے ایسا منتر سیکھتے تھے جس کے ذریعے شوہر اور اس کی بیوی کے درمیان جدائی ڈال دیتے ،',\n",
              " 'حالانکہ وہ اس کے ذریعے کسی کو بھی نقصان نہیں پہنچا سکتے مگر اللہ ہی کے حکم سے',\n",
              " 'اور یہ لوگ وہی چیزیں سیکھتے ہیں جو ان کے لئے ضرر رساں ہیں اور انہیں نفع نہیں پہنچاتیں',\n",
              " 'اور انہیں یہ بھی یقینا معلوم تھا کہ جو کوئی اس کفر یا جادو ٹونے کا خریدار بنا اس کے لئے آخرت میں کوئی حصہ نہیں ہوگا ،',\n",
              " 'اور وہ بہت ہی بری چیز ہے جس کے بدلے میں انہوں نے اپنی جانوں کی حقیقی بہتری یعنی اُخروی فلاح کو بیچ ڈالا ،',\n",
              " 'کاش ! وہ اس سودے کی حقیقت کو جانتے ۔',\n",
              " 'اور اگر وہ ایمان لے آتے اور پرہیزگاری اختیار کرتے تو اللہ کی بارگاہ سے تھوڑا سا ثواب بھی ان سب چیزوں سے کہیں بہتر ہوتا ، کاش ! وہ اس راز سے آگاہ ہوتے ۔',\n",
              " 'اے ایمان والو ! نبی اکرم صلی اللہ علیہ وآلہ وسلم کو اپنی طرف متوجہ کرنے کے لئے رَاعِنَا مت کہا کرو بلکہ ادب سے اُنْظُرْنَا ہماری طرف نظرِ کرم فرمائیے کہا کرو اور ان کا ارشاد بغور سنتے رہا کرو ، اور کافروں کے لئے دردناک عذاب ہے ۔',\n",
              " 'نہ وہ لوگ جو اہلِ کتاب میں سے کافر ہو گئے اور نہ ہی مشرکین اسے پسند کرتے ہیں کہ تمہارے رب کی طرف سے تم پر کوئی بھلائی اترے ، اور اللہ جسے چاہتا ہے اپنی رحمت کے ساتھ خاص کر لیتا ہے ، اور اللہ بڑے فضل والا ہے ۔',\n",
              " 'ہم جب کوئی آیت منسوخ کر دیتے ہیں یا اسے فراموش کرا دیتے ہیں تو بہرصورت اس سے بہتر یا ویسی ہی کوئی اور آیت لے آتے ہیں ، کیا تم نہیں جانتے کہ اللہ ہر چیز پر کامل قدرت رکھتا ہے ۔',\n",
              " 'کیا تمہیں معلوم نہیں کہ آسمانوں اور زمین کی بادشاہت اللہ ہی کے لئے ہے ، اور اللہ کے سوا نہ تمہارا کوئی دوست ہے اور نہ ہی مددگار ۔',\n",
              " 'اے مسلمانو ! کیا تم چاہتے ہو کہ تم بھی اپنے رسول صلی اللہ علیہ وآلہ وسلم سے اسی طرح سوالات کرو جیسا کہ اس سے پہلے موسیٰ علیہ السلام سے سوال کیے گئے تھے ، تو جو کوئی ایمان کے بدلے کفر حاصل کرے پس وہ واقعۃً سیدھے راستے سے بھٹک گیا ۔',\n",
              " 'بہت سے اہلِ کتاب کی یہ خواہش ہے تمہارے ایمان لے آنے کے بعد پھر تمہیں کفر کی طرف لوٹا دیں ، اس حسد کے باعث جو ان کے دلوں میں ہے اس کے باوجود کہ ان پر حق خوب ظاہر ہو چکا ہے ، سو تم درگزر کرتے رہو اور نظرانداز کرتے رہو یہاں تک کہ اللہ اپنا حکم بھیج دے ، بیشک اللہ ہر چیز پر کامل قدرت رکھتا ہے ۔',\n",
              " 'اور نماز قائم کیا کرو اور زکوٰۃ دیتے رہا کرو ، اور تم اپنے لئے جو نیکی بھی آگے بھیجو گے اسے اللہ کے حضور پا لو گے ، جو کچھ تم کر رہے ہو یقینا اللہ اسے دیکھ رہا ہے ۔',\n",
              " 'اور اہلِ کتاب کہتے ہیں کہ جنت میں ہرگز کوئی بھی داخل نہیں ہوگا سوائے اس کے کہ وہ یہودی ہو یا نصرانی ، یہ ان کی باطل امیدیں ہیں ، آپ فرما دیں کہ اگر تم اپنے دعوے میں سچے ہو تو اپنی اس خواہش پر سند لاؤ ۔',\n",
              " 'ہاں ، جس نے اپنا چہرہ اﷲ کے لئے جھکا دیا یعنی خود کو اﷲ کے سپرد کر دیا اور وہ صاحبِ اِحسان ہو گیا تو اس کے لئے اس کا اجر اس کے رب کے ہاں ہے اور ایسے لوگوں پر نہ کوئی خوف ہو گا اورنہ وہ رنجیدہ ہوں گے ۔',\n",
              " 'اور یہود کہتے ہیں کہ نصرانیوں کی بنیاد کسی شے یعنی صحیح عقیدے پر نہیں اور نصرانی کہتے ہیں کہ یہودیوں کی بنیاد کسی شے پر نہیں ، حالانکہ وہ سب اللہ کی نازل کردہ کتاب پڑھتے ہیں ،',\n",
              " 'اسی طرح وہ مشرک لوگ جن کے پاس سرے سے کوئی آسمانی علم ہی نہیں وہ بھی انہی جیسی بات کرتے ہیں ،',\n",
              " 'پس اللہ ان کے درمیان قیامت کے دن اس معاملے میں خود ہی فیصلہ فرما دے گا جس میں وہ اختلاف کرتے رہتے ہیں ۔',\n",
              " 'اور اس شخص سے بڑھ کر کون ظالم ہوگا جو اللہ کی مسجدوں میں اس کے نام کا ذکر کیے جانے سے روک دے اور انہیں ویران کرنے کی کوشش کرے ! انہیں ایسا کرنا مناسب نہ تھا کہ مسجدوں میں داخل ہوتے مگر ڈرتے ہوئے ، ان کے لئے دنیا میں بھی ذلّت ہے اور ان کے لئے آخرت میں بھی بڑا عذاب ہے ۔',\n",
              " 'اور مشرق و مغرب سب اللہ ہی کا ہے ، پس تم جدھر بھی رخ کرو ادھر ہی اللہ کی توجہ ہے یعنی ہر سمت ہی اللہ کی ذات جلوہ گر ہے ، بیشک اللہ بڑی وسعت والا سب کچھ جاننے والا ہے ۔',\n",
              " 'اور وہ کہتے ہیں : اللہ نے اپنے لئے اولاد بنائی ہے ، حالانکہ وہ اس سے پاک ہے ، بلکہ جو کچھ آسمانوں اور زمین میں ہے سب اسی کی خَلق اور مِلک ہے ، اور سب کے سب اس کے فرماں بردار ہیں ۔',\n",
              " 'وہی آسمانوں اور زمین کو وجود میں لانے والا ہے ، اور جب کسی چیز کے ایجاد کا فیصلہ فرما لیتا ہے تو پھر اس کو صرف یہی فرماتا ہے کہ \" تو ہو جا \" پس وہ ہوجاتی ہے ۔',\n",
              " 'اور جو لوگ علم نہیں رکھتے کہتے ہیں کہ اللہ ہم سے کلام کیوں نہیں فرماتا یا ہمارے پاس براہِ راست کوئی نشانی کیوں نہیں آتی ؟ اسی طرح ان سے پہلے لوگوں نے بھی انہی جیسی بات کہی تھی ، ان سب لوگوں کے دل آپس میں ایک جیسے ہیں ، بیشک ہم نے یقین والوں کے لئے نشانیاں خوب واضح کر دی ہیں ۔',\n",
              " 'اے محبوبِ مکرّم ! بیشک ہم نے آپ کو حق کے ساتھ خوشخبری سنانے والا اور ڈر سنانے والا بنا کر بھیجا ہے اور اہلِ دوزخ کے بارے میں آپ سے پرسش نہیں کی جائے گی ۔',\n",
              " 'اور یہود و نصارٰی آپ سے اس وقت تک ہرگز خوش نہیں ہوں گے جب تک آپ ان کے مذہب کی پیروی اختیار نہ کر لیں ، آپ فرما دیں کہ بیشک اللہ کی عطا کردہ ہدایت ہی حقیقی ہدایت ہے ،',\n",
              " 'امت کی تعلیم کے لئے فرمایا : اور اگر بفرضِ محال آپ نے اس علم کے بعد جو آپ کے پاس اللہ کی طرف سے آچکا ہے ، ان کی خواہشات کی پیروی کی تو آپ کے لئے اللہ سے بچانے والا نہ کوئی دوست ہوگا اور نہ کوئی مددگار ۔',\n",
              " 'ایسے لوگ بھی ہیں جنہیں ہم نے کتاب دی وہ اسے اس طرح پڑھتے ہیں جیسے پڑھنے کا حق ہے ، وہی لوگ اس کتاب پر ایمان رکھتے ہیں ، اور جو اس کا انکار کر رہے ہیں سو وہی لوگ نقصان اٹھانے والے ہیں ۔',\n",
              " 'اے اولادِ یعقوب ! میری اس نعمت کو یاد کرو جو میں نے تم پر ارزانی فرمائی اور خصوصاً یہ کہ میں نے تمہیں اس زمانے کے تمام لوگوں پر فضیلت عطا کی ۔',\n",
              " 'اور اس دن سے ڈرو جب کوئی جان کسی دوسری جان کی جگہ کوئی بدلہ نہ دے سکے گی اور نہ اس کی طرف سے اپنے آپ کو چھڑانے کے لیے کوئی معاوضہ قبول کیا جائے گا اور نہ اس کو اِذنِ الٰہی کے بغیر کوئی سفارش ہی فائدہ پہنچا سکے گی اور نہ اَمرِِ الٰہی کے خلاف انہیں کوئی مدد دی جا سکے گی ۔',\n",
              " 'اور وہ وقت یاد کرو جب ابراہیم علیہ السلام کو ان کے رب نے کئی باتوں میں آزمایا تو انہوں نے وہ پوری کر دیں ، اس پر اللہ نے فرمایا : میں تمہیں لوگوں کا پیشوا بناؤں گا ، انہوں نے عرض کیا : کیا میری اولاد میں سے بھی ؟ ارشاد ہوا : ہاں ! مگر میرا وعدہ ظالموں کو نہیں پہنچتا ۔',\n",
              " 'اور یاد کرو جب ہم نے اس گھر خانہ کعبہ کو لوگوں کے لئے رجوع اور اجتماع کا مرکز اور جائے امان بنا دیا ، اور حکم دیا کہ ابراہیم علیہ السلام کے کھڑے ہونے کی جگہ کو مقامِ نماز بنا لو ، اور ہم نے ابراہیم اور اسماعیل علیھما السلام کو تاکید فرمائی کہ میرے گھر کو طواف کرنے والوں اور اعتکاف کرنے والوں اور رکوع و سجود کرنے والوں کے لئے پاک صاف کر دو ۔',\n",
              " 'اور جب ابراہیم علیہ السلام نے عرض کیا : اے میرے رب ! اسے امن والا شہر بنا دے اور اس کے باشندوں کو طرح طرح کے پھلوں سے نواز یعنی ان لوگوں کو جو ان میں سے اللہ پر اور یومِ آخرت پر ایمان لائے ، اللہ نے فرمایا : اور جو کوئی کفر کرے گا اس کو بھی زندگی کی تھوڑی مدت کے لئے فائدہ پہنچاؤں گا پھر اسے اس کے کفر کے باعث دوزخ کے عذاب کی طرف جانے پر مجبور کر دوں گا اور وہ بہت بری جگہ ہے ۔',\n",
              " 'اور یاد کرو جب ابراہیم اور اسماعیل علیھما السلام خانہ کعبہ کی بنیادیں اٹھا رہے تھے تو دونوں دعا کر رہے تھے کہ اے ہمارے رب ! تو ہم سے یہ خدمت قبول فرما لے ، بیشک تو خوب سننے والا خوب جاننے والا ہے ۔',\n",
              " 'اے ہمارے رب ! ہم دونوں کو اپنے حکم کے سامنے جھکنے والا بنا اور ہماری اولاد سے بھی ایک امت کو خاص اپنا تابع فرمان بنا اور ہمیں ہماری عبادت اور حج کے قواعد بتا دے اور ہم پر رحمت و مغفرت کی نظر فرما ، بیشک تو ہی بہت توبہ قبول فرمانے والا مہربان ہے ۔',\n",
              " 'اے ہمارے رب ! ان میں انہی میں سے وہ آخری اور برگزیدہ رسول صلی اللہ علیہ وآلہ وسلم مبعوث فرما جو ان پر تیری آیتیں تلاوت فرمائے اور انہیں کتاب اور حکمت کی تعلیم دے کر دانائے راز بنا دے اور ان کے نفوس و قلوب کو خوب پاک صاف کر دے ،',\n",
              " 'بیشک تو ہی غالب حکمت والا ہے ۔',\n",
              " 'اور کون ہے جو ابراہیم علیہ السلام کے دین سے رُوگرداں ہو سوائے اس کے جس نے خود کو مبتلائے حماقت کر رکھا ہو ، اور بیشک ہم نے انہیں ضرور دنیا میں بھی منتخب فرما لیا تھا اور یقیناً وہ آخرت میں بھی بلند رتبہ مقرّبین میں ہوں گے ۔',\n",
              " 'اور جب ان کے رب نے ان سے فرمایا : میرے سامنے گردن جھکا دو ، تو عرض کرنے لگے : میں نے سارے جہانوں کے رب کے سامنے سرِ تسلیم خم کر دیا ۔',\n",
              " 'اور ابراہیم علیہ السلام نے اپنے بیٹوں کو اسی بات کی وصیت کی اور یعقوب علیہ السلام نے بھی یہی کہا : اے میرے لڑکو ! بیشک اللہ نے تمہارے لئے یہی دین اسلام پسند فرمایا ہے سو تم بہرصورت مسلمان رہتے ہوئے ہی مرنا ۔',\n",
              " 'کیا تم اس وقت حاضر تھے جب یعقوب علیہ السلام کو موت آئی ، جب انہوں نے اپنے بیٹوں سے پوچھا : تم میرے انتقال کے بعد کس کی عبادت کرو گے ؟ تو انہوں نے کہا : ہم آپ کے معبود اور آپ کے باپ دادا ابراہیم اور اسماعیل اور اسحٰق علیھم السلام کے معبود کی عبادت کریں گے جو معبودِ یکتا ہے ، اور ہم سب اسی کے فرماں بردار رہیں گے ۔',\n",
              " 'وہ ایک امت تھی جو گزر چکی ، ان کے لئے وہی کچھ ہوگا جو انہوں نے کمایا اور تمہارے لئے وہ ہوگا جو تم کماؤ گے اور تم سے ان کے اعمال کی باز پُرس نہ کی جائے گی ۔',\n",
              " 'اور اہلِ کتاب کہتے ہیں : یہودی یا نصرانی ہو جاؤ ہدایت پا جاؤ گے ، آپ فرما دیں کہ نہیں بلکہ ہم تو اس ابراہیم علیہ السلام کا دین اختیار کیے ہوئے ہیں جو ہر باطل سے جدا صرف اللہ کی طرف متوجہ تھے ، اور وہ مشرکوں میں سے نہ تھے ۔',\n",
              " 'اے مسلمانو ! تم کہہ دو : ہم اللہ پر ایمان لائے اور اس کتاب پر جو ہماری طرف اتاری گئی اور اس پر بھی جو ابراہیم اور اسماعیل اور اسحٰق اور یعقوب علیھم السلام اور ان کی اولاد کی طرف اتاری گئی اور ان کتابوں پر بھی جو موسیٰ اور عیسیٰ علیھما السلام کو عطا کی گئیں اور اسی طرح جو دوسرے انبیاء علیھم السلام کو ان کے رب کی طرف سے عطا کی گئیں ،',\n",
              " 'ہم ان میں سے کسی ایک پر بھی ایمان میں فرق نہیں کرتے ، اور ہم اسی معبودِ واحد کے فرماں بردار ہیں ۔',\n",
              " 'پھر اگر وہ بھی اسی طرح ایمان لائیں جیسے تم اس پر ایمان لائے ہو تو وہ واقعی ہدایت پا جائیں گے ، اور اگر وہ منہ پھیر لیں تو سمجھ لیں کہ وہ محض مخالفت میں ہیں ، پس اب اللہ آپ کو ان کے شر سے بچانے کے لئے کافی ہوگا ، اور وہ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'کہہ دو : ہم اللہ کے رنگ میں رنگے گئے ہیں اور کس کا رنگ اللہ کے رنگ سے بہتر ہے اور ہم تو اسی کے عبادت گزار ہیں ۔',\n",
              " 'فرما دیں : کیا تم اللہ کے بارے میں ہم سے جھگڑا کرتے ہو حالانکہ وہ ہمارا بھی رب ہے ، اور تمہارا بھی رب ہے اور ہمارے لئے ہمارے اعمال اور تمہارے لئے تمہارے اعمال ہیں ، اور ہم تو خالصۃً اسی کے ہو چکے ہیں ۔',\n",
              " 'اے اہلِ کتاب ! کیا تم یہ کہتے ہو کہ ابراہیم اور اسماعیل اور اسحٰق اور یعقوب علیھم السلام اور ان کے بیٹے یہودی یا نصرانی تھے ، فرما دیں : کیا تم زیادہ جانتے ہو یا اللہ ؟ اور اس سے بڑھ کر ظالم کون ہوگا جو اس گواہی کو چھپائے جو اس کے پاس اللہ کی طرف سے کتاب میں موجود ہے ، اور اللہ تمہارے کاموں سے بے خبر نہیں ۔',\n",
              " 'وہ ایک جماعت تھی جو گزر چکی ، جو اس نے کمایا وہ اس کے لئے تھا اور جو تم کماؤ گے وہ تمہارے لئے ہوگا ، اور تم سے ان کے اعمال کی نسبت نہیں پوچھا جائے گا ۔',\n",
              " 'اَب بیوقوف لوگ یہ کہیں گے کہ ان مسلمانوں کو اپنے اس قبلہ بیت المقدس سے کس نے پھیر دیا جس پر وہ پہلے سے تھے ، آپ فرما دیں : مشرق و مغرب سب اﷲ ہی کے لئے ہے ، وہ جسے چاہتا ہے سیدھی راہ پر ڈال دیتا ہے ۔',\n",
              " 'اور اے مسلمانو ! اسی طرح ہم نے تمہیں اعتدال والی بہتر امت بنایا تاکہ تم لوگوں پر گواہ بنو اور ہمارا یہ برگزیدہ رسول صلی اللہ علیہ وآلہ وسلم تم پر گواہ ہو ،',\n",
              " 'اور آپ پہلے جس قبلہ پر تھے ہم نے صرف اس لئے مقرر کیا تھا کہ ہم پرکھ کر ظاہر کر دیں کہ کون ہمارے رسول صلی اللہ علیہ وآلہ وسلم کی پیروی کرتا ہے اور کون اپنے الٹے پاؤں پھر جاتا ہے ،',\n",
              " 'اور بیشک یہ قبلہ کا بدلنا بڑی بھاری بات تھی مگر ان پر نہیں جنہیں اﷲ نے ہدایت و معرفت سے نوازا ، اور اﷲ کی یہ شان نہیں کہ تمہارا ایمان یونہی ضائع کردے ، بیشک اﷲ لوگوں پر بڑی شفقت فرمانے والا مہربان ہے ۔',\n",
              " 'اے حبیب ! ہم بار بار آپ کے رُخِ انور کا آسمان کی طرف پلٹنا دیکھ رہے ہیں ، سو ہم ضرور بالضرور آپ کو اسی قبلہ کی طرف پھیر دیں گے جس پر آپ راضی ہیں ، پس آپ اپنا رخ ابھی مسجدِ حرام کی طرف پھیر لیجئے ، اور اے مسلمانو ! تم جہاں کہیں بھی ہو پس اپنے چہرے اسی کی طرف پھیر لو ،',\n",
              " 'اور وہ لوگ جنہیں کتاب دی گئی ہے ضرور جانتے ہیں کہ یہ تحویلِ قبلہ کا حکم ان کے رب کی طرف سے حق ہے ،',\n",
              " 'اور اﷲ ان کاموں سے بے خبر نہیں جو وہ انجام دے رہے ہیں ۔',\n",
              " 'اوراگر آپ اہلِ کتاب کے پاس ہر ایک نشانی بھی لے آئیں تب بھی وہ آپ کے قبلہ کی پیروی نہیں کریں گے اور نہ آپ ہی ان کے قبلہ کی پیروی کرنے والے ہیں',\n",
              " 'اور وہ آپس میں بھی ایک دوسرے کے قبلہ کی پیروی نہیں کرتے ،',\n",
              " 'امت کی تعلیم کے لئے فرمایا : اور اگر بفرضِ محال آپ نے بھی اپنے پاس علم آجانے کے بعد ان کی خواہشات کی پیروی کی تو بیشک آپ اپنی جان پر زیادتی کرنے والوں میں سے ہو جائیں گے ۔',\n",
              " 'اور جن لوگوں کو ہم نے کتاب عطا فرمائی ہے وہ اس رسول آخر الزماں حضرت محمد صلی اللہ علیہ وآلہ وسلم اور ان کی شان و عظمت کو اسی طرح پہچانتے ہیں جیسا کہ بلاشبہ اپنے بیٹوں کو پہچانتے ہیں ،',\n",
              " 'اور یقیناً انہی میں سے ایک طبقہ حق کو جان بوجھ کر چھپا رہا ہے ۔',\n",
              " 'اے سننے والے ! حق تیرے رب کی طرف سے ہے سو تو ہرگز شک کرنے والوں میں سے نہ ہو ۔',\n",
              " 'اور ہر ایک کے لئے توجہ کی ایک سمت مقرر ہے وہ اسی کی طرف رُخ کرتا ہے پس تم نیکیوں کی طرف پیش قدمی کیا کرو ، تم جہاں کہیں بھی ہوگے اﷲ تم سب کو جمع کر لے گا ، بیشک اﷲ ہر چیز پر خوب قادر ہے ۔',\n",
              " 'اور تم جدھر سے بھی سفر پر نکلو اپنا چہرہ نماز کے وقت مسجدِ حرام کی طرف پھیر لو ، اور یہی تمہارے رب کی طرف سے حق ہے ، اور اﷲ تمہارے اعمال سے بے خبر نہیں ۔',\n",
              " 'اور تم جدھر سے بھی سفر پر نکلو اپنا چہرہ نماز کے وقت مسجدِ حرام کی طرف پھیر لو ، اور اے مسلمانو ! تم جہاں کہیں بھی ہو سو اپنے چہرے اسی کی سمت پھیر لیا کرو تاکہ لوگوں کے پاس تم پر اعتراض کرنے کی گنجائش نہ رہے سوائے ان لوگوں کے جو ان میں حد سے بڑھنے والے ہیں ، پس تم ان سے مت ڈرو مجھ سے ڈرا کرو ، اس لئے کہ میں تم پر اپنی نعمت پوری کردوں اور تاکہ تم کامل ہدایت پا جاؤ ۔',\n",
              " 'اسی طرح ہم نے تمہارے اندر تمہیں میں سے اپنا رسول بھیجا جو تم پر ہماری آیتیں تلاوت فرماتا ہے اور تمہیں نفسًا و قلبًا پاک صاف کرتا ہے اور تمہیں کتاب کی تعلیم دیتا ہے اور حکمت و دانائی سکھاتا ہے اور تمہیں وہ اَسرارِ معرفت و حقیقت سکھاتا ہے جو تم نہ جانتے تھے ۔',\n",
              " 'سو تم مجھے یاد کیا کرو میں تمہیں یاد رکھوں گا اور میرا شکر ادا کیا کرو اور میری ناشکری نہ کیا کرو ۔',\n",
              " 'اے ایمان والو ! صبر اور نماز کے ذریعے مجھ سے مدد چاہا کرو ، یقیناً اﷲ صبر کرنے والوں کے ساتھ ہوتا ہے ۔',\n",
              " 'اور جو لوگ اﷲ کی راہ میں مارے جائیں انہیں مت کہا کرو کہ یہ مُردہ ہیں ، وہ مُردہ نہیں بلکہ زندہ ہیں لیکن تمہیں ان کی زندگی کا شعور نہیں ۔',\n",
              " 'اور ہم ضرور بالضرور تمہیں آزمائیں گے کچھ خوف اور بھوک سے اور کچھ مالوں اور جانوں اور پھلوں کے نقصان سے ، اور اے حبیب ! آپ ان صبر کرنے والوں کو خوشخبری سنا دیں ۔',\n",
              " 'جن پر کوئی مصیبت پڑتی ہے تو کہتے ہیں : بیشک ہم بھی اﷲ ہی کا مال ہیں اور ہم بھی اسی کی طرف پلٹ کر جانے والے ہیں ۔',\n",
              " 'یہی وہ لوگ ہیں جن پر ان کے رب کی طرف سے پے در پے نوازشیں ہیں اور رحمت ہے ، اور یہی لوگ ہدایت یافتہ ہیں ۔',\n",
              " 'بیشک صفا اور مروہ اﷲ کی نشانیوں میں سے ہیں ، چنانچہ جو شخص بیت اﷲ کا حج یا عمرہ کرے تو اس پر کوئی گناہ نہیں کہ ان دونوں کے درمیان چکر لگائے ، اور جو شخص اپنی خوشی سے کوئی نیکی کرے تو یقیناً اﷲ بڑا قدر شناس بڑا خبردار ہے ۔',\n",
              " 'بیشک جو لوگ ہماری نازل کردہ کھلی نشانیوں اور ہدایت کو چھپاتے ہیں اس کے بعد کہ ہم نے اسے لوگوں کے لئے اپنی کتاب میں واضح کردیا ہے تو انہی لوگوں پر اﷲ لعنت بھیجتا ہے یعنی انہیں اپنی رحمت سے دور کرتا ہے اور لعنت بھیجنے والے بھی ان پر لعنت بھیجتے ہیں ۔',\n",
              " 'مگر جو لوگ توبہ کر لیں اور اپنی اصلاح کر لیں اور حق کو ظاہر کر دیں تو میں بھی انہیں معاف فرما دوں گا ، اور میں بڑا ہی توبہ قبول کرنے والا مہربان ہوں ۔',\n",
              " 'بیشک جنہوں نے حق کو چھپا کر کفر کیا اور اس حال میں مرے کہ وہ کافر ہی تھے ان پر اﷲ کی اور فرشتوں کی اور سب لوگوں کی لعنت ہے ۔',\n",
              " 'وہ ہمیشہ اسی لعنت میں گرفتار رہیں گے ، ان پر سے عذاب ہلکا نہیں کیا جائے گا اور نہ ہی انہیں مہلت دی جائے گی ۔',\n",
              " 'اور تمہارا معبود خدائے واحد ہے اس کے سوا کوئی معبود نہیں وہ نہایت مہربان بہت رحم فرمانے والا ہے ۔',\n",
              " 'بیشک آسمانوں اور زمین کی تخلیق میں اور رات دن کی گردش میں اور ان جہازوں اور کشتیوں میں جو سمندر میں لوگوں کو نفع پہنچانے والی چیزیں اٹھا کر چلتی ہیں',\n",
              " 'اور اس بارش کے پانی میں جسے اﷲ آسمان کی طرف سے اتارتا ہے پھر اس کے ذریعے زمین کو مُردہ ہو جانے کے بعد زندہ کرتا ہے وہ زمین جس میں اس نے ہر قسم کے جانور پھیلا دیئے ہیں اور ہواؤں کے رُخ بدلنے میں اور اس بادل میں جو آسمان اور زمین کے درمیان حکمِ الٰہی کا پابند ہو کر چلتا ہے',\n",
              " 'ان میں عقلمندوں کے لئے قدرتِ الٰہی کی بہت سی نشانیاں ہیں ۔',\n",
              " 'اور لوگوں میں بعض ایسے بھی ہیں جو اﷲ کے غیروں کو اﷲ کا شریک ٹھہراتے ہیں اور ان سے ” اﷲ سے محبت “ جیسی محبت کرتے ہیں ، اور جو لوگ ایمان والے ہیں وہ ہر ایک سے بڑھ کر اﷲ سے بہت ہی زیادہ محبت کرتے ہیں ، اور اگر یہ ظالم لوگ اس وقت کو دیکھ لیں جب اُخروی عذاب ان کی آنکھوں کے سامنے ہوگا توجان لیں کہ ساری قوتوں کا مالک اﷲ ہے اور بیشک اﷲ سخت عذاب دینے والا ہے ۔',\n",
              " 'اور جب وہ پیشوایانِ کفر جن کی پیروی کی گئی اپنے پیروکاروں سے بے زار ہوں گے اور وہ سب اﷲ کا عذاب دیکھ لیں گے اور سارے اسباب ان سے منقطع ہو جائیں گے ۔',\n",
              " 'اور یہ بے زاری دیکھ کر مشرک پیروکار کہیں گے : کاش ! ہمیں دنیا میں جانے کا ایک موقع مل جائے تو ہم بھی ان سے بے زاری ظاہر کردیں جیسے انہوں نے آج ہم سے بے زاری ظاہر کی ہے ، یوں اﷲ انہیں ان کے اپنے اعمال انہی پر حسرت بنا کر دکھائے گا ، اور وہ کسی صورت بھی دوزخ سے نکلنے نہ پائیں گے ۔',\n",
              " 'اے لوگو ! زمین کی چیزوں میں سے جو حلال اور پاکیزہ ہے کھاؤ ، اور شیطان کے راستوں پر نہ چلو ، بیشک وہ تمہارا کھلا دشمن ہے ۔',\n",
              " 'وہ تمہیں بدی اور بے حیائی کا ہی حکم دیتا ہے اور یہ بھی کہ تم اﷲ کی نسبت وہ کچھ کہو جس کا تمہیں خود علم نہ ہو ۔',\n",
              " 'اور جب ان کافروں سے کہا جاتا ہے کہ جو اﷲ نے نازل فرمایا ہے اس کی پیروی کرو تو کہتے ہیں : نہیں بلکہ ہم تو اسی روش پر چلیں گے جس پر ہم نے اپنے باپ دادا کو پایا ہے ، اگرچہ ان کے باپ دادا نہ کچھ عقل رکھتے ہوں اور نہ ہی ہدایت پر ہوں ۔',\n",
              " 'اور ان کافروں کو ہدایت کی طرف بلانے کی مثال ایسے شخص کی سی ہے جو کسی ایسے جانور کو پکارے جو سوائے پکار اور آواز کے کچھ نہیں سنتا ، یہ لوگ بہرے ، گونگے ، اندھے ہیں سو انہیں کوئی سمجھ نہیں ۔',\n",
              " 'اے ایمان والو ! ان پاکیزہ چیزوں میں سے کھاؤ جو ہم نے تمہیں عطا کی ہیں اور اﷲ کا شکر ادا کرو اگر تم صرف اسی کی بندگی بجا لاتے ہو ۔',\n",
              " 'اس نے تم پر صرف مُردار اور خون اور سؤر کا گوشت اور وہ جانور جس پر ذبح کے وقت غیر اﷲ کا نام پکارا گیا ہو حرام کیا ہے ، پھر جو شخص سخت مجبور ہو جائے نہ تو نافرمانی کرنے والا ہو اور نہ حد سے بڑھنے والا تو اس پر زندگی بچانے کی حد تک کھا لینے میں کوئی گناہ نہیں ، بیشک اﷲ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'بیشک جو لوگ کتابِ تورات کی ان آیتوں کو جو اﷲ نے نازل فرمائی ہیں چھپاتے ہیں اور اس کے بدلے حقیر قیمت حاصل کرتے ہیں ، وہ لوگ سوائے اپنے پیٹوں میں آگ بھرنے کے کچھ نہیں کھاتے اور اﷲ قیامت کے روز ان سے کلام تک نہیں فرمائے گا اور نہ ہی ان کو پاک کرے گا ، اور ان کے لئے درد ناک عذاب ہے ۔',\n",
              " 'یہی وہ لوگ ہیں جنہوں نے ہدایت کے بدلے گمراہی خریدی اور مغفرت کے بدلے عذاب ، کس چیز نے انہیں دوزخ کی آگ پر صبر کرنے والا بنا دیا ہے ۔',\n",
              " 'یہ اس وجہ سے ہے کہ اﷲ نے کتاب حق کے ساتھ نازل فرمائی ، اور بیشک جنہوں نے کتاب میں اختلاف ڈالا وہ مخالفت میں حق سے بہت دور جا پڑے ہیں ۔',\n",
              " 'نیکی صرف یہی نہیں کہ تم اپنے منہ مشرق اور مغرب کی طرف پھیر لو بلکہ اصل نیکی تو یہ ہے کہ کوئی شخص اﷲ پر اور قیامت کے دن پر اور فرشتوں پر اور اﷲ کی کتاب پر اور پیغمبروں پر ایمان لائے ،',\n",
              " 'اور اﷲ کی محبت میں اپنا مال قرابت داروں پر اور یتیموں پر اور محتاجوں پر اور مسافروں پر اور مانگنے والوں پر اور غلاموں کی گردنوں کو آزاد کرانے میں خرچ کرے ، اور نماز قائم کرے اور زکوٰۃ دے',\n",
              " 'اور جب کوئی وعدہ کریں تو اپنا وعدہ پورا کرنے والے ہوں ، اور سختی تنگدستی میں اور مصیبت بیماری میں اور جنگ کی شدّت جہاد کے وقت صبر کرنے والے ہوں ،',\n",
              " 'یہی لوگ سچے ہیں اور یہی پرہیزگار ہیں ۔',\n",
              " 'اے ایمان والو ! تم پر ان کے خون کا بدلہ قصاص فرض کیا گیا ہے جو ناحق قتل کئے جائیں ، آزاد کے بدلے آزاد اور غلام کے بدلے غلام اور عورت کے بدلے عورت ،',\n",
              " 'پھر اگر اس کو یعنی قاتل کو اس کے بھائی یعنی مقتول کے وارث کی طرف سے کچھ یعنی قصاص معاف کر دیا جائے تو چاہئے کہ بھلے دستور کے موافق پیروی کی جائے اور خون بہا کو اچھے طریقے سے اس مقتول کے وارث تک پہنچا دیا جائے ،',\n",
              " 'یہ تمہارے رب کی طرف سے رعایت اور مہربانی ہے ، پس جو کوئی اس کے بعد زیادتی کرے تو اس کے لئے دردناک عذاب ہے ۔',\n",
              " 'اور تمہارے لئے قصاص یعنی خون کا بدلہ لینے میں ہی زندگی کی ضمانت ہے اے عقلمند لوگو ! تاکہ تم خوں ریزی اور بربادی سے بچو ۔',\n",
              " 'تم پر فرض کیا جاتاہے کہ جب تم میں سے کسی کی موت قریب آپہنچے اگر اس نے کچھ مال چھوڑا ہو ، تو اپنے والدین اور قریبی رشتہ داروں کے حق میں بھلے طریقے سے وصیت کرے ، یہ پرہیزگاروں پر لازم ہے ۔',\n",
              " 'پھر جس شخص نے اس وصیّت کو سننے کے بعد اسے بدل دیا تو اس کا گناہ انہی بدلنے والوں پر ہے ، بیشک اﷲ بڑا سننے والا خوب جاننے والا ہے ۔',\n",
              " 'پس اگر کسی شخص کو وصیّت کرنے والے سے کسی کی طرف داری یا کسی کے حق میں زیادتی کا اندیشہ ہو پھر وہ ان کے درمیان صلح کرادے تو اس پر کوئی گناہ نہیں ، بیشک اﷲ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'اے ایمان والو ! تم پر اسی طرح روزے فرض کئے گئے ہیں جیسے تم سے پہلے لوگوں پر فرض کئے گئے تھے تاکہ تم پرہیزگار بن جاؤ ۔',\n",
              " 'یہ گنتی کے چند دن ہیں ، پس اگر تم میں سے کوئی بیمار ہو یا سفر پر ہو تو دوسرے دنوں کے روزوں سے گنتی پوری کر لے ، اور جنہیں اس کی طاقت نہ ہو ان کے ذمے ایک مسکین کے کھانے کا بدلہ ہے ، پھر جو کوئی اپنی خوشی سے زیادہ نیکی کرے تو وہ اس کے لئے بہتر ہے ، اور تمہارا روزہ رکھ لینا تمہارے لئے بہتر ہے اگر تمہیں سمجھ ہو ۔',\n",
              " 'رمضان کا مہینہ وہ ہے جس میں قرآن اتارا گیا ہے جو لوگوں کے لئے ہدایت ہے اور جس میں رہنمائی کرنے والی اور حق و باطل میں امتیاز کرنے والی واضح نشانیاں ہیں ، پس تم میں سے جو کوئی اس مہینہ کو پا لے تو وہ اس کے روزے ضرور رکھے اور جو کوئی بیمار ہو یا سفر پر ہو تو دوسرے دنوں کے روزوں سے گنتی پوری کرے ،',\n",
              " 'اﷲ تمہارے حق میں آسانی چاہتا ہے اور تمہارے لئے دشواری نہیں چاہتا ، اور اس لئے کہ تم گنتی پوری کر سکو اور اس لئے کہ اس نے تمہیں جو ہدایت فرمائی ہے اس پر اس کی بڑائی بیان کرو اور اس لئے کہ تم شکر گزار بن جاؤ ۔',\n",
              " 'اور اے حبیب ! جب میرے بندے آپ سے میری نسبت سوال کریں تو بتا دیا کریں کہ میں نزدیک ہوں ، میں پکارنے والے کی پکار کا جواب دیتا ہوں جب بھی وہ مجھے پکارتا ہے ، پس انہیں چاہئے کہ میری فرمانبرداری اختیار کریں اور مجھ پر پختہ یقین رکھیں تاکہ وہ راہِ مراد پاجائیں ۔',\n",
              " 'تمہارے لئے روزوں کی راتوں میں اپنی بیویوں کے پاس جانا حلال کر دیا گیا ہے ،',\n",
              " 'وہ تمہاری پوشاک ہیں اور تم ان کی پوشاک ہو ،',\n",
              " 'اﷲ کو معلوم ہے کہ تم اپنے حق میں خیانت کرتے تھے',\n",
              " 'سو اس نے تمہارے حال پر رحم کیا اور تمہیں معاف فرما دیا ،',\n",
              " 'پس اب روزوں کی راتوں میں بیشک ان سے مباشرت کیا کرو اور جو اﷲ نے تمہارے لئے لکھ دیا ہے چاہا کرو',\n",
              " 'اور کھاتے پیتے رہا کرو یہاں تک کہ تم پر صبح کا سفید ڈورا رات کے سیاہ ڈورے سے الگ ہو کر نمایاں ہو جائے ،',\n",
              " 'پھر روزہ رات کی آمد تک پورا کرو ،',\n",
              " 'اور عورتوں سے اس دوران شب باشی نہ کیا کرو جب تم مسجدوں میں اعتکاف بیٹھے ہو ،',\n",
              " 'یہ اﷲ کی قائم کردہ حدیں ہیں پس ان کے توڑنے کے نزدیک نہ جاؤ ،',\n",
              " 'اسی طرح اﷲ لوگوں کے لئے اپنی آیتیں کھول کر بیان فرماتا ہے تاکہ وہ پرہیزگاری اختیار کریں ۔',\n",
              " 'اور تم ایک دوسرے کے مال آپس میں ناحق نہ کھایا کرو اور نہ مال کو بطورِ رشوت حاکموں تک پہنچایا کرو کہ یوں لوگوں کے مال کا کچھ حصہ تم بھی ناجائز طریقے سے کھا سکو حالانکہ تمہارے علم میں ہو کہ یہ گناہ ہے ۔',\n",
              " 'اے حبیب ! لوگ آپ سے نئے چاندوں کے بارے میں دریافت کرتے ہیں ، فرما دیں : یہ لوگوں کے لئے اور ماہِ حج کے تعیّن کے لئے وقت کی علامتیں ہیں ، اور یہ کوئی نیکی نہیں کہ تم حالتِ احرام میں گھروں میں ان کی پشت کی طرف سے آؤ بلکہ نیکی تو ایسی الٹی رسموں کی بجائے پرہیزگاری اختیار کرنا ہے ، اور تم گھروں میں ان کے دروازوں سے آیا کرو ، اور اﷲ سے ڈرتے رہو تاکہ تم فلاح پاؤ ۔',\n",
              " 'اور اﷲ کی راہ میں ان سے جنگ کرو جو تم سے جنگ کرتے ہیں ہاں مگر حد سے نہ بڑھو ، بیشک اﷲ حد سے بڑھنے والوں کو پسند نہیں فرماتا ۔',\n",
              " 'اور دورانِ جنگ ان کافروں کو جہاں بھی پاؤ مار ڈالو اور انہیں وہاں سے باہر نکال دو جہاں سے انہوں نے تمہیں نکالا تھا اور فتنہ انگیزی تو قتل سے بھی زیادہ سخت جرم ہے اور ان سے مسجدِ حرام خانہ کعبہ کے پاس جنگ نہ کرو جب تک وہ خود تم سے وہاں جنگ نہ کریں ،',\n",
              " 'پھر اگر وہ تم سے قتال کریں تو انہیں قتل کر ڈالو ، ایسے کافروں کی یہی سزا ہے ۔',\n",
              " 'پھر اگر وہ باز آجائیں تو بیشک اﷲ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'اور ان سے جنگ کرتے رہو حتٰی کہ کوئی فتنہ باقی نہ رہے اور دین یعنی زندگی اور بندگی کا نظام عملًا اﷲ ہی کے تابع ہو جائے ، پھر اگر وہ باز آجائیں تو سوائے ظالموں کے کسی پر زیادتی روا نہیں ۔',\n",
              " 'حرمت والے مہینے کے بدلے حرمت والا مہینہ ہے اور دیگر حرمت والی چیزیں ایک دوسرے کا بدل ہیں ، پس اگر تم پر کوئی زیادتی کرے تم بھی اس پر زیادتی کرو مگر اسی قدر جتنی اس نے تم پر کی ، اور اﷲ سے ڈرتے رہو اور جان لو کہ اﷲ ڈرنے والوں کے ساتھ ہے ۔',\n",
              " 'اور اﷲ کی راہ میں خرچ کرو اور اپنے ہی ہاتھوں خود کو ہلاکت میں نہ ڈالو ، اور نیکی اختیار کرو ، بیشک اﷲ نیکوکاروں سے محبت فرماتا ہے ۔',\n",
              " 'اور حج اور عمرہ کے مناسک اﷲ کے لئے مکمل کرو ، پھر اگر تم راستے میں روک لئے جاؤ تو جو قربانی بھی میسر آئے کرنے کے لئے بھیج دو',\n",
              " 'اور اپنے سروں کو اس وقت تک نہ منڈواؤ جب تک قربانی کا جانور اپنے مقام پر نہ پہنچ جائے ، پھر تم میں سے جو کوئی بیمار ہو یا اس کے سر میں کچھ تکلیف ہو اس وجہ سے قبل از وقت سر منڈوالے تو اس کے بدلے میں روزے رکھے یا صدقہ دے یا قربانی کرے ،',\n",
              " 'پھر جب تم اطمینان کی حالت میں ہو تو جو کوئی عمرہ کو حج کے ساتھ ملانے کا فائدہ اٹھائے تو جو بھی قربانی میّسر آئے کر دے ، پھر جسے یہ بھی میّسر نہ ہو وہ تین دن کے روزے زمانۂ حج میں رکھے اور سات جب تم حج سے واپس لوٹو ، یہ پورے دس روزے ہوئے ،',\n",
              " 'یہ رعایت اس کے لئے ہے جس کے اہل و عیال مسجدِ حرام کے پاس نہ رہتے ہوں یعنی جو مکہ کا رہنے والا نہ ہو ، اور اﷲ سے ڈرتے رہو اور جان لو کہ اﷲ سخت عذاب دینے والا ہے ۔',\n",
              " 'حج کے چند مہینے معیّن ہیں یعنی شوّال ، ذوالقعدہ اور عشرہء ذی الحجہ ،',\n",
              " 'تو جو شخص ان مہینوں میں نیت کر کے اپنے اوپر حج لازم کرلے تو حج کے دنوں میں نہ عورتوں سے اختلاط کرے اور نہ کوئی اور گناہ اور نہ ہی کسی سے جھگڑا کرے ،',\n",
              " 'اور تم جو بھلائی بھی کرو اﷲ اسے خوب جانتا ہے ،',\n",
              " 'اور آخرت کے سفر کا سامان کرلو ،',\n",
              " 'بیشک سب سے بہترزادِ راہ تقویٰ ہے ، اور اے عقل والو ! میرا تقویٰ اختیار کرو ۔',\n",
              " 'اور تم پر اس بات میں کوئی گناہ نہیں اگر تم زمانۂ حج میں تجارت کے ذریعے اپنے رب کا فضل بھی تلاش کرو ، پھر جب تم عرفات سے واپس آؤ تو مشعرِ حرام مُزدلفہ کے پاس اﷲ کا ذکر کیا کرو اور اس کا ذکر اس طرح کرو جیسے اس نے تمہیں ہدایت فرمائی ، اور بیشک اس سے پہلے تم بھٹکے ہوئے تھے ۔',\n",
              " 'پھر تم وہیں سے جاکر واپس آیا کرو جہاں سے اور لوگ واپس آتے ہیں اور اﷲ سے خوب بخشش طلب کرو ، بیشک اﷲ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'پھر جب تم اپنے حج کے ارکان پورے کر چکو تو منیٰ میں اﷲ کا خوب ذکر کیا کرو جیسے تم اپنے باپ دادا کا بڑے شوق سے ذکر کرتے ہو یا اس سے بھی زیادہ شدّتِ شوق سے اﷲ کا ذکر کیا کرو ، پھر لوگوں میں سے کچھ ایسے بھی ہیں جو کہتے ہیں : اے ہمارے رب ! ہمیں دنیا میں ہی عطا کر دے اور ایسے شخص کے لئے آخرت میں کوئی حصہ نہیں ہے ۔',\n",
              " 'اور انہی میں سے ایسے بھی ہیں جو عرض کرتے ہیں : اے ہمارے پروردگار ! ہمیں دنیا میں بھی بھلائی عطا فرما اور آخرت میں بھی بھلائی سے نواز اور ہمیں دوزخ کے عذاب سے محفوظ رکھ ۔',\n",
              " 'یہی وہ لوگ ہیں جن کے لئے ان کی نیک کمائی میں سے حصہ ہے ، اور اﷲ جلد حساب کرنے والا ہے ۔',\n",
              " 'اور اﷲ کو ان گنتی کے چند دنوں میں خوب یاد کیا کرو ، پھر جس کسی نے منیٰ سے واپسی میں دو ہی دنوں میں جلدی کی تو اس پر کوئی گناہ نہیں اور جس نے اس میں تاخیر کی تو اس پر بھی کوئی گناہ نہیں ، یہ اس کے لئے ہے جو پرہیزگاری اختیار کرے ، اور اﷲ سے ڈرتے رہو اور جان لو کہ تم سب کو اسی کے پاس جمع کیا جائے گا ۔',\n",
              " 'اور لوگوں میں کوئی شخص ایسا بھی ہوتا ہے کہ جس کی گفتگو دنیاوی زندگی میں تجھے اچھی لگتی ہے اور وہ اﷲ کو اپنے دل کی بات پر گواہ بھی بناتا ہے ، حالانکہ وہ سب سے زیادہ جھگڑالو ہے ۔',\n",
              " 'اور جب وہ آپ سے پھر جاتا ہے تو زمین میں ہر ممکن بھاگ دوڑ کرتا ہے تاکہ اس میں فساد انگیزی کرے اور کھیتیاں اور جانیں تباہ کر دے ، اور اﷲ فساد کو پسند نہیں فرماتا ۔',\n",
              " 'اور جب اسے اس ظلم و فساد پر کہا جائے کہ اﷲ سے ڈرو تو اس کا غرور اسے مزید گناہ پر اکساتا ہے ، پس اس کے لئے جہنم کافی ہے اور وہ یقیناً برا ٹھکانا ہے ۔',\n",
              " 'اور اس کے برعکس لوگوں میں کوئی شخص ایسا بھی ہوتا ہے جو اﷲ کی رضا حاصل کرنے کے لئے اپنی جان بھی بیچ ڈالتا ہے ، اور اﷲ بندوں پر بڑی مہربانی فرمانے والا ہے ۔',\n",
              " 'اے ایمان والو ! اسلام میں پورے پورے داخل ہو جاؤ ، اور شیطان کے راستوں پر نہ چلو ، بیشک وہ تمہارا کھلا دشمن ہے ۔',\n",
              " 'پس اگر تم اس کے بعد بھی لغزش کرو جب کہ تمہارے پاس واضح نشانیاں آچکیں تو جان لو کہ اﷲ بہت غالب بڑی حکمت والا ہے ۔',\n",
              " 'کیا وہ اسی بات کے منتظر ہیں کہ بادل کے سائبانوں میں اﷲ کا عذاب آجائے اور فرشتے بھی نیچے اتر آئیں اور سارا قصہ تمام ہو جائے ، تو سارے کام اﷲ ہی کی طرف لوٹائے جائیں گے ۔',\n",
              " 'آپ بنی اسرائیل سے پوچھ لیں کہ ہم نے انہیں کتنی واضح نشانیاں عطا کی تھیں ، اور جو شخص اﷲ کی نعمت کو اپنے پاس آجانے کے بعد بدل ڈالے تو بیشک اﷲ سخت عذاب دینے والا ہے ۔',\n",
              " 'کافروں کے لئے دنیا کی زندگی خوب آراستہ کر دی گئی ہے اور وہ ایمان والوں سے تمسخر کرتے ہیں ، اور جنہوں نے تقویٰ اختیار کیا وہ قیامت کے دن ان پر سربلند ہوں گے ، اور اﷲ جسے چاہتا ہے بے حساب نوازتا ہے ۔',\n",
              " 'ابتداء میں سب لوگ ایک ہی دین پر جمع تھے ، پھر جب ان میں اختلافات رونما ہو گئے تو اﷲ نے بشارت دینے والے اور ڈر سنانے والے پیغمبروں کو بھیجا ، اور ان کے ساتھ حق پر مبنی کتاب اتاری تاکہ وہ لوگوں میں ان امور کا فیصلہ کر دے جن میں وہ اختلاف کرنے لگے تھے',\n",
              " 'اور اس میں اختلاف بھی فقط انہی لوگوں نے کیا جنہیں وہ کتاب دی گئی تھی ، باوجود اس کے کہ ان کے پاس واضح نشانیاں آچکی تھیں ،',\n",
              " 'اور انہوں نے یہ اختلاف بھی محض باہمی بغض و حسد کے باعث کیا',\n",
              " 'پھر اﷲ نے ایمان والوں کو اپنے حکم سے وہ حق کی بات سمجھا دی جس میں وہ اختلاف کرتے تھے ،',\n",
              " 'اور اﷲ جسے چاہتا ہے سیدھے راستے کی طرف ہدایت فرما دیتا ہے ۔',\n",
              " 'کیا تم یہ گمان کرتے ہو کہ تم یونہی بلا آزمائش جنت میں داخل ہو جاؤ گے حالانکہ تم پر تو ابھی ان لوگوں جیسی حالت ہی نہیں بیتی جو تم سے پہلے گزر چکے ، انہیں توطرح طرح کی سختیاں اور تکلیفیں پہنچیں اور انہیں اس طرح ہلا ڈالا گیا کہ خود پیغمبر اور ان کے ایمان والے ساتھی بھی پکار اٹھے کہ اﷲ کی مدد کب آئے گی ؟ آگاہ ہو جاؤ کہ بیشک اﷲ کی مدد قریب ہے ۔',\n",
              " 'آپ سے پوچھتے ہیں کہ اﷲ کی راہ میں کیا خرچ کریں ، فرما دیں : جس قدر بھی مال خرچ کرو درست ہے ، مگر اس کے حق دار تمہارے ماں باپ ہیں اور قریبی رشتہ دار ہیں اور یتیم ہیں اور محتاج ہیں اور مسافر ہیں ، اور جو نیکی بھی تم کرتے ہو بیشک اﷲ اسے خوب جاننے والا ہے ۔',\n",
              " 'اﷲ کی راہ میں قتال تم پر فرض کر دیا گیا ہے حالانکہ وہ تمہیں طبعاً ناگوار ہے ، اور ممکن ہے تم کسی چیز کو ناپسند کرو اور وہ حقیقتاً تمہارے لئے بہتر ہو ، اور یہ بھی ممکن ہے کہ تم کسی چیز کو پسند کرو اور وہ حقیقتاً تمہارے لئے بری ہو ، اور اﷲ خوب جانتا ہے اور تم نہیں جانتے ۔',\n",
              " 'لوگ آپ سے حرمت والے مہینے میں جنگ کا حکم دریافت کرتے ہیں ، فرما دیں : اس میں جنگ بڑا گناہ ہے اور اﷲ کی راہ سے روکنا اور اس سے کفر کرنا اور مسجدِ حرام خانہ کعبہ سے روکنا اور وہاں کے رہنے والوں کو وہاں سے نکالنا اﷲ کے نزدیک اس سے بھی بڑا گناہ ہے ، اور یہ فتنہ انگیزی قتل و خون سے بھی بڑھ کر ہے',\n",
              " 'اور یہ کافر تم سے ہمیشہ جنگ جاری رکھیں گے یہاں تک کہ تمہیں تمہارے دین سے پھیر دیں اگر وہ اتنی طاقت پاسکیں ،',\n",
              " 'اور تم میں سے جو شخص اپنے دین سے پھر جائے اور پھر وہ کافر ہی مرے تو ایسے لوگوں کے دنیا و آخرت میں سب اعمال برباد ہو جائیں گے ،',\n",
              " 'اور یہی لوگ جہنمی ہیں وہ اس میں ہمیشہ رہیں گے ۔',\n",
              " 'بیشک جو لوگ ایمان لائے اور جنہوں نے اﷲ کے لئے وطن چھوڑا اور اﷲ کی راہ میں جہاد کیا ، یہی لوگ اﷲ کی رحمت کے امیدوار ہیں ، اور اﷲ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'آپ سے شراب اور جوئے کی نسبت سوال کرتے ہیں ، فرما دیں : ان دونوں میں بڑا گناہ ہے اور لوگوں کے لئے کچھ دنیوی فائدے بھی ہیں مگر ان دونوں کا گناہ ان کے نفع سے بڑھ کر ہے ، اور آپ سے یہ بھی پوچھتے ہیں کہ کیا کچھ خرچ کریں ؟ فرما دیں : جو ضرورت سے زائد ہے خرچ کر دو ، اسی طرح اﷲ تمہارے لئے اپنے احکام کھول کر بیان فرماتا ہے تاکہ تم غور و فکر کرو ۔',\n",
              " 'تمہارا غور و فکر دنیا اور آخرت دونوں کے معاملات میں رہے ، اور آپ سے یتیموں کے بارے میں دریافت کرتے ہیں ، فرما دیں : ان کے معاملات کا سنوارنا بہتر ہے ، اور اگر انہیں نفقہ و کاروبار میں اپنے ساتھ ملا لو تو وہ بھی تمہارے بھائی ہیں ، اور اﷲ خرابی کرنے والے کو بھلائی کرنے والے سے جدا پہچانتا ہے ، اور اگر اﷲ چاہتا تو تمہیں مشقت میں ڈال دیتا ، بیشک اﷲ بڑا غالب بڑی حکمت والا ہے ۔',\n",
              " 'اور تم مشرک عورتوں کے ساتھ نکاح مت کرو جب تک وہ مسلمان نہ ہو جائیں ، اور بیشک مسلمان لونڈی آزاد مشرک عورت سے بہتر ہے خواہ وہ تمہیں بھلی ہی لگے ، اور مسلمان عورتوں کا مشرک مردوں سے بھی نکاح نہ کرو جب تک وہ مسلمان نہ ہو جائیں ، اور یقیناً مشرک مرد سے مؤمن غلام بہتر ہے خواہ وہ تمہیں بھلا ہی لگے ، وہ کافر اور مشرک دوزخ کی طرف بلاتے ہیں ، اور اﷲ اپنے حکم سے جنت اور مغفرت کی طرف بلاتا ہے ، اور اپنی آیتیں لوگوں کے لئے کھول کر بیان فرماتا ہے تاکہ وہ نصیحت حاصل کریں ۔',\n",
              " 'اور آپ سے حیض ایامِ ماہواری کی نسبت سوال کرتے ہیں ، فرما دیں : وہ نجاست ہے ، سو تم حیض کے دنوں میں عورتوں سے کنارہ کش رہا کرو ، اور جب تک وہ پاک نہ ہو جائیں ان کے قریب نہ جایا کرو ، اور جب وہ خوب پاک ہو جائیں تو جس راستے سے اﷲ نے تمہیں اجازت دی ہے ان کے پاس جایا کرو ، بیشک اﷲ بہت توبہ کرنے والوں سے محبت فرماتا ہے اور خوب پاکیزگی اختیار کرنے والوں سے محبت فرماتا ہے ۔',\n",
              " 'تمہاری عورتیں تمہاری کھیتیاں ہیں پس تم اپنی کھیتیوں میں جیسے چاہو آؤ ، اور اپنے لئے آئندہ کا کچھ سامان کرلو ، اور اﷲ کا تقوٰی اختیار کرو اور جان لو کہ تم اس کے حضور پیش ہونے والے ہو ، اور اے حبیب ! آپ اہلِ ایمان کو خوشخبری سنادیں کہ اﷲ کے حضور ان کی پیشی بہتر رہے گی ۔',\n",
              " 'اور اپنی قَسموں کے باعث اﷲ کے نام کو لوگوں کے ساتھ نیکی کرنے اور پرہیزگاری اختیار کرنے اور لوگوں میں صلح کرانے میں آڑ مت بناؤ ، اور اﷲ خوب سننے والا بڑا جاننے والا ہے ۔',\n",
              " 'اﷲ تمہاری بے ہودہ قَسموں پر تم سے مؤاخذہ نہیں فرمائے گا مگر ان کا ضرور مؤاخذہ فرمائے گا جن کا تمہارے دلوں نے ارادہ کیا ہو ، اور اﷲ بڑا بخشنے والا بہت حلم والا ہے ۔',\n",
              " 'اور ان لوگوں کے لئے جو اپنی بیویوں کے قریب نہ جانے کی قسم کھالیں چار ماہ کی مہلت ہے پس اگر وہ اس مدت میں رجوع کر لیں تو بیشک اﷲ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'اور اگر انہوں نے طلاق کا پختہ ارادہ کر لیا ہو تو بیشک اﷲ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'اور طلاق یافتہ عورتیں اپنے آپ کو تین حیض تک روکے رکھیں ، اور ان کے لئے جائز نہیں کہ وہ اسے چھپائیں جو اﷲ نے ان کے رحموں میں پیدا فرما دیا ہو ، اگر وہ اﷲ پر اور قیامت کے دن پر ایمان رکھتی ہیں ، اور اس مدت کے اندر ان کے شوہروں کو انہیں پھر اپنی زوجیت میں لوٹا لینے کا حق زیادہ ہے اگر وہ اصلاح کا ارادہ کر لیں ،',\n",
              " 'اور دستور کے مطابق عورتوں کے بھی مردوں پر اسی طرح حقوق ہیں جیسے مردوں کے عورتوں پر ،',\n",
              " 'البتہ مردوں کو ان پر فضیلت ہے ، اور اﷲ بڑا غالب بڑی حکمت والا ہے ۔',\n",
              " 'طلاق صرف دو بار تک ہے ، پھر یا تو بیوی کو اچھے طریقے سے زوجیت میں روک لینا ہے یا بھلائی کے ساتھ چھوڑ دینا ہے ، اور تمہارے لئے جائز نہیں کہ جو چیزیں تم انہیں دے چکے ہو اس میں سے کچھ واپس لو سوائے اس کے کہ دونوں کو اندیشہ ہو کہ اب رشتۂ زوجیت برقرار رکھتے ہوئے دونوں اﷲ کی حدود کو قائم نہ رکھ سکیں گے ،',\n",
              " 'پھر اگر تمہیں اندیشہ ہو کہ دونوں اﷲ کی حدود کو قائم نہ رکھ سکیں گے ، سو اندریں صورت ان پر کوئی گناہ نہیں کہ بیوی خود کچھ بدلہ دے کر اس تکلیف دہ بندھن سے آزادی لے لے ،',\n",
              " 'یہ اﷲ کی مقرر کی ہوئی حدیں ہیں ، پس تم ان سے آگے مت بڑھو اور جو لوگ اﷲ کی حدود سے تجاوز کرتے ہیں سو وہی لوگ ظالم ہیں ۔',\n",
              " 'پھر اگر اس نے تیسری مرتبہ طلاق دے دی تو اس کے بعد وہ اس کے لئے حلال نہ ہوگی یہاں تک کہ وہ کسی اور شوہر کے ساتھ نکاح کر لے ،',\n",
              " 'پھر اگر وہ دوسرا شوہر بھی طلاق دے دے تو اب ان دونوں یعنی پہلے شوہر اور اس عورت پر کوئی گناہ نہ ہوگا اگر وہ دوبارہ رشتۂ زوجیت میں پلٹ جائیں بشرطیکہ دونوں یہ خیال کریں کہ اب وہ حدودِ الٰہی قائم رکھ سکیں گے ،',\n",
              " 'یہ اﷲ کی مقرر کردہ حدود ہیں جنہیں وہ علم والوں کے لئے بیان فرماتا ہے ۔',\n",
              " 'اور جب تم عورتوں کو طلاق دو اور وہ اپنی عدت پوری ہونے کو آپہنچیں تو انہیں اچھے طریقے سے اپنی زوجیّت میں روک لو یا انہیں اچھے طریقے سے چھوڑ دو ،',\n",
              " 'اور انہیں محض تکلیف دینے کے لئے نہ روکے رکھو کہ ان پر زیادتی کرتے رہو ،',\n",
              " 'اور جو کوئی ایسا کرے پس اس نے اپنی ہی جان پر ظلم کیا ،',\n",
              " 'اور اﷲ کے احکام کو مذاق نہ بنا لو ،',\n",
              " 'اور یاد کرو اﷲ کی اس نعمت کو جو تم پر کی گئی ہے اور اس کتاب کو جو اس نے تم پر نازل فرمائی ہے اور دانائی کی باتوں کو جن کی اس نے تمہیں تعلیم دی ہے',\n",
              " 'وہ تمہیں اس امر کی نصیحت فرماتا ہے ،',\n",
              " 'اور اﷲ سے ڈرو اور جان لو کہ بیشک اﷲ سب کچھ جاننے والا ہے ۔',\n",
              " 'اور جب تم عورتوں کو طلاق دو اور وہ اپنی عدت پوری ہونے کو آپہنچیں تو جب وہ شرعی دستور کے مطابق باہم رضامند ہو جائیں تو انہیں اپنے پرانے یا نئے شوہروں سے نکاح کرنے سے مت روکو ، اس شخص کو اس امر کی نصیحت کی جاتی ہے جو تم میں سے اﷲ پراور یومِ قیامت پر ایمان رکھتا ہو ، یہ تمہارے لئے بہت ستھری اور نہایت پاکیزہ بات ہے ، اور اﷲ جانتا ہے اور تم بہت سی باتوں کو نہیں جانتے ۔',\n",
              " 'اور مائیں اپنے بچوں کو پورے دو برس تک دودھ پلائیں یہ حکم اس کے لئے ہے جو دودھ پلانے کی مدت پوری کرنا چاہے ،',\n",
              " 'اور دودھ پلانے والی ماؤں کا کھانا اور پہننا دستور کے مطابق بچے کے باپ پر لازم ہے ،',\n",
              " 'کسی جان کو اس کی طاقت سے بڑھ کر تکلیف نہ دی جائے ، اور نہ ماں کو اس کے بچے کے باعث نقصان پہنچایا جائے اور نہ باپ کو اس کی اولاد کے سبب سے ،',\n",
              " 'اور وارثوں پر بھی یہی حکم عائد ہوگا ،',\n",
              " 'پھر اگر ماں باپ دونوں باہمی رضا مندی اور مشورے سے دو برس سے پہلے ہی دودھ چھڑانا چاہیں تو ان پر کوئی گناہ نہیں ،',\n",
              " 'اور پھر اگر تم اپنی اولاد کو دایہ سے دودھ پلوانے کا ارادہ رکھتے ہو تب بھی تم پر کوئی گناہ نہیں جب کہ جو تم دستور کے مطابق دیتے ہو انہیں ادا کر دو ،',\n",
              " 'اور اﷲ سے ڈرتے رہو اور یہ جان لو کہ بیشک جو کچھ تم کرتے ہو اﷲ اسے خوب دیکھنے والا ہے ۔',\n",
              " 'اور تم میں سے جو فوت ہو جائیں اور اپنی بیویاں چھوڑ جائیں تو وہ اپنے آپ کو چار ماہ دس دن انتظار میں روکے رکھیں ، پھر جب وہ اپنی عدت پوری ہونے کو آپہنچیں تو پھر جو کچھ وہ شرعی دستور کے مطابق اپنے حق میں کریں تم پر اس معاملے میں کوئی مؤاخذہ نہیں ، اور جو کچھ تم کرتے ہو اﷲ اس سے اچھی طرح خبردار ہے ۔',\n",
              " 'اور تم پر اس بات میں کوئی گناہ نہیں کہ دورانِ عدت بھی ان عورتوں کو اشارۃً نکاح کا پیغام دے دو یا یہ خیال اپنے دلوں میں چھپا رکھو ، اﷲ جانتا ہے کہ تم عنقریب ان سے ذکر کرو گے مگر ان سے خفیہ طور پر بھی ایسا وعدہ نہ لو سوائے اس کے کہ تم فقط شریعت کی رُو سے کنایۃً معروف بات کہہ دو ، اور اس دوران عقدِ نکاح کا پختہ عزم نہ کرو یہاں تک کہ مقررہ عدت اپنی انتہا کو پہنچ جائے ، اور جان لو کہ اﷲ تمہارے دلوں کی بات کو بھی جانتا ہے تو اس سے ڈرتے رہا کرو ، اور یہ بھی جان لو کہ اﷲ بڑا بخشنے والا بڑا حلم والا ہے ۔',\n",
              " 'تم پر اس بات میں بھی کوئی گناہ نہیں کہ اگر تم نے اپنی منکوحہ عورتوں کو ان کے چھونے یا ان کے مہر مقرر کرنے سے بھی پہلے طلاق دے دی ہے تو انہیں ایسی صورت میں مناسب خرچہ دے دو ، وسعت والے پر اس کی حیثیت کے مطابق لازم ہے اور تنگ دست پر اس کی حیثیت کے مطابق ، بہر طور یہ خرچہ مناسب طریق پر دیا جائے ، یہ بھلائی کرنے والوں پر واجب ہے ۔',\n",
              " 'اور اگر تم نے انہیں چھونے سے پہلے طلاق دے دی درآنحالیکہ تم ان کا مَہر مقرر کر چکے تھے تو اس مَہر کا جو تم نے مقرر کیا تھا نصف دینا ضروری ہے سوائے اس کے کہ وہ اپنا حق خود معاف کر دیں یا وہ شوہر جس کے ہاتھ میں نکاح کی گرہ ہے معاف کردے یعنی بجائے نصف کے زیادہ یا پورا ادا کردے ، اور اے مَردو ! اگر تم معاف کر دو تو یہ تقویٰ کے قریب تر ہے ، اور کشیدگی کے ان لمحات میں بھی آپس میں احسان کرنا نہ بھولا کرو ، بیشک اﷲ تمہارے اعمال کو خوب دیکھنے والا ہے ۔',\n",
              " 'سب نمازوں کی محافظت کیا کرو اور بالخصوص درمیانی نماز کی ، اور اﷲ کے حضور سراپا ادب و نیاز بن کر قیام کیا کرو ۔',\n",
              " 'پھر اگر تم حالتِ خوف میں ہو تو پیادہ یا سوار جیسے بھی ہو نماز پڑھ لیا کرو ، پھر جب تم حالتِ امن میں آجاؤ تو انہی طریقوں پر اﷲ کی یاد کرو جو اس نے تمہیں سکھائے ہیں جنہیں تم پہلے نہیں جانتے تھے ۔',\n",
              " 'اور تم میں سے جو لوگ فوت ہوں اور اپنی بیویاں چھوڑ جائیں ان پر لازم ہے کہ مرنے سے پہلے اپنی بیویوں کے لئے انہیں ایک سال تک کا خرچہ دینے اور اپنے گھروں سے نہ نکالے جانے کی وصیّت کر جائیں ،',\n",
              " 'پھر اگر وہ خود اپنی مرضی سی نکل جائیں تو دستور کے مطابق جو کچھ بھی وہ اپنے حق میں کریں تم پر اس معاملے میں کوئی گناہ نہیں ، اور اﷲ بڑا غالب بڑی حکمت والا ہے ۔',\n",
              " 'اور طلاق یافتہ عورتوں کو بھی مناسب طریقے سے خرچہ دیا جائے ، یہ پرہیزگاروں پر واجب ہے ۔',\n",
              " 'ا سی طرح اﷲ تمہارے لئے اپنے احکام واضح فرماتا ہے تاکہ تم سمجھ سکو ۔',\n",
              " 'اے حبیب ! کیا آپ نے ان لوگوں کو نہیں دیکھا جو موت کے ڈر سے اپنے گھروں سے نکل گئے حالانکہ وہ ہزاروں کی تعداد میں تھے ، تو اﷲ نے انہیں حکم دیا : مر جاؤ سو وہ مرگئے ، پھر انہیں زندہ فرما دیا ، بیشک اﷲ لوگوں پر فضل فرمانے والا ہے مگر اکثر لوگ اس کا شکر ادا نہیں کرتے ۔',\n",
              " 'اے مسلمانو ! اﷲ کی راہ میں جنگ کرو اور جان لو کہ اﷲ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'کون ہے جو اﷲ کو قرضِ حسنہ دے پھر وہ اس کے لئے اسے کئی گنا بڑھا دے گا ، اور اﷲ ہی تمہارے رزق میں تنگی اور کشادگی کرتا ہے ، اور تم اسی کی طرف لوٹائے جاؤگے ۔',\n",
              " 'اے حبیب ! کیا آپ نے بنی اسرائیل کے اس گروہ کو نہیں دیکھا جو موسٰی علیہ السلام کے بعد ہوا ،',\n",
              " 'جب انہوں نے اپنے پیغمبر سے کہا کہ ہمارے لئے ایک بادشاہ مقرر کر دیں تاکہ ہم اس کی قیادت میں اﷲ کی راہ میں جنگ کریں ،',\n",
              " 'نبی نے ان سے فرمایا : کہیں ایسا نہ ہو کہ تم پر قتال فرض کردیا جائے تو تم قتال ہی نہ کرو ،',\n",
              " 'وہ کہنے لگے : ہمیں کیا ہوا ہے کہ ہم اﷲ کی راہ میں جنگ نہ کریں حالانکہ ہمیں اپنے گھروں سے اور اولاد سے جدا کر دیا گیا ہے ،',\n",
              " 'سو جب ان پر قتال فرض کردیا گیا تو ان میں سے چند ایک کے سوا سب پھر گئے ،',\n",
              " 'اور اﷲ ظالموں کو خوب جاننے والا ہے ۔',\n",
              " 'اور ان سے ان کے نبی نے فرمایا : بیشک اﷲ نے تمہارے لئے طالوت کو بادشاہ مقرّر فرمایا ہے ،',\n",
              " 'تو کہنے لگے کہ اسے ہم پر حکمرانی کیسے مل گئی حالانکہ ہم اس سے حکومت کرنے کے زیادہ حق دار ہیں اسے تو دولت کی فراوانی بھی نہیں دی گئی ،',\n",
              " 'نبی نے فرمایا : بیشک اﷲ نے اسے تم پر منتخب کر لیا ہے اور اسے علم اور جسم میں زیادہ کشادگی عطا فرما دی ہے ،',\n",
              " 'اور اﷲ اپنی سلطنت کی امانت جسے چاہتا ہے عطا فرما دیتا ہے ، اور اﷲ بڑی وسعت والا خوب جاننے والا ہے ۔',\n",
              " 'اور ان کے نبی نے ان سے فرمایا : اس کی سلطنت کے مِن جانِبِ اﷲ ہونے کی نشانی یہ ہے کہ تمہارے پاس صندوق آئے گا اس میں تمہارے رب کی طرف سے سکونِ قلب کا سامان ہوگا اور کچھ آلِ موسٰی اور آلِ ہارون کے چھوڑے ہوئے تبرکات ہوں گے اسے فرشتوں نے اٹھایا ہوا ہوگا ، اگر تم ایمان والے ہو تو بیشک اس میں تمہارے لئے بڑی نشانی ہے ۔',\n",
              " 'پھرجب طالوت اپنے لشکروں کو لے کر شہر سے نکلا ، تو اس نے کہا : بیشک اﷲ تمہیں ایک نہر کے ذریعے آزمانے والا ہے ، پس جس نے اس میں سے پانی پیا سو وہ میرے ساتھیوں میں سے نہیں ہوگا ، اور جو اس کو نہیں پئے گا پس وہی میری جماعت سے ہوگا مگر جو شخص ایک چُلّو کی حد تک اپنے ہاتھ سے پی لے اس پر کوئی حرج نہیں ،',\n",
              " 'سو ان میں سے چند لوگوں کے سوا باقی سب نے اس سے پانی پی لیا ،',\n",
              " 'پس جب طالوت اور ان کے ایمان والے ساتھی نہر کے پار چلے گئے ، تو کہنے لگے : آج ہم میں جالوت اور اس کی فوجوں سے مقابلے کی طاقت نہیں ،',\n",
              " 'جو لوگ یہ یقین رکھتے تھے کہ وہ شہید ہو کر یا مرنے کے بعد اﷲ سے ملاقات کا شرف پانے والے ہیں ، کہنے لگے : کئی مرتبہ اﷲ کے حکم سے تھوڑی سی جماعت خاصی بڑی جماعت پر غالب آجاتی ہے ، اور اﷲ صبر کرنے والوں کو اپنی معیّت سے نوازتا ہے ۔',\n",
              " 'اور جب وہ جالوت اور اس کی فوجوں کے مقابل ہوئے تو عرض کرنے لگے : اے ہمارے پروردگار ! ہم پر صبر میں وسعت ارزانی فرما اور ہمیں ثابت قدم رکھ اور ہمیں کافروں پر غلبہ عطا فرما ۔',\n",
              " 'پھر انہوں نے ان جالوتی فوجوں کو اللہ کے امر سے شکست دی ، اور داؤد علیہ السلام نے جالوت کو قتل کر دیا اور اﷲ نے ان کو یعنی داؤد علیہ السلام کو حکومت اور حکمت عطا فرمائی اور انہیں جو چاہا سکھایا ، اور اگر اﷲ لوگوں کے ایک گروہ کو دوسرے گروہ کے ذریعے نہ ہٹاتا رہتا تو زمین میں انسانی زندگی بعض جابروں کے مسلسل تسلّط اور ظلم کے باعث برباد ہو جاتی مگر اﷲ تمام جہانوں پر بڑا فضل فرمانے والا ہے ۔',\n",
              " 'یہ اﷲ کی آیتیں ہیں ہم انہیں اے حبیب ! آپ پر سچائی کے ساتھ پڑھتے ہیں ، اور بیشک آپ رسولوں میں سے ہیں ۔',\n",
              " 'یہ سب رسول جو ہم نے مبعوث فرمائے ہم نے ان میں سے بعض کو بعض پر فضیلت دی ہے ، ان میں سے کسی سے اﷲ نے براہِ راست کلام فرمایا اور کسی کو درجات میں سب پر فوقیّت دی یعنی حضور نبی اکرم صلی اللہ علیہ وآلہ وسلم کو جملہ درجات میں سب پر بلندی عطا فرمائی ، اور ہم نے مریم کے فرزند عیسٰی علیہ السلام کو واضح نشانیاں عطا کیں اور ہم نے پاکیزہ روح کے ذریعے اس کی مدد فرمائی ،',\n",
              " 'اور اگر اﷲ چاہتا تو ان رسولوں کے پیچھے آنے والے لوگ اپنے پاس کھلی نشانیاں آجانے کے بعد آپس میں کبھی بھی نہ لڑتے جھگڑتے مگر انہوں نے اس آزادانہ توفیق کے باعث جو انہیں اپنے کئے پر اﷲ کے حضور جواب دہ ہونے کے لئے دی گئی تھی اختلاف کیا پس ان میں سے کچھ ایمان لائے اور ان میں سے کچھ نے کفر اختیار کیا ،',\n",
              " 'اور یہ بات یاد رکھو کہ اگر اﷲ چاہتا یعنی انہیں ایک ہی بات پر مجبور رکھتا تو وہ کبھی بھی باہم نہ لڑتے ، لیکن اﷲ جو چاہتا ہے کرتا ہے ۔',\n",
              " 'اے ایمان والو ! جو کچھ ہم نے تمہیں عطا کیا ہے اس میں سے اﷲ کی راہ میں خرچ کرو قبل اس کے کہ وہ دن آجائے جس میں نہ کوئی خرید و فروخت ہوگی اور کافروں کے لئے نہ کوئی دوستی کار آمد ہوگی اور نہ کوئی سفارش ، اور یہ کفار ہی ظالم ہیں ۔',\n",
              " 'اﷲ ، اس کے سوا کوئی عبادت کے لائق نہیں ، ہمیشہ زندہ رہنے والا ہے سارے عالم کو اپنی تدبیر سے قائم رکھنے والا ہے ، نہ اس کو اُونگھ آتی ہے اور نہ نیند جو کچھ آسمانوں میں ہے اور جو کچھ زمین میں ہے سب اسی کا ہے ، کون ایسا شخص ہے جو اس کے حضور اس کے اِذن کے بغیر سفارش کر سکے ، جو کچھ مخلوقات کے سامنے ہو رہا ہے یا ہو چکا ہے اور جو کچھ ان کے بعد ہونے والا ہے وہ سب جانتا ہے ، اور وہ اس کی معلومات میں سے کسی چیز کا بھی احاطہ نہیں کر سکتے مگر جس قدر وہ چاہے ، اس کی کرسیء سلطنت و قدرت تمام آسمانوں اور زمین کو محیط ہے ، اور اس پر ان دونوں یعنی زمین و آسمان کی حفاظت ہرگز دشوار نہیں ، وہی سب سے بلند رتبہ بڑی عظمت والا ہے ۔',\n",
              " 'دین میں کوئی زبردستی نہیں ، بیشک ہدایت گمراہی سے واضح طور پر ممتاز ہو چکی ہے ، سو جو کوئی معبودانِ باطلہ کا انکار کر دے اور اﷲ پر ایمان لے آئے تو اس نے ایک ایسا مضبوط حلقہ تھام لیا جس کے لئے ٹوٹنا ممکن نہیں ، اور اﷲ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'اﷲ ایمان والوں کا کارساز ہے وہ انہیں تاریکیوں سے نکال کر نور کی طرف لے جاتا ہے ، اور جو لوگ کافر ہیں ان کے حمایتی شیطان ہیں وہ انہیں حق کی روشنی سے نکال کر باطل کی تاریکیوں کی طرف لے جاتے ہیں ، یہی لوگ جہنمی ہیں ، وہ اس میں ہمیشہ رہیں گے ۔',\n",
              " 'اے حبیب ! کیا آپ نے اس شخص کو نہیں دیکھا جو اس وجہ سے کہ اﷲ نے اسے سلطنت دی تھی ابراہیم علیہ السلام سے خود اپنے رب ہی کے بارے میں جھگڑا کرنے لگا ، جب ابراہیم علیہ السلام نے کہا : میرا رب وہ ہے جو زندہ بھی کرتا ہے اور مارتا بھی ہے ، تو جواباً کہنے لگا : میں بھی زندہ کرتا ہوں اور مارتا ہوں ، ابراہیم علیہ السلام نے کہا : بیشک اﷲ سورج کو مشرق کی طرف سے نکالتا ہے تُو اسے مغرب کی طرف سے نکال لا ! سو وہ کافر دہشت زدہ ہو گیا ، اور اﷲ ظالم قوم کو حق کی راہ نہیں دکھاتا ۔',\n",
              " 'یا اسی طرح اس شخص کو نہیں دیکھا جو ایک بستی پر سے گزرا جو اپنی چھتوں پر گری پڑی تھی تو اس نے کہا کہ اﷲ اس کی موت کے بعد اسے کیسے زندہ فرمائے گا ، سو اپنی قدرت کا مشاہدہ کرانے کے لئے اﷲ نے اسے سو برس تک مُردہ رکھا پھر اُسے زندہ کیا ، بعد ازاں پوچھا : تُو یہاں مرنے کے بعد کتنی دیر ٹھہرا رہا ہے ؟',\n",
              " 'اس نے کہا : میں ایک دن یا ایک دن کا بھی کچھ حصہ ٹھہرا ہوں ، فرمایا : نہیں بلکہ تُو سو برس پڑا رہا ہے پس اب تُو اپنے کھانے اور پینے کی چیزوں کو دیکھ وہ متغیّر باسی بھی نہیں ہوئیں اور اب اپنے گدھے کی طرف نظر کر جس کی ہڈیاں بھی سلامت نہیں رہیں',\n",
              " 'اور یہ اس لئے کہ ہم تجھے لوگوں کے لئے اپنی قدرت کی نشانی بنا دیں اور اب ان ہڈیوں کی طرف دیکھ ہم انہیں کیسے جُنبش دیتے اور اٹھاتے ہیں پھر انہیں گوشت کا لباس پہناتے ہیں ، جب یہ معاملہ اس پر خوب آشکار ہو گیا تو بول اٹھا : میں مشاہداتی یقین سے جان گیا ہوں کہ بیشک اﷲ ہر چیز پر خوب قادر ہے ۔',\n",
              " 'اور وہ واقعہ بھی یاد کریں جب ابراہیم علیہ السلام نے عرض کیا : میرے رب ! مجھے دکھا دے کہ تُو مُردوں کو کس طرح زندہ فرماتا ہے ؟ ارشاد ہوا : کیا تم یقین نہیں رکھتے ؟ اس نے عرض کیا : کیوں نہیں یقین رکھتا ہوں لیکن چاہتا ہوں کہ میرے دل کو بھی خوب سکون نصیب ہو جائے ، ارشاد فرمایا : سو تم چار پرندے پکڑ لو پھر انہیں اپنی طرف مانوس کر لو پھر انہیں ذبح کر کے ان کا ایک ایک ٹکڑا ایک ایک پہاڑ پر رکھ دو پھر انہیں بلاؤ وہ تمہارے پاس دوڑتے ہوئے آجائیں گے ، اور جان لو کہ یقینا اﷲ بڑا غالب بڑی حکمت والا ہے ۔',\n",
              " 'جو لوگ اﷲ کی راہ میں اپنے مال خرچ کرتے ہیں ان کی مثال اس دانے کی سی ہے جس سے سات بالیاں اگیں اور پھر ہر بالی میں سو دانے ہوں یعنی سات سو گنا اجر پاتے ہیں ، اور اﷲ جس کے لئے چاہتا ہے اس سے بھی اضافہ فرما دیتا ہے ، اور اﷲ بڑی وسعت والا خوب جاننے والا ہے ۔',\n",
              " 'جو لوگ اﷲ کی راہ میں اپنے مال خرچ کرتے ہیں پھر اپنے خرچ کئے ہوئے کے پیچھے نہ احسان جتلاتے ہیں اور نہ اذیت دیتے ہیں ان کے لئے ان کے رب کے پاس ان کا اجر ہے اور روزِ قیامت ان پر نہ کوئی خوف ہوگا اور نہ وہ غمگین ہوں گے ۔',\n",
              " 'سائل سے نرمی کے ساتھ گفتگو کرنا اور درگزر کرنا اس صدقہ سے کہیں بہتر ہے جس کے بعد اس کی دل آزاری ہو ، اور اﷲ بے نیاز بڑا حلم والا ہے ۔',\n",
              " 'اے ایمان والو ! اپنے صدقات بعد ازاں احسان جتا کر اور دُکھ دے کر اس شخص کی طرح برباد نہ کر لیا کرو جو مال لوگوں کے دکھانے کے لئے خرچ کرتا ہے اور نہ اﷲ پر ایمان رکھتا ہے اور نہ روزِ قیامت پر ، اس کی مثال ایک ایسے چکنے پتھر کی سی ہے جس پر تھوڑی سی مٹی پڑی ہو پھر اس پر زوردار بارش ہو تو وہ اسے پھر وہی سخت اور صاف پتھر کر کے ہی چھوڑ دے ، سو اپنی کمائی میں سے ان ریاکاروں کے ہاتھ کچھ بھی نہیں آئے گا ، اور اﷲ کافر قوم کو ہدایت نہیں فرماتا ۔',\n",
              " 'اور جو لوگ اپنے مال اﷲ کی رضا حاصل کرنے اور اپنے آپ کو ایمان و اطاعت پر مضبوط کرنے کے لئے خرچ کرتے ہیں ان کی مثال ایک ایسے باغ کی سی ہے جو اونچی سطح پر ہو اس پر زوردار بارش ہو تو وہ دوگنا پھل لائے ، اور اگر اسے زوردار بارش نہ ملے تو اسے شبنم یا ہلکی سی پھوار بھی کافی ہو ، اور اﷲ تمہارے اعمال کو خوب دیکھنے والا ہے ۔',\n",
              " 'کیا تم میں سے کوئی شخص یہ پسند کرے گا کہ اس کے پاس کھجوروں اور انگوروں کا ایک باغ ہو جس کے نیچے نہریں بہتی ہوں اس کے لئے اس میں کھجوروں اور انگوروں کے علاوہ بھی ہر قسم کے پھل ہوں اور ایسے وقت میں اسے بڑھاپا آپہنچے اور ابھی اس کی اولاد بھی ناتواں ہو اور ایسے وقت میں اس باغ پر ایک بگولا آجائے جس میں نِری آگ ہو اور وہ باغ جل جائے تو اس کی محرومی اور پریشانی کا عالم کیا ہو گا ، اسی طرح اﷲ تمہارے لئے نشانیاں واضح طور پر بیان فرماتا ہے تاکہ تم غور کرو سو کیا تم چاہتے ہو کہ آخرت میں تمہارے اعمال کا باغ بھی ریاکاری کی آگ میں جل کر بھسم ہو جائے اور تمہیں سنبھالا دینے والا بھی کوئی نہ ہو ۔',\n",
              " 'اے ایمان والو ! ان پاکیزہ کمائیوں میں سے اور اس میں سے جو ہم نے تمہارے لئے زمین سے نکالا ہے اﷲ کی راہ میں خرچ کیا کرو اور اس میں سے گندے مال کو اﷲ کی راہ میں خرچ کرنے کا ارادہ مت کرو کہ اگر وہی تمہیں دیا جائے تو تم خود اسے ہرگز نہ لو سوائے اس کے کہ تم اس میں چشم پوشی کر لو ، اور جان لو کہ بیشک اﷲ بے نیاز لائقِ ہر حمد ہے ۔',\n",
              " 'شیطان تمہیں اﷲ کی راہ میں خرچ کرنے سے روکنے کے لئے تنگدستی کا خوف دلاتا ہے اور بے حیائی کا حکم دیتا ہے ، اور اﷲ تم سے اپنی بخشش اور فضل کا وعدہ فرماتا ہے ، اور اﷲ بہت وسعت والا خوب جاننے والا ہے ۔',\n",
              " 'جسے چاہتا ہے دانائی عطا فرما دیتا ہے ، اور جسے حکمت و دانائی عطا کی گئی اسے بہت بڑی بھلائی نصیب ہوگئی ، اور صرف وہی لوگ نصیحت حاصل کرتے ہیں جو صاحبِ عقل و دانش ہیں ۔',\n",
              " 'اور تم جو کچھ بھی خرچ کرو یا تم جو مَنّت بھی مانو تو اﷲ اسے یقینا جانتا ہے ، اور ظالموں کے لئے کوئی مددگار نہیں ۔',\n",
              " 'اگر تم خیرات ظاہر کر کے دو تو یہ بھی اچھا ہے اس سے دوسروں کو ترغیب ہوگی ، اور اگر تم انہیں مخفی رکھو اور وہ محتاجوں کو پہنچا دو تو یہ تمہارے لئے اور بہتر ہے ، اور اﷲ اس خیرات کی وجہ سے تمہارے کچھ گناہوں کو تم سے دور فرما دے گا ، اور اﷲ تمہارے اعمال سے باخبر ہے ۔',\n",
              " 'ان کا ہدایت یافتہ ہو جانا آپ کے ذمہ نہیں بلکہ اﷲ ہی جسے چاہتا ہے ہدایت سے نوازتا ہے ، اور تم جو مال بھی خرچ کرو سو وہ تمہارے اپنے فائدے میں ہے ، اور اﷲ کی رضاجوئی کے سوا تمہارا خرچ کرنا مناسب ہی نہیں ہے ، اور تم جو مال بھی خرچ کرو گے اس کا اجر تمہیں پورا پورا دیا جائے گا اور تم پر کوئی ظلم نہیں کیا جائے گا ۔',\n",
              " 'خیرات ان فقراءکا حق ہے جو اﷲ کی راہ میں کسبِ معاش سے روک دیئے گئے ہیں وہ امورِ دین میں ہمہ وقت مشغول رہنے کے باعث زمین میں چل پھر بھی نہیں سکتے ان کے زُھداً طمع سے باز رہنے کے باعث نادان جو ان کے حال سے بے خبر ہے انہیں مالدار سمجھے ہوئے ہے ، تم انہیں ان کی صورت سے پہچان لو گے ، وہ لوگوں سے بالکل سوال ہی نہیں کرتے کہ کہیں مخلوق کے سامنے گڑگڑانا نہ پڑے ، اور تم جو مال بھی خرچ کرو تو بیشک اﷲ اسے خوب جانتا ہے ۔',\n",
              " 'جو لوگ اﷲ کی راہ میں شب و روز اپنے مال پوشیدہ اور ظاہر خرچ کرتے ہیں تو ان کے لئے ان کے رب کے پاس ان کا اجر ہے اور روزِ قیامت ان پر نہ کوئی خوف ہوگا اور نہ وہ رنجیدہ ہوں گے ۔',\n",
              " 'جو لوگ سُود کھاتے ہیں وہ روزِ قیامت کھڑے نہیں ہو سکیں گے مگر جیسے وہ شخص کھڑا ہوتا ہے جسے شیطان آسیب نے چھو کر بدحواس کر دیا ہو ، یہ اس لئے کہ وہ کہتے تھے کہ تجارت خرید و فروخت بھی تو سود کی مانند ہے ، حالانکہ اﷲ نے تجارت سوداگری کو حلال فرمایا ہے اور سود کو حرام کیا ہے ، پس جس کے پاس اس کے رب کی جانب سے نصیحت پہنچی سو وہ سود سے باز آگیا تو جو پہلے گزر چکا وہ اسی کا ہے ، اور اس کا معاملہ اﷲ کے سپرد ہے ، اور جس نے پھر بھی لیا سو ایسے لوگ جہنمی ہیں ، وہ اس میں ہمیشہ رہیں گے ۔',\n",
              " 'اور اﷲ سود کو مٹاتا ہے یعنی سودی مال سے برکت کو ختم کرتا ہے اور صدقات کو بڑھاتا ہے یعنی صدقہ کے ذریعے مال کی برکت کو زیادہ کرتا ہے ، اور اﷲ کسی بھی ناسپاس نافرمان کو پسند نہیں کرتا ۔',\n",
              " 'بیشک جو لوگ ایمان لائے اور انہوں نے نیک اعمال کئے اور نماز قائم رکھی اور زکوٰۃ دیتے رہے ان کے لئے ان کے رب کے پاس ان کا اجر ہے ، اور ان پر آخرت میں نہ کوئی خوف ہوگا اور نہ وہ رنجیدہ ہوں گے ۔',\n",
              " 'اے ایمان والو ! اﷲ سے ڈرو اور جو کچھ بھی سود میں سے باقی رہ گیا ہے چھوڑ دو اگر تم صدقِ دل سے ایمان رکھتے ہو ۔',\n",
              " 'پھر اگر تم نے ایسا نہ کیا تو اﷲ اور اس کے رسول صلی اللہ علیہ وآلہ وسلم کی طرف سے اعلانِ جنگ پر خبردار ہو جاؤ ، اور اگر تم توبہ کر لو تو تمہارے لئے تمہارے اصل مال جائز ہیں ، نہ تم خود ظلم کرو اور نہ تم پر ظلم کیا جائے ۔',\n",
              " 'اور اگر قرض دار تنگدست ہو تو خوشحالی تک مہلت دی جانی چاہئے ، اور تمہارا قرض کو معاف کر دینا تمہارے لئے بہتر ہے اگر تمہیں معلوم ہو کہ غریب کی دل جوئی اﷲ کی نگاہ میں کیا مقام رکھتی ہے ۔',\n",
              " 'اور اس دن سے ڈرو جس میں تم اﷲ کی طرف لوٹائے جاؤ گے ، پھر ہر شخص کو جو کچھ عمل اس نے کیا ہے اس کی پوری پوری جزا دی جائے گی اور ان پر ظلم نہیں ہوگا ۔',\n",
              " 'اے ایمان والو ! جب تم کسی مقررہ مدت تک کے لئے آپس میں قرض کا معاملہ کرو تو اسے لکھ لیا کرو ،',\n",
              " 'اور تمہارے درمیان جو لکھنے والا ہو اسے چاہئے کہ انصاف کے ساتھ لکھے اور لکھنے والا لکھنے سے انکار نہ کرے جیسا کہ اسے اﷲ نے لکھنا سکھایا ہے ،',\n",
              " 'پس وہ لکھ دے یعنی شرع اور ملکی دستور کے مطابق وثیقہ نویسی کا حق پوری دیانت سے ادا کرے ،',\n",
              " 'اور مضمون وہ شخص لکھوائے جس کے ذمہ حق یعنی قرض ہو',\n",
              " 'اور اسے چاہئے کہ اﷲ سے ڈرے جو اس کا پروردگار ہے اور اس زرِ قرض میں سے لکھواتے وقت کچھ بھی کمی نہ کرے ،',\n",
              " 'پھر اگر وہ شخص جس کے ذمہ حق واجب ہوا ہے ناسمجھ یا ناتواں ہو یا خود مضمون لکھوانے کی صلاحیت نہ رکھتا ہو تو اس کے کارندے کو چاہئے کہ وہ انصاف کے ساتھ لکھوا دے ،',\n",
              " 'اور اپنے لوگوں میں سے دو مردوں کو گواہ بنا لو ، پھر اگر دونوں مرد میسر نہ ہوں تو ایک مرد اور دو عورتیں ہوں یہ ان لوگوں میں سے ہوں جنہیں تم گواہی کے لئے پسند کرتے ہو یعنی قابلِ اعتماد سمجھتے ہو تاکہ ان دو میں سے ایک عورت بھول جائے تو اس ایک کو دوسری یاد دلا دے ،',\n",
              " 'اور گواہوں کو جب بھی گواہی کے لئے بلایا جائے وہ انکار نہ کریں ، اور معاملہ چھوٹا ہو یا بڑا اسے اپنی میعاد تک لکھ رکھنے میں اکتایا نہ کرو ،',\n",
              " 'یہ تمہارا دستاویز تیار کر لینا اﷲ کے نزدیک زیادہ قرینِ انصاف ہے اور گواہی کے لئے مضبوط تر اور یہ اس کے بھی قریب تر ہے کہ تم شک میں مبتلا نہ ہو سوائے اس کے کہ دست بدست ایسی تجارت ہو جس کا لین دین تم آپس میں کرتے رہتے ہو تو تم پر اس کے نہ لکھنے کا کوئی گناہ نہیں ،',\n",
              " 'اور جب بھی آپس میں خرید و فروخت کرو تو گواہ بنا لیا کرو ،',\n",
              " 'اور نہ لکھنے والے کو نقصان پہنچایا جائے اور نہ گواہ کو ، اور اگر تم نے ایسا کیا تو یہ تمہاری حکم شکنی ہوگی ،',\n",
              " 'اور اﷲ سے ڈرتے رہو ، اور اﷲ تمہیں معاملات کی تعلیم دیتا ہے اور اﷲ ہر چیز کا خوب جاننے والا ہے ۔',\n",
              " 'اور اگر تم سفر پر ہو اور کوئی لکھنے والا نہ پاؤ تو باقبضہ رہن رکھ لیا کرو ، پھر اگر تم میں سے ایک کو دوسرے پر اعتماد ہو تو جس کی دیانت پر اعتماد کیا گیا اسے چاہئے کہ اپنی امانت ادا کر دے اور وہ اﷲ سے ڈرتا رہے جو اس کا پالنے والا ہے ، اور تم گواہی کو چُھپایا نہ کرو ، اور جو شخص گواہی چُھپاتا ہے تو یقینا اس کا دل گنہگار ہے ، اور اﷲ تمہارے اعمال کو خوب جاننے والا ہے ۔',\n",
              " 'جو کچھ آسمانوں میں اور زمین میں ہے سب اﷲ کے لئے ہے ، وہ باتیں جو تمہارے دلوں میں ہیں خواہ انہیں ظاہر کرو یا انہیں چھپاؤ اﷲ تم سے اس کا حساب لے گا ، پھر جسے وہ چاہے گا بخش دے گا اور جسے چاہے گا عذاب دے گا ، اور اﷲ ہر چیز پر کامل قدرت رکھتا ہے ۔',\n",
              " 'وہ رسول صلی اللہ علیہ وآلہ وسلم اس پر ایمان لائے یعنی اس کی تصدیق کی جو کچھ ان پر ان کے رب کی طرف سے نازل کیا گیا اور اہلِ ایمان نے بھی ، سب ہی دل سے اﷲ پر اور اس کے فرشتوں پر اور اس کی کتابوں پر اور اس کے رسولوں پر ایمان لائے ، نیز کہتے ہیں : ہم اس کے پیغمبروں میں سے کسی کے درمیان بھی ایمان لانے میں فرق نہیں کرتے ، اور اﷲ کے حضور عرض کرتے ہیں : ہم نے تیرا حکم سنا اور اطاعت قبول کی ، اے ہمارے رب ! ہم تیری بخشش کے طلب گار ہیں اور ہم سب کو تیری ہی طرف لوٹنا ہے ۔',\n",
              " 'اﷲ کسی جان کو اس کی طاقت سے بڑھ کر تکلیف نہیں دیتا ، اس نے جو نیکی کمائی اس کے لئے اس کا اجر ہے اور اس نے جو گناہ کمایا اس پر اس کا عذاب ہے ، اے ہمارے رب ! اگر ہم بھول جائیں یا خطا کر بیٹھیں تو ہماری گرفت نہ فرما ، اے ہمارے پروردگار ! اور ہم پر اتنا بھی بوجھ نہ ڈال جیسا تو نے ہم سے پہلے لوگوں پر ڈالا تھا ، اے ہمارے پروردگار ! اور ہم پر اتنا بوجھ بھی نہ ڈال جسے اٹھانے کی ہم میں طاقت نہیں ، اور ہمارے گناہوں سے درگزر فرما ، اور ہمیں بخش دے ، اور ہم پر رحم فرما ، تو ہی ہمارا کارساز ہے پس ہمیں کافروں کی قوم پر غلبہ عطا فرما',\n",
              " 'الف لام میم حقیقی معنی اﷲ اور رسول صلی اللہ علیہ وآلہ وسلم ہی بہتر جانتے ہیں ۔',\n",
              " 'اﷲ ، اس کے سوا کوئی لائقِ عبادت نہیں وہ ہمیشہ زندہ رہنے والا ہے سارے عالم کو اپنی تدبیر سے قائم رکھنے والا ہے ۔',\n",
              " 'اے حبیب ! اسی نے یہ کتاب آپ پر حق کے ساتھ نازل فرمائی ہے یہ ان سب کتابوں کی تصدیق کرنے والی ہے جو اس سے پہلے اتری ہیں اور اسی نے تورات اور انجیل نازل فرمائی ہے ۔',\n",
              " 'جیسے اس سے قبل لوگوں کی رہنمائی کے لئے کتابیں اتاری گئیں اور اب اسی طرح اس نے حق اور باطل میں امتیاز کرنے والا قرآن نازل فرمایا ہے ، بیشک جو لوگ اﷲ کی آیتوں کا انکار کرتے ہیں ان کے لئے سنگین عذاب ہے ، اور اﷲ بڑا غالب انتقام لینے والا ہے ۔',\n",
              " 'یقینا اﷲ پر زمین اور آسمان کی کوئی بھی چیز مخفی نہیں ۔',\n",
              " 'وہی ہے جو ماؤں کے رحموں میں تمہاری صورتیں جس طرح چاہتا ہے بناتا ہے ، اس کے سوا کوئی لائقِ پرستش نہیں وہ بڑا غالب بڑی حکمت والا ہے ۔',\n",
              " 'وہی ہے جس نے آپ پر کتاب نازل فرمائی جس میں سے کچھ آیتیں محکم یعنی ظاہراً بھی صاف اور واضح معنی رکھنے والی ہیں وہی احکام کتاب کی بنیاد ہیں اور دوسری آیتیں متشابہ یعنی معنی میں کئی احتمال اور اشتباہ رکھنے والی ہیں ، سو وہ لوگ جن کے دلوں میں کجی ہے اس میں سے صرف متشابہات کی پیروی کرتے ہیں فقط فتنہ پروری کی خواہش کے زیرِ اثر اور اصل مراد کی بجائے من پسند معنی مراد لینے کی غرض سے ، اور اس کی اصل مراد کو اﷲ کے سوا کوئی نہیں جانتا ، اور علم میں کامل پختگی رکھنے والے کہتے ہیں کہ ہم اس پر ایمان لائے ، ساری کتاب ہمارے رب کی طرف سے اتری ہے ، اور نصیحت صرف اہلِ دانش کو ہی نصیب ہوتی ہے ۔',\n",
              " 'اور عرض کرتے ہیں : اے ہمارے رب ! ہمارے دلوں میں کجی پیدا نہ کر اس کے بعد کہ تو نے ہمیں ہدایت سے سرفراز فرمایا ہے اور ہمیں خاص اپنی طرف سے رحمت عطا فرما ، بیشک تو ہی بہت عطا فرمانے والا ہے ۔',\n",
              " 'اے ہمارے رب ! بیشک تو اس دن کہ جس میں کوئی شک نہیں سب لوگوں کو جمع فرمانے والا ہے ، یقینا اﷲ اپنے وعدہ کے خلاف نہیں کرتا ۔',\n",
              " 'بیشک جنہوں نے کفر کیا نہ ان کے مال انہیں اﷲ کے عذاب سے کچھ بھی بچا سکیں گے اور نہ ان کی اولاد ، اور وہی لوگ دوزخ کا ایندھن ہیں ۔',\n",
              " 'ان کا بھی قومِ فرعون اور ان سے پہلی قوموں جیسا طریقہ ہے ، جنہوں نے ہماری آیتوں کو جھٹلایا تو اﷲ نے ان کے گناہوں کے باعث انہیں پکڑ لیا ، اور اﷲ سخت عذاب دینے والا ہے ۔',\n",
              " 'کافروں سے فرما دیں : تم عنقریب مغلوب ہو جاؤ گے اور جہنم کی طرف ہانکے جاؤ گے ، اور وہ بہت ہی برا ٹھکانا ہے ۔',\n",
              " 'بیشک تمہارے لئے ان دو جماعتوں میں ایک نشانی ہے جو میدانِ بدر میں آپس میں مقابل ہوئیں ، ایک جماعت نے اﷲ کی راہ میں جنگ کی اور دوسری کافر تھی وہ انہیں اپنی آنکھوں سے اپنے سے دوگنا دیکھ رہے تھے ، اور اﷲ اپنی مدد کے ذریعے جسے چاہتا ہے تقویت دیتا ہے ، یقینا اس واقعہ میں آنکھ والوں کے لئے بڑی عبرت ہے ۔',\n",
              " 'لوگوں کے لئے ان خواہشات کی محبت خوب آراستہ کر دی گئی ہے جن میں عورتیں اور اولاد اور سونے اور چاندی کے جمع کئے ہوئے خزانے اور نشان کئے ہوئے خوبصورت گھوڑے اور مویشی اور کھیتی شامل ہیں ، یہ سب دنیوی زندگی کا سامان ہے ، اور اﷲ کے پاس بہتر ٹھکانا ہے ۔',\n",
              " 'اے حبیب ! آپ فرما دیں : کیا میں تمہیں ان سب سے بہترین چیز کی خبر دوں ؟ ہاں پرہیزگاروں کے لئے ان کے رب کے پاس ایسی جنتیں ہیں جن کے نیچے نہریں بہتی ہیں وہ ان میں ہمیشہ رہیں گے ان کے لئے پاکیزہ بیویاں ہوں گی اور سب سے بڑی بات یہ کہ اﷲ کی طرف سے خوشنودی نصیب ہوگی ، اور اﷲ بندوں کو خوب دیکھنے والا ہے ۔',\n",
              " 'یہ وہ لوگ ہیں جو کہتے ہیں : اے ہمارے رب ! ہم یقینا ایمان لے آئے ہیں سو ہمارے گناہ معاف فرما دے اور ہمیں دوزخ کے عذاب سے بچا لے ۔',\n",
              " 'یہ لوگ صبر کرنے والے ہیں اور قول و عمل میں سچائی والے ہیں اور ادب و اطاعت میں جھکنے والے ہیں اور اﷲ کی راہ میں خرچ کرنے والے ہیں اور رات کے پچھلے پہر اٹھ کر اﷲ سے معافی مانگنے والے ہیں ۔',\n",
              " 'اﷲ نے اس بات پر گواہی دی کہ اس کے سوا کوئی لائقِ عبادت نہیں اور فرشتوں نے اور علم والوں نے بھی اور ساتھ یہ بھی کہ وہ ہر تدبیر عدل کے ساتھ فرمانے والا ہے ، اس کے سوا کوئی لائقِ پرستش نہیں وہی غالب حکمت والا ہے ۔',\n",
              " 'بیشک دین اﷲ کے نزدیک اسلام ہی ہے ، اور اہلِ کتاب نے جو اپنے پاس علم آجانے کے بعد اختلاف کیا وہ صرف باہمی حسد و عناد کے باعث تھا ، اور جو کوئی اﷲ کی آیتوں کا انکار کرے تو بیشک اﷲ حساب میں جلدی فرمانے والا ہے ۔',\n",
              " 'اے حبیب ! اگر پھر بھی آپ سے جھگڑا کریں تو فرما دیں کہ میں نے اور جس نے بھی میری پیروی کی اپنا روئے نیاز اﷲ کے حضور جھکا دیا ہے ، اور آپ اہلِ کتاب اور اَن پڑھ لوگوں سے فرما دیں : کیا تم بھی اﷲ کے حضور جھکتے ہو یعنی اسلام قبول کرتے ہو ؟ پھر اگر وہ فرمانبرداری اختیار کر لیں تو وہ حقیقتاً ہدایت پا گئے ، اور اگر منہ پھیر لیں تو آپ کے ذمہ فقط حکم پہنچا دینا ہی ہے ، اور اﷲ بندوں کو خوب دیکھنے والا ہے ۔',\n",
              " 'یقینا جو لوگ اﷲ کی آیتوں کا انکار کرتے ہیں اور انبیاءکو ناحق قتل کرتے ہیں اور لوگوں میں سے بھی انہیں قتل کرتے ہیں جو عدل و انصاف کا حکم دیتے ہیں سو آپ انہیں دردناک عذاب کی خبر سنا دیں ۔',\n",
              " 'یہ وہ لوگ ہیں جن کے اعمال دنیا اور آخرت دونوں میں غارت ہوگئے اور ان کا کوئی مددگار نہیں ہوگا ۔',\n",
              " 'کیا آپ نے ان لوگوں کو نہیں دیکھا جنہیں علمِ کتاب میں سے ایک حصہ دیا گیا وہ کتابِ الٰہی کی طرف بلائے جاتے ہیں تاکہ وہ کتاب ان کے درمیان نزاعات کا فیصلہ کر دے تو پھر ان میں سے ایک طبقہ منہ پھیر لیتا ہے اور وہ روگردانی کرنے والے ہی ہیں ۔',\n",
              " 'یہ روگردانی کی جرأت اس لئے کہ وہ کہتے ہیں کہ ہمیں گنتی کے چند دنوں کے سوا دوزخ کی آگ مَس نہیں کرے گی ، اور وہ اﷲ پر جو بہتان باندھتے رہتے ہیں اس نے ان کو اپنے دین کے بارے میں فریب میں مبتلا کر دیا ہے ۔',\n",
              " 'سو کیا حال ہو گا جب ہم ان کو اس دن جس کے بپا ہونے میں کوئی شک نہیں جمع کریں گے ، اور جس جان نے جو کچھ بھی اعمال میں سے کمایا ہو گا اسے اس کا پورا پورا بدلہ دیا جائے گا اور ان پر کوئی ظلم نہیں کیا جائے گا ۔',\n",
              " 'اے حبیب ! یوں عرض کیجئے : اے اﷲ ، سلطنت کے مالک ! تُو جسے چاہے سلطنت عطا فرما دے اور جس سے چاہے سلطنت چھین لے اور تُو جسے چاہے عزت عطا فرما دے اور جسے چاہے ذلّت دے ، ساری بھلائی تیرے ہی دستِ قدرت میں ہے ، بیشک تُو ہر چیز پر بڑی قدرت والا ہے ۔',\n",
              " 'تو ہی رات کو دن میں داخل کرتا ہے اور دن کو رات میں داخل کرتا ہے اور تُو ہی زندہ کو مُردہ سے نکالتا ہے اورمُردہ کو زندہ سے نکالتا ہے اور جسے چاہتا ہے بغیر حساب کے اپنی نوازشات سے بہرہ اندوز کرتا ہے ۔',\n",
              " 'مسلمانوں کو چاہئے کہ اہلِ ایمان کو چھوڑ کر کافروں کو دوست نہ بنائیں اور جو کوئی ایسا کرے گا اس کے لئے اﷲ کی دوستی میں سے کچھ نہیں ہوگا سوائے اس کے کہ تم ان کے شر سے بچنا چاہو ، اور اﷲ تمہیں اپنی ذات کے غضب سے ڈراتا ہے ، اور اﷲ ہی کی طرف لوٹ کر جانا ہے ۔',\n",
              " 'آپ فرما دیں کہ جو تمہارے سینوں میں ہے خواہ تم اسے چھپاؤ یا اسے ظاہر کر دو اﷲ اسے جانتا ہے ، اور جو کچھ آسمانوں اور زمین میں ہے وہ خوب جانتا ہے ، اور اﷲ ہر چیز پر بڑا قادر ہے ۔',\n",
              " 'جس دن ہر جان ہر اس نیکی کو بھی اپنے سامنے حاضر پا لے گی جو اس نے کی تھی اور ہر برائی کو بھی جو اس نے کی تھی ، تو وہ آرزو کرے گی : کاش ! میرے اور اس برائی یا اس دن کے درمیان بہت زیادہ فاصلہ ہوتا ، اور اﷲ تمہیں اپنی ذات کے غضب سے ڈراتا ہے ، اور اﷲ بندوں پر بہت مہربان ہے ۔',\n",
              " 'اے حبیب ! آپ فرما دیں : اگر تم اﷲ سے محبت کرتے ہو تو میری پیروی کرو تب اﷲ تمہیں اپنا محبوب بنا لے گا اور تمہارے لئے تمہارے گناہ معاف فرما دے گا ، اور اﷲ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'آپ فرما دیں کہ اﷲ اور رسول صلی اللہ علیہ وآلہ وسلم کی اطاعت کرو پھر اگر وہ روگردانی کریں تو اﷲ کافروں کو پسند نہیں کرتا ۔',\n",
              " 'بیشک اﷲ نے آدم علیہ السلام کو اور نوح علیہ السلام کو اور آلِ ابراہیم کو اور آلِ عمران کو سب جہان والوں پر بزرگی میں منتخب فرما لیا ۔',\n",
              " 'یہ ایک ہی نسل ہے ان میں سے بعض بعض کی اولاد ہیں ، اور اﷲ خوب سننے والا خوب جاننے والا ہے ۔',\n",
              " 'اور یاد کریں جب عمران کی بیوی نے عرض کیا : اے میرے رب ! جو میرے پیٹ میں ہے میں اسے دیگر ذمہ داریوں سے آزاد کر کے خالص تیری نذر کرتی ہوں سو تو میری طرف سے یہ نذرانہ قبول فرما لے ، بیشک تو خوب سننے خوب جاننے والا ہے ۔',\n",
              " 'پھر جب اس نے لڑکی جنی تو عرض کرنے لگی : مولا ! میں نے تو یہ لڑکی جنی ہے ، حالانکہ جو کچھ اس نے جنا تھا اﷲ اسے خوب جانتا تھا ، وہ بولی : اور لڑکا جو میں نے مانگا تھا ہرگز اس لڑکی جیسا نہیں ہو سکتا تھا جو اﷲ نے عطا کی ہے ، اور میں نے اس کا نام ہی مریم عبادت گزار رکھ دیا ہے اور بیشک میں اس کو اور اس کی اولاد کو شیطان مردود کے شر سے تیری پناہ میں دیتی ہوں ۔',\n",
              " 'سو اس کے رب نے اس مریم کو اچھی قبولیت کے ساتھ قبول فرما لیا اور اسے اچھی پرورش کے ساتھ پروان چڑھایا اور اس کی نگہبانی زکریا علیہ السلام کے سپرد کر دی ، جب بھی زکریا علیہ السلام اس کے پاس عبادت گاہ میں داخل ہوتے تو وہ اس کے پاس نئی سے نئی کھانے کی چیزیں موجود پاتے ، انہوں نے پوچھا : اے مریم ! یہ چیزیں تمہارے لئے کہاں سے آتی ہیں ؟ اس نے کہا : یہ رزق اﷲ کے پاس سے آتا ہے ، بیشک اﷲ جسے چاہتا ہے بے حساب رزق عطا کرتا ہے ۔',\n",
              " 'اسی جگہ زکریا علیہ السلام نے اپنے رب سے دعا کی ، عرض کیا : میرے مولا ! مجھے اپنی جناب سے پاکیزہ اولاد عطا فرما ، بیشک تو ہی دعا کا سننے والا ہے ۔',\n",
              " 'ابھی وہ حجرے میں کھڑے نماز ہی پڑھ رہے تھے یا دعا ہی کر رہے تھے کہ انہیں فرشتوں نے آواز دی : بیشک اﷲ آپ کو فرزند یحیٰی علیہ السلام کی بشارت دیتا ہے جو کلمۃ اﷲ یعنی عیسٰی علیہ السلام کی تصدیق کرنے والا ہو گا اور سردار ہو گا اور عورتوں کی رغبت سے بہت محفوظ ہو گا اور ہمارے خاص نیکوکار بندوں میں سے نبی ہو گا ۔',\n",
              " 'زکریاعلیہ السلام نے عرض کیا : اے میرے رب ! میرے ہاں لڑکا کیسے ہو گا ؟ درآنحالیکہ مجھے بڑھاپا پہنچ چکا ہے اور میری بیوی بھی بانجھ ہے ، فرمایا : اسی طرح اﷲ جو چاہتا ہے کرتا ہے ۔',\n",
              " 'عرض کیا : اے میرے رب ! میرے لئے کوئی نشانی مقرر فرما ، فرمایا : تمہارے لئے نشانی یہ ہے کہ تم تین دن تک لوگوں سے سوائے اشارے کے بات نہیں کر سکو گے ، اور اپنے رب کو کثرت سے یاد کرو اور شام اور صبح اس کی تسبیح کرتے رہو ۔',\n",
              " 'اور جب فرشتوں نے کہا : اے مریم ! بیشک اﷲ نے تمہیں منتخب کر لیا ہے اور تمہیں پاکیزگی عطا کی ہے اور تمہیں آج سارے جہان کی عورتوں پر برگزیدہ کر دیا ہے ۔',\n",
              " 'اے مریم ! تم اپنے رب کی بڑی عاجزی سے بندگی بجا لاتی رہو اور سجدہ کرو اور رکوع کرنے والوں کے ساتھ رکوع کیا کرو ۔',\n",
              " 'اے محبوب ! یہ غیب کی خبریں ہیں جو ہم آپ کی طرف وحی فرماتے ہیں ، حالانکہ آپ اس وقت ان کے پاس نہ تھے جب وہ قرعہ اندازی کے طور پر اپنے قلم پھینک رہے تھے کہ ان میں سے کون مریم علیہا السلام کی کفالت کرے اور نہ آپ اس وقت ان کے پاس تھے جب وہ آپس میں جھگڑ رہے تھے ۔',\n",
              " 'جب فرشتوں نے کہا : اے مریم ! بیشک اﷲ تمہیں اپنے پاس سے ایک کلمۂ خاص کی بشارت دیتا ہے جس کا نام مسیح عیسٰی بن مریم علیھما السلام ہوگا وہ دنیا اور آخرت دونوں میں قدر و منزلت والا ہو گا اور اﷲ کے خاص قربت یافتہ بندوں میں سے ہوگا ۔',\n",
              " 'اور وہ لوگوں سے گہوارے میں اور پختہ عمر میں یکساں گفتگو کرے گا اور وہ اﷲ کے نیکوکار بندوں میں سے ہو گا ۔',\n",
              " 'مریم علیہا السلام نے عرض کیا : اے میرے رب ! میرے ہاں کیسے لڑکا ہوگا درآنحالیکہ مجھے تو کسی شخص نے ہاتھ تک نہیں لگایا ، ارشاد ہوا : اسی طرح اﷲ جو چاہتا ہے پیدا فرماتا ہے ، جب کسی کام کے کرنے کا فیصلہ فرما لیتا ہے تو اس سے فقط اتنا فرماتا ہے کہ ’ ہو جا ‘ وہ ہو جاتا ہے ۔',\n",
              " 'اور اﷲ اسے کتاب اور حکمت اور تورات اور انجیل سب کچھ سکھائے گا ۔',\n",
              " 'اور وہ بنی اسرائیل کی طرف رسول ہو گا ان سے کہے گا کہ بیشک میں تمہارے پاس تمہارے رب کی جانب سے ایک نشانی لے کر آیا ہوں میں تمہارے لئے مٹی سے پرندے کی شکل جیسا ایک پُتلا بناتا ہوں پھر میں اس میں پھونک مارتا ہوں سو وہ اﷲ کے حکم سے فوراً اڑنے والا پرندہ ہو جاتا ہے ، اور میں مادرزاد اندھے اور سفید داغ والے کو شفایاب کرتا ہوں اور میں اﷲ کے حکم سے مُردے کو زندہ کر دیتا ہوں ، اور جو کچھ تم کھا کر آئے ہو اور جو کچھ تم اپنے گھروں میں جمع کرتے ہو میں تمہیں وہ سب کچھ بتا دیتا ہوں ، بیشک اس میں تمہارے لئے نشانی ہے اگر تم ایمان رکھتے ہو ۔',\n",
              " 'اور میں اپنے سے پہلے اتری ہوئی کتاب تورات کی تصدیق کرنے والا ہوں اور یہ اس لئے کہ تمہاری خاطر بعض ایسی چیزیں حلال کر دوں جو تم پر حرام کر دی گئی تھیں اور تمہارے پاس تمہارے رب کی طرف سے نشانی لے کر آیا ہوں ، سو اﷲ سے ڈرو اور میری اطاعت اختیار کر لو ۔',\n",
              " 'بیشک اﷲ میرا رب ہے اور تمہارا بھی وہی رب ہے پس اسی کی عبادت کرو ، یہی سیدھا راستہ ہے ۔',\n",
              " 'پھر جب عیسٰی علیہ السلام نے ان کا کفر محسوس کیا تو اس نے کہا : اﷲ کی طرف کون لوگ میرے مددگار ہیں ؟ تو اس کے مخلص ساتھیوں نے عرض کیا : ہم اﷲ کے دین کے مددگار ہیں ، ہم اﷲ پر ایمان لائے ہیں ، اور آپ گواہ رہیں کہ ہم یقیناً مسلمان ہیں ۔',\n",
              " 'اے ہمارے رب ! ہم اس کتاب پر ایمان لائے جو تو نے نازل فرمائی اور ہم نے اس رسول کی اتباع کی سو ہمیں حق کی گواہی دینے والوں کے ساتھ لکھ لے ۔',\n",
              " 'پھر یہودی کافروں نے عیسٰی علیہ السلام کے قتل کے لئے خفیہ سازش کی اور اﷲ نے عیسٰی علیہ السلام کو بچانے کے لئے مخفی تدبیر فرمائی ، اور اﷲ سب سے بہتر مخفی تدبیر فرمانے والا ہے ۔',\n",
              " 'جب اﷲ نے فرمایا : اے عیسٰی ! بیشک میں تمہیں پوری عمر تک پہنچانے والا ہوں اور تمہیں اپنی طرف آسمان پر اٹھانے والا ہوں اور تمہیں کافروں سے نجات دلانے والا ہوں اور تمہارے پیروکاروں کو ان کافروں پر قیامت تک برتری دینے والا ہوں ، پھر تمہیں میری ہی طرف لوٹ کر آنا ہے سو جن باتوں میں تم جھگڑتے تھے میں تمہارے درمیان ان کا فیصلہ کر دوں گا ۔',\n",
              " 'پھر جو لوگ کافر ہوئے انہیں دنیا اور آخرت دونوں میں سخت عذاب دوں گا اور ان کا کوئی مددگار نہ ہو گا ۔',\n",
              " 'اور جو لوگ ایمان لائے اور انہوں نے نیک عمل کئے تو اﷲ انہیں ان کا بھرپور اجر دے گا ، اور اﷲ ظالموں کو پسند نہیں کرتا ۔',\n",
              " 'یہ جو ہم آپ کو پڑھ کر سناتے ہیں یہ نشانیاں ہیں اور حکمت والی نصیحت ہے ۔',\n",
              " 'بیشک عیسٰی علیہ السلام کی مثال اﷲ کے نزدیک آدم علیہ السلام کی سی ہے ، جسے اس نے مٹی سے بنایا پھر اسے فرمایا ’ ہو جا ‘ وہ ہو گیا ۔',\n",
              " 'امت کی تنبیہ کے لئے فرمایا : یہ تمہارے رب کی طرف سے حق ہے پس شک کرنے والوں میں سے نہ ہو جانا ۔',\n",
              " 'پس آپ کے پاس علم آجانے کے بعد جو شخص عیسٰی علیہ السلام کے معاملے میں آپ سے جھگڑا کرے تو آپ فرما دیں کہ آجاؤ ہم مل کر اپنے بیٹوں کو اور تمہارے بیٹوں کو اور اپنی عورتوں کو اور تمہاری عورتوں کو اور اپنے آپ کو بھی اور تمہیں بھی ایک جگہ پر بلا لیتے ہیں ، پھر ہم مباہلہ یعنی گڑگڑا کر دعا کرتے ہیں اور جھوٹوں پر اﷲ کی لعنت بھیجتے ہیں ۔',\n",
              " 'بیشک یہی سچا بیان ہے ، اور کوئی بھی اﷲ کے سوا لائقِ عبادت نہیں ، اور بیشک اﷲ ہی تو بڑا غالب حکمت والا ہے ۔',\n",
              " 'پھر اگر وہ لوگ روگردانی کریں تو یقینا اﷲ فساد کرنے والوں کو خوب جانتا ہے ۔',\n",
              " 'آپ فرما دیں : اے اہلِ کتاب ! تم اس بات کی طرف آجاؤ جو ہمارے اور تمہارے درمیان یکساں ہے ، وہ یہ کہ ہم اﷲ کے سوا کسی کی عبادت نہیں کریں گے اور ہم اس کے ساتھ کسی کو شریک نہیں ٹھہرائیں گے اور ہم میں سے کوئی ایک دوسرے کو اﷲ کے سوا رب نہیں بنائے گا ، پھر اگر وہ روگردانی کریں تو کہہ دو کہ گواہ ہو جاؤ کہ ہم تو اﷲ کے تابع فرمان مسلمان ہیں ۔',\n",
              " 'اے اہلِ کتاب ! تم ابراہیم علیہ السلام کے بارے میں کیوں جھگڑتے ہو یعنی انہیں یہودی یا نصرانی کیوں ٹھہراتے ہو حالانکہ تورات اور انجیل جن پر تمہارے دونوں مذہبوں کی بنیاد ہے تو نازل ہی ان کے بعد کی گئی تھیں ، کیا تم اتنی بھی عقل نہیں رکھتے ۔',\n",
              " 'سن لو ! تم وہی لوگ ہو جو ان باتوں میں بھی جھگڑتے رہے ہو جن کا تمہیں کچھ نہ کچھ علم تھا مگر ان باتوں میں کیوں تکرار کرتے ہو جن کا تمہیں سرے سے کوئی علم ہی نہیں ، اور اﷲ جانتا ہے اور تم نہیں جانتے ۔',\n",
              " 'ابراہیم علیہ السلام نہ یہودی تھے اور نہ نصرانی وہ ہر باطل سے جدا رہنے والے سچے مسلمان تھے ، اور وہ مشرکوں میں سے بھی نہ تھے ۔',\n",
              " 'بیشک سب لوگوں سے بڑھ کر ابراہیم علیہ السلام کے قریب اور حق دار تو وہی لوگ ہیں جنہوں نے ان کے دین کی پیروی کی ہے اور وہ یہی نبی صلی اللہ علیہ وآلہ وسلم اور ان پر ایمان لانے والے ہیں ، اور اﷲ ایمان والوں کا مددگار ہے ۔',\n",
              " 'اے مسلمانو ! اہلِ کتاب میں سے ایک گروہ تو شدید خواہش رکھتا ہے کہ کاش وہ تمہیں گمراہ کر سکیں ، مگر وہ فقط اپنے آپ ہی کو گمراہی میں مبتلا کئے ہوئے ہیں اور انہیں اس بات کا شعور نہیں ۔',\n",
              " 'اے اہلِ کتاب ! تم اﷲ کی آیتوں کا انکار کیوں کر رہے ہو حالانکہ تم خود گواہ ہو یعنی تم اپنی کتابوں میں سب کچھ پڑھ چکے ہو ۔',\n",
              " 'اے اہلِ کتاب ! تم حق کو باطل کے ساتھ کیوں خلط ملط کرتے ہو اور حق کو کیوں چھپاتے ہو حالانکہ تم جانتے ہو ۔',\n",
              " 'اور اہلِ کتاب کا ایک گروہ لوگوں سے کہتا ہے کہ تم اس کتاب قرآن پر جو مسلمانوں پر نازل کی گئی ہے دن چڑھے یعنی صبح ایمان لایا کرو اور شام کو انکار کر دیا کرو تاکہ تمہیں دیکھ کر وہ بھی برگشتہ ہو جائیں ۔',\n",
              " 'اور کسی کی بات نہ مانو سوائے اس شخص کے جو تمہارے ہی دین کا پیرو ہو ، فرما دیں کہ بیشک ہدایت تو فقط ہدایتِ الٰہی ہے اور اپنے لوگوں سے مزید کہتے ہیں کہ یہ بھی ہرگز نہ ماننا کہ جیسی کتاب یا دِین تمہیں دیا گیا اس جیسا کسی اور کو بھی دیا جائے گا یا یہ کہ کوئی تمہارے رب کے پاس تمہارے خلاف حجت لا سکے گا ، فرما دیں : بیشک فضل تو اﷲ کے ہاتھ میں ہے ، جسے چاہتا ہے عطا فرماتا ہے ، اور اﷲ وسعت والا بڑے علم والا ہے ۔',\n",
              " 'وہ جسے چاہتا ہے اپنی رحمت کے ساتھ خاص فرما لیتا ہے ، اور اﷲ بڑے فضل والا ہے ۔',\n",
              " 'اور اہلِ کتاب میں ایسے بھی ہیں کہ اگر آپ اس کے پاس مال کا ڈھیر امانت رکھ دیں تو وہ آپ کو لوٹا دے گا اور انہی میں ایسے بھی ہیں کہ اگر اس کے پاس ایک دینار امانت رکھ دیں تو آپ کو وہ بھی نہیں لوٹائے گا سوائے اس کے کہ آپ اس کے سر پر کھڑے رہیں ، یہ اس لئے کہ وہ کہتے ہیں کہ اَن پڑھوں کے معاملہ میں ہم پر کوئی مؤاخذہ نہیں ، اور اﷲ پر جھوٹ باندھتے ہیں اور انہیں خود بھی معلوم ہے ۔',\n",
              " 'ہاں جو اپنا وعدہ پورا کرے اور تقویٰ اختیار کرے اس پر واقعی کوئی مؤاخذہ نہیں سو بیشک اﷲ پرہیز گاروں سے محبت فرماتا ہے ۔',\n",
              " 'بیشک جو لوگ اﷲ کے عہد اور اپنی قَسموں کا تھوڑی سی قیمت کے عوض سودا کر دیتے ہیں یہی وہ لوگ ہیں جن کے لئے آخرت میں کوئی حصہ نہیں اور نہ قیامت کے دن اﷲ ان سے کلام فرمائے گا اور نہ ہی ان کی طرف نگاہ فرمائے گا اور نہ انہیں پاکیزگی دے گا اور ان کے لئے دردناک عذاب ہو گا ۔',\n",
              " 'اور بیشک ان میں ایک گروہ ایسا بھی ہے جو کتاب پڑھتے ہوئے اپنی زبانوں کو مروڑ لیتے ہیں تاکہ تم ان کی الٹ پھیر کو بھی کتاب کا حصّہ سمجھو حالانکہ وہ کتاب میں سے نہیں ہے ، اور کہتے ہیں : یہ سب اﷲ کی طرف سے ہے ، اور وہ ہرگز اﷲ کی طرف سے نہیں ہے ، اور وہ اﷲ پر جھوٹ گھڑتے ہیں اور یہ انہیں خود بھی معلوم ہے ۔',\n",
              " 'کسی بشر کو یہ حق نہیں کہ اﷲ اسے کتاب اور حکمت اور نبوت عطا فرمائے پھر وہ لوگوں سے یہ کہنے لگے کہ تم اﷲ کو چھوڑ کر میرے بندے بن جاؤ بلکہ وہ تو یہ کہے گا تم اﷲ والے بن جاؤ اس سبب سے کہ تم کتاب سکھاتے ہو اور اس وجہ سے کہ تم خود اسے پڑھتے بھی ہو ۔',\n",
              " 'اور وہ پیغمبر تمہیں یہ حکم کبھی نہیں دیتا کہ تم فرشتوں اور پیغمبروں کو رب بنا لو ، کیا وہ تمہارے مسلمان ہو جانے کے بعد اب تمہیں کفر کا حکم دے گا ۔',\n",
              " 'اور اے محبوب ! وہ وقت یاد کریں جب اﷲ نے انبیاءسے پختہ عہد لیا کہ جب میں تمہیں کتاب اور حکمت عطا کر دوں پھر تمہارے پاس وہ سب پر عظمت والا رسول صلی اللہ علیہ وآلہ وسلم تشریف لائے جو ان کتابوں کی تصدیق فرمانے والا ہو جو تمہارے ساتھ ہوں گی تو ضرور بالضرور ان پر ایمان لاؤ گے اور ضرور بالضرور ان کی مدد کرو گے ، فرمایا : کیا تم نے اِقرار کیا اور اس شرط پر میرا بھاری عہد مضبوطی سے تھام لیا ؟ سب نے عرض کیا : ہم نے اِقرار کر لیا ، فرمایا کہ تم گواہ ہو جاؤ اور میں بھی تمہارے ساتھ گواہوں میں سے ہوں ۔',\n",
              " 'اب پوری نسل آدم کے لئے تنبیہاً فرمایا : پھر جس نے اس اقرار کے بعد روگردانی کی پس وہی لوگ نافرمان ہوں گے ۔',\n",
              " 'کیا یہ اﷲ کے دین کے سوا کوئی اور دین چاہتے ہیں اور جو کوئی بھی آسمانوں اور زمین میں ہے اس نے خوشی سے یا لاچاری سے بہرحال اسی کی فرمانبرداری اختیار کی ہے اور سب اسی کی طرف لوٹائے جائیں گے ۔',\n",
              " 'آپ فرمائیں : ہم اﷲ پر ایمان لائے ہیں اور جو کچھ ہم پر اتارا گیا ہے اور جو کچھ ابراہیم اور اسماعیل اور اسحاق اور یعقوب علیھم السلام اور ان کی اولاد پر اتارا گیا ہے اور جو کچھ موسٰی اور عیسٰی اور جملہ انبیاء علیھم السلام کو ان کے رب کی طرف سے عطا کیا گیا ہے سب پر ایمان لائے ہیں ، ہم ان میں سے کسی پر بھی ایمان میں فرق نہیں کرتے اور ہم اسی کے تابع فرمان ہیں ۔',\n",
              " 'اور جو کوئی اسلام کے سوا کسی اور دین کو چاہے گا تو وہ اس سے ہرگز قبول نہیں کیا جائے گا ، اور وہ آخرت میں نقصان اٹھانے والوں میں سے ہوگا ۔',\n",
              " 'اﷲ ان لوگوں کو کیونکر ہدایت فرمائے جو ایمان لانے کے بعد کافر ہو گئے حالانکہ وہ اس امر کی گواہی دے چکے تھے کہ یہ رسول سچا ہے اور ان کے پاس واضح نشانیاں بھی آچکی تھیں ، اور اﷲ ظالم قوم کو ہدایت نہیں فرماتا ۔',\n",
              " 'ایسے لوگوں کی سزا یہ ہے کہ ان پر اﷲ کی اور فرشتوں کی اور تمام انسانوں کی لعنت پڑتی رہے ۔',\n",
              " 'وہ اس پھٹکار میں ہمیشہ گرفتار رہیں گے اور ان سے اس عذاب میں کمی نہیں کی جائے گی اور نہ انہیں مہلت دی جائے گے ۔',\n",
              " 'سوائے ان لوگوں کے جنہوں نے اس کے بعد توبہ کر لی اور اپنی اصلاح کر لی ، تو بیشک اﷲ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'بیشک جن لوگوں نے اپنے ایمان کے بعد کفر کیا پھر وہ کفر میں بڑھتے گئے ان کی توبہ ہرگز قبول نہیں کی جائے گے ، اور وہی لوگ گمراہ ہیں ۔',\n",
              " 'بیشک جو لوگ کافر ہوئے اور حالتِ کفر میں ہی مر گئے سو ان میں سے کوئی شخص اگر زمین بھر سونا بھی اپنی نجات کے لئے معاوضہ میں دینا چاہے تو اس سے ہرگز قبول نہیں کیا جائے گا ، انہی لوگوں کے لئے دردناک عذاب ہے اور ان کا کوئی مددگار نہیں ہو سکے گا ۔',\n",
              " 'تم ہرگز نیکی کو نہیں پہنچ سکو گے جب تک تم اللہ کی راہ میں اپنی محبوب چیزوں میں سے خرچ نہ کرو ، اور تم جو کچھ بھی خرچ کرتے ہو بیشک اللہ اسے خوب جاننے والا ہے ۔',\n",
              " 'تورات کے اترنے سے پہلے بنی اسرائیل کے لئے ہر کھانے کی چیز حلال تھی سوائے ان چیزوں کے جو یعقوب علیہ السلام نے خود اپنے اوپر حرام کر لی تھیں ، فرما دیں : تورات لاؤ اور اسے پڑھو اگر تم سچے ہو ۔',\n",
              " 'پھر اس کے بعد بھی جو شخص اللہ پر جھوٹ گھڑے تو وہی لوگ ظالم ہیں ۔',\n",
              " 'فرما دیں کہ اللہ نے سچ فرمایا ہے ، سو تم ابراہیم علیہ السلام کے دین کی پیروی کرو جو ہر باطل سے منہ موڑ کر صرف اللہ کے ہوگئے تھے ، اور وہ مشرکوں میں سے نہیں تھے ۔',\n",
              " 'بیشک سب سے پہلا گھر جو لوگوں کی عبادت کے لئے بنایا گیا وہی ہے جو مکہّ میں ہے ، برکت والا ہے اور سارے جہان والوں کے لئے مرکزِ ہدایت ہے ۔',\n",
              " 'اس میں کھلی نشانیاں ہیں ان میں سے ایک ابراہیم علیہ السلام کی جائے قیام ہے ، اور جو اس میں داخل ہوگیا امان پا گیا ، اور اللہ کے لئے لوگوں پر اس گھر کا حج فرض ہے جو بھی اس تک پہنچنے کی استطاعت رکھتا ہو ، اور جو اس کا منکر ہو تو بیشک اللہ سب جہانوں سے بے نیاز ہے ۔',\n",
              " 'فرما دیں : اے اہلِ کتاب ! تم اللہ کی آیتوں کا انکار کیوں کرتے ہو ؟ اور اللہ تمہارے کاموں کا مشاہدہ فرما رہا ہے ۔',\n",
              " 'فرما دیں : اے اہلِ کتاب ! جو شخص ایمان لے آیا ہے تم اسے اللہ کی راہ سے کیوں روکتے ہو ؟ تم ان کی راہ میں بھی کجی چاہتے ہو حالانکہ تم اس کے حق ہونے پر خود گواہ ہو ، اور اللہ تمہارے اعمال سے بے خبر نہیں ۔',\n",
              " 'اے ایمان والو ! اگر تم اہلِ کتاب میں سے کسی گروہ کا بھی کہنا مانو گے تو وہ تمہارے ایمان لانے کے بعد پھر تمہیں کفر کی طرف لوٹا دیں گے ۔',\n",
              " 'اور تم اب کس طرح کفر کرو گے حالانکہ تم وہ خوش نصیب ہو کہ تم پر اللہ کی آیتیں تلاوت کی جاتی ہیں اور تم میں خود اللہ کے رسول صلی اللہ علیہ وآلہ وسلم موجود ہیں ، اور جو شخص اللہ کے دامن کو مضبوط پکڑ لیتا ہے تو اسے ضرور سیدھی راہ کی طرف ہدایت کی جاتی ہے ۔',\n",
              " 'اے ایمان والو ! اللہ سے ڈرا کرو جیسے اس سے ڈرنے کا حق ہے اور تمہاری موت صرف اسی حال پر آئے کہ تم مسلمان ہو ۔',\n",
              " 'اور تم سب مل کر اللہ کی رسی کو مضبوطی سے تھام لو اور تفرقہ مت ڈالو ، اور اپنے اوپر اللہ کی اس نعمت کو یاد کرو جب تم ایک دوسرے کے دشمن تھے تو اس نے تمہارے دلوں میں الفت پیدا کردی اور تم اس کی نعمت کے باعث آپس میں بھائی بھائی ہوگئے ، اور تم دوزخ کی آگ کے گڑھے کے کنارے پر پہنچ چکے تھے پھر اس نے تمہیں اس گڑھے سے بچا لیا ، یوں ہی اللہ تمہارے لئے اپنی نشانیاں کھول کر بیان فرماتا ہے تاکہ تم ہدایت پا جاؤ ۔',\n",
              " 'اور تم میں سے ایسے لوگوں کی ایک جماعت ضرور ہونی چاہئے جو لوگوں کو نیکی کی طرف بلائیں اور بھلائی کا حکم دیں اور برائی سے روکیں ، اور وہی لوگ بامراد ہیں ۔',\n",
              " 'اور ان لوگوں کی طرح نہ ہو جانا جو فرقوں میں بٹ گئے تھے اور جب ان کے پاس واضح نشانیاں آچکیں اس کے بعد بھی اختلاف کرنے لگے ، اور انہی لوگوں کے لئے سخت عذاب ہے ۔',\n",
              " 'جس دن کئی چہرے سفید ہوں گے اور کئی چہرے سیاہ ہوں گے ، تو جن کے چہرے سیاہ ہو جائیں گے ان سے کہا جائے گا : کیا تم نے ایمان لانے کے بعد کفر کیا ؟ تو جو کفر تم کرتے رہے تھے سواس کے عذاب کا مزہ چکھ لو ۔',\n",
              " 'اور جن لوگوں کے چہرے سفید روشن ہوں گے تو وہ اللہ کی رحمت میں ہوں گے اور وہ اس میں ہمیشہ رہیں گے ۔',\n",
              " 'یہ اللہ کی آیتیں ہیں جنہیں ہم آپ پر حق کے ساتھ پڑھتے ہیں ، اور اللہ جہان والوں پر ظلم نہیں چاہتا ۔',\n",
              " 'اور اللہ ہی کے لئے ہے جو کچھ آسمانوں اور زمین میں ہے اور سب کام اللہ ہی کی طرف لوٹائے جائیں گے ۔',\n",
              " 'تم بہترین اُمّت ہو جو سب لوگوں کی رہنمائی کے لئے ظاہر کی گئی ہے ، تم بھلائی کا حکم دیتے ہو اور برائی سے منع کرتے ہو اور اللہ پر ایمان رکھتے ہو ، اور اگر اہلِ کتاب بھی ایمان لے آتے تو یقیناً ان کے لئے بہتر ہوتا ، ان میں سے کچھ ایمان والے بھی ہیں اور ان میں سے اکثر نافرمان ہیں ۔',\n",
              " 'یہ لوگ ستانے کے سوا تمہارا کچھ نہیں بگاڑ سکیں گے ، اور اگر یہ تم سے جنگ کریں تو تمہارے سامنے پیٹھ پھیر جائیں گے ، پھر ان کی مدد بھی نہیں کی جائے گے ۔',\n",
              " 'وہ جہاں کہیں بھی پائے جائیں ان پر ذلّت مسلط کر دی گئی ہے سوائے اس کے کہ انہیں کہیں اللہ کے عہد سے یا لوگوں کے عہد سے پناہ دے دی جائے اور وہ اللہ کے غضب کے سزاوار ہوئے ہیں اور ان پر محتاجی مسلط کی گئی ہے ، یہ اس لئے کہ وہ اللہ کی آیتوں کا انکار کرتے تھے اور انبیاء کو ناحق قتل کرتے تھے ، کیونکہ وہ نافرمان ہو گئے تھے اور سرکشی میں حد سے بڑھ گئے تھے ۔',\n",
              " 'یہ سب برابر نہیں ہیں ، اہلِ کتاب میں سے کچھ لوگ حق پر بھی قائم ہیں وہ رات کی ساعتوں میں اللہ کی آیات کی تلاوت کرتے ہیں اور سر بسجود رہتے ہیں ۔',\n",
              " 'وہ اللہ پر اور آخرت کے دن پر ایمان لاتے ہیں اور بھلائی کا حکم دیتے ہیں اور برائی سے منع کرتے ہیں اور نیک کاموں میں تیزی سے بڑھتے ہیں ، اور یہی لوگ نیکوکاروں میں سے ہیں ۔',\n",
              " 'اور یہ لوگ جو نیک کام بھی کریں اس کی ناقدری نہیں کی جائے گے اور اللہ پرہیزگاروں کو خوب جاننے والا ہے ۔',\n",
              " 'یقینا جن لوگوں نے کفر کیا ہے نہ ان کے مال انہیں اللہ کے عذاب سے کچھ بھی بچا سکیں گے اور نہ ان کی اولاد ، اور وہی لوگ جہنمی ہیں ، جو اس میں ہمیشہ رہیں گے ۔',\n",
              " 'یہ لوگ جو مال بھی اس دنیا کی زندگی میں خرچ کرتے ہیں اس کی مثال اس ہوا جیسی ہے جس میں سخت پالا ہو اور وہ ایسی قوم کی کھیتی پر جا پڑے جو اپنی جانوں پر ظلم کرتی ہو اور وہ اسے تباہ کر دے ، اور اللہ نے ان پر کوئی ظلم نہیں کیا بلکہ وہ خود اپنی جانوں پر ظلم کرتے ہیں ۔',\n",
              " 'اے ایمان والو ! تم غیروں کو اپنا راز دار نہ بناؤ وہ تمہاری نسبت فتنہ انگیزی میں کبھی کمی نہیں کریں گے ، وہ تمہیں سخت تکلیف پہنچنے کی خواہش رکھتے ہیں ، بغض تو ان کی زبانوں سے خود ظاہر ہو چکا ہے ، اور جو عداوت ان کے سینوں نے چھپا رکھی ہے وہ اس سے بھی بڑھ کر ہے ۔ ہم نے تمہارے لئے نشانیاں واضح کر دی ہیں اگر تمہیں عقل ہو ۔',\n",
              " 'آگاہ ہو جاؤ ! تم وہ لوگ ہو کہ ان سے محبت رکھتے ہو اور وہ تمہیں پسند تک نہیں کرتے حالانکہ تم سب کتابوں پر ایمان رکھتے ہو ، اور جب وہ تم سے ملتے ہیں تو کہتے ہیں : ہم ایمان لے آئے ہیں ، اور جب اکیلے ہوتے ہیں تو تم پر غصے سے انگلیاں چباتے ہیں ، فرما دیں : مر جاؤ اپنی گھٹن میں ، بیشک اللہ دلوں کی پوشیدہ باتوں کو خوب جاننے والا ہے ۔',\n",
              " 'اگر تمہیں کوئی بھلائی پہنچے تو انہیں بری لگتی ہے اور تمہیں کوئی رنج پہنچے تو وہ اس سے خوش ہوتے ہیں ، اور اگر تم صبر کرتے رہو اور تقوٰی اختیار کئے رکھو تو ان کا فریب تمہیں کوئی نقصان نہیں پہنچا سکے گا ، جو کچھ وہ کر رہے ہیں بیشک اللہ اس پر احاطہ فرمائے ہوئے ہے ۔',\n",
              " 'اور وہ وقت یاد کیجئے جب آپ صبح سویرے اپنے درِ دولت سے روانہ ہو کر مسلمانوں کو غزوۂ احد کے موقع پر جنگ کے لئے مورچوں پر ٹھہرا رہے تھے ، اور اللہ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'جب تم میں سے بنو سلمہ خزرج اور بنوحارثہ اوس دو گروہوں کا ارادہ ہوا کہ بزدلی کر جائیں ، حالانکہ اللہ ان دونوں کا مدد گار تھا ، اور ایمان والوں کو اللہ ہی پر بھروسہ کرنا چاہئے ۔',\n",
              " 'اور اللہ نے بدر میں تمہاری مدد فرمائی حالانکہ تم اس وقت بالکل بے سرو سامان تھے پس اللہ سے ڈرا کرو تاکہ تم شکر گزار بن جاؤ ۔',\n",
              " 'جب آپ مسلمانوں سے فرما رہے تھے کہ کیا تمہارے لئے یہ کافی نہیں کہ تمہارا رب تین ہزار اتارے ہوئے فرشتوں کے ذریعے تمہاری مدد فرمائے ۔',\n",
              " 'ہاں اگر تم صبر کرتے رہو اور پرہیزگاری قائم رکھو اور وہ کفّار تم پر اسی وقت پورے جوش سے حملہ آور ہو جائیں تو تمہارا رب پانچ ہزار نشان والے فرشتوں کے ذریعے تمہاری مدد فرمائے گا ۔',\n",
              " 'اور اللہ نے اس مدد کو محض تمہارے لئے خوشخبری بنایا اور اس لئے کہ اس سے تمہارے دل مطمئن ہو جائیں ، اور مدد تو صرف اللہ ہی کی طرف سے ہوتی ہے جو بڑا غالب حکمت والا ہے ۔',\n",
              " 'مزید اس لئے کہ اللہ کافروں کے ایک گروہ کو ہلاک کر دے یا انہیں ذلیل کر دے سو وہ ناکام ہو کر واپس پلٹ جائیں ۔',\n",
              " 'اے حبیب ! اب آپ کا اس معاملہ سے کوئی تعلق نہیں چاہے تو اللہ انہیں توبہ کی توفیق دے یا انہیں عذاب دے کیونکہ وہ ظالم ہیں ۔',\n",
              " 'اور اللہ ہی کے لئے ہے جو کچھ آسمانوں میں اور زمین میں ہے ۔ وہ جسے چاہے بخش دے جسے چاہے عذاب دے ، اور اللہ نہایت بخشنے والا مہربان ہے ۔',\n",
              " 'اے ایمان والو ! دو گنا اور چوگنا کر کے سود مت کھایا کرو ، اور اللہ سے ڈرا کرو تاکہ تم فلاح پاؤ ۔',\n",
              " 'اور اس آگ سے ڈرو جو کافروں کے لئے تیار کی گئی ہے ۔',\n",
              " 'اور اللہ کی اور رسول صلی اللہ علیہ وآلہ وسلم کی فرمانبرداری کرتے رہو تاکہ تم پر رحم کیا جائے ۔',\n",
              " 'اور اپنے رب کی بخشش اور اس جنت کی طرف تیزی سے بڑھو جس کی وسعت میں سب آسمان اور زمین آجاتے ہیں ، جو پرہیزگاروں کے لئے تیار کی گئی ہے ۔',\n",
              " 'یہ وہ لوگ ہیں جو فراخی اور تنگی دونوں حالتوں میں خرچ کرتے ہیں اور غصہ ضبط کرنے والے ہیں اور لوگوں سے ان کی غلطیوں پر درگزر کرنے والے ہیں ، اور اللہ احسان کرنے والوں سے محبت فرماتا ہے ۔',\n",
              " 'اور یہ ایسے لوگ ہیں کہ جب کوئی برائی کر بیٹھتے ہیں یا اپنی جانوں پر ظلم کر بیٹھتے ہیں تو اللہ کا ذکر کرتے ہیں پھر اپنے گناہوں کی معافی مانگتے ہیں ، اور اللہ کے سوا گناہوں کی بخشش کون کرتا ہے ، اور پھر جو گناہ وہ کر بیٹھے تھے ان پر جان بوجھ کر اصرار بھی نہیں کرتے ۔',\n",
              " 'یہ وہ لوگ ہیں جن کی جزا ان کے رب کی طرف سے مغفرت ہے اور جنتیں ہیں جن کے نیچے نہریں رواں ہیں وہ ان میں ہمیشہ رہنے والے ہیں ، اور نیک عمل کرنے والوں کا کیا ہی اچھا صلہ ہے ۔',\n",
              " 'تم سے پہلے گذشتہ امتوں کے لئے قانونِ قدرت کے بہت سے ضابطے گزر چکے ہیں سو تم زمین میں چلا پھرا کرو اور دیکھا کرو کہ جھٹلانے والوں کا کیا انجام ہوا ۔',\n",
              " 'یہ قرآن لوگوں کے لئے واضح بیان ہے اور ہدایت ہے اور پرہیزگاروں کے لئے نصیحت ہے ۔',\n",
              " 'اور تم ہمت نہ ہارو اور نہ غم کرو اور تم ہی غالب آؤ گے اگر تم کامل ایمان رکھتے ہو ۔',\n",
              " 'اگر تمہیں اب کوئی زخم لگا ہے تو یاد رکھو کہ ان لوگوں کو بھی اسی طرح کا زخم لگ چکا ہے ، اور یہ دن ہیں جنہیں ہم لوگوں کے درمیان پھیرتے رہتے ہیں ، اور یہ گردشِ ا یّام اس لئے ہے کہ اللہ اہلِ ایمان کی پہچان کرا دے اور تم میں سے بعض کو شہادت کا رتبہ عطا کرے ، اور اللہ ظالموں کو پسند نہیں کرتا ۔',\n",
              " 'اور یہ اس لئے بھی ہے کہ اللہ ایمان والوں کو مزید نکھار دے یعنی پاک و صاف کر دے اور کافروں کو مٹا دے ۔',\n",
              " 'کیا تم یہ گمان کئے ہوئے ہو کہ تم یونہی جنت میں چلے جاؤ گے ؟ حالانکہ ابھی اللہ نے تم میں سے جہاد کرنے والوں کو پرکھا ہی نہیں ہے اور نہ ہی صبر کرنے والوں کو جانچا ہے ۔',\n",
              " 'اور تم تو اس کا سامنا کرنے سے پہلے شہادت کی موت کی تمنا کیا کرتے تھے ، سو اب تم نے اسے اپنی آنکھوں کے سامنے دیکھ لیا ہے ۔',\n",
              " 'اور محمد صلی اللہ علیہ وآلہ وسلم بھی تو رسول ہی ہیں نہ کہ خدا ، آپ سے پہلے بھی کئی پیغمبر مصائب اور تکلیفیں جھیلتے ہوئے اس دنیا سے گزر چکے ہیں ، پھر اگر وہ وفات فرما جائیں یا شہید کر دیئے جائیں تو کیا تم اپنے پچھلے مذہب کی طرف الٹے پاؤں پھر جاؤ گے یعنی کیا ان کی وفات یا شہادت کو معاذ اللہ دینِ اسلام کے حق نہ ہونے پر یا ان کے سچے رسول نہ ہونے پر محمول کرو گے ، اور جو کوئی اپنے الٹے پاؤں پھرے گا تو وہ اللہ کا ہرگز کچھ نہیں بگاڑے گا ، اور اللہ عنقریب مصائب پر ثابت قدم رہ کر شکر کرنے والوں کو جزا عطا فرمائے گا ۔',\n",
              " 'اور کوئی شخص اللہ کے حکم کے بغیر نہیں مر سکتا اس کا وقت لکھا ہوا ہے ، اور جو شخص دنیا کا انعام چاہتا ہے ہم اسے اس میں سے دے دیتے ہیں ، اور جو آخرت کا انعام چاہتا ہے ہم اسے اس میں سے دے دیتے ہیں ، اور ہم عنقریب شکر گزاروں کو خوب صلہ دیں گے ۔',\n",
              " 'اور کتنے ہی انبیاءایسے ہوئے جنہوں نے جہاد کیا ان کے ساتھ بہت سے اللہ والے اولیاء بھی شریک ہوئے ، تو نہ انہوں نے ان مصیبتوں کے باعث جو انہیں اللہ کی راہ میں پہنچیں ہمت ہاری اور نہ وہ کمزور پڑے اور نہ وہ جھکے ، اور اللہ صبر کرنے والوں سے محبت کرتا ہے ۔',\n",
              " 'اور ان کا کہنا کچھ نہ تھا سوائے اس التجا کے کہ اے ہمارے رب ! ہمارے گناہ بخش دے اور ہمارے کام میں ہم سے ہونے والی زیادتیوں سے درگزر فرما اور ہمیں اپنی راہ میں ثابت قدم رکھ اور ہمیں کافروں پر غلبہ عطا فرما ۔',\n",
              " 'پس اللہ نے انہیں دنیا کا بھی انعام عطا فرمایا اور آخرت کے بھی عمدہ اجر سے نوازا ، اور اللہ ان نیکو کاروں سے پیار کرتا ہے جو صرف اسی کو چاہتے ہیں ۔',\n",
              " 'اے ایمان والو ! اگر تم نے کافروں کا کہا مانا تو وہ تمہیں الٹے پاؤں کفر کی جانب پھیر دیں گے پھر تم نقصان اٹھاتے ہوئے پلٹو گے ۔',\n",
              " 'بلکہ اللہ تمہارا مولیٰ ہے اور وہ سب سے بہتر مدد فرمانے والا ہے ۔',\n",
              " 'ہم عنقریب کافروں کے دلوں میں تمہارا رعب ڈال دیں گے اس وجہ سے کہ انہوں نے اس چیز کو اللہ کا شریک ٹھہرایا ہے جس کے لئے اللہ نے کوئی سند نہیں اتاری اور ان کا ٹھکانا دوزخ ہے اور ظالموں کا وہ ٹھکانا بہت ہی برا ہے ۔',\n",
              " 'اور بیشک اللہ نے تمہیں اپنا وعدہ سچ کر دکھایا جب تم اس کے حکم سے انہیں قتل کر رہے تھے ، یہاں تک کہ تم نے بزدلی کی اور رسول صلی اللہ علیہ وآلہ وسلم کے حکم کے بارے میں جھگڑنے لگے اور تم نے اس کے بعد ان کی نافرمانی کی جب کہ اللہ نے تمہیں وہ فتح دکھا دی تھی جو تم چاہتے تھے ، تم میں سے کوئی دنیا کا خواہش مند تھا اور تم میں سے کوئی آخرت کا طلب گار تھا ، پھر اس نے تمہیں ان سے مغلوب کر کے پھیر دیا تاکہ وہ تمہیں آزمائے ، بعد ازاں اس نے تمہیں معاف کر دیا ، اور اللہ اہلِ ایمان پر بڑے فضل والا ہے ۔',\n",
              " 'جب تم افراتفری کی حالت میں بھاگے جا رہے تھے اور کسی کو مڑ کر نہیں دیکھتے تھے اور رسول صلی اللہ علیہ وآلہ وسلم اس جماعت میں کھڑے جو تمہارے پیچھے ثابت قدم رہی تھی تمہیں پکار رہے تھے پھر اس نے تمہیں غم پر غم دیا یہ نصیحت و تربیت تھی تاکہ تم اس پر جو تمہارے ہاتھ سے جاتا رہا اور اس مصیبت پر جو تم پر آن پڑی رنج نہ کرو ، اور اللہ تمہارے کاموں سے خبردار ہے ۔',\n",
              " 'پھر اس نے غم کے بعد تم پر تسکین کے لئے غنودگی کی صورت میں امان اتاری جو تم میں سے ایک جماعت پر چھا گئی اور ایک گروہ کو جو منافقوں کا تھا صرف اپنی جانوں کی فکر پڑی ہوئی تھی وہ اللہ کے ساتھ ناحق گمان کرتے تھے جو محض جاہلیت کے گمان تھے ، وہ کہتے ہیں : کیا اس کام میں ہمارے لئے بھی کچھ اختیار ہے ؟ فرما دیں کہ سب کام اللہ ہی کے ہاتھ میں ہے ، وہ اپنے دلوں میں وہ باتیں چھپائے ہوئے ہیں جو آپ پر ظاہر نہیں ہونے دیتے ۔ کہتے ہیں کہ اگر اس کام میں کچھ ہمارا اختیار ہوتا تو ہم اس جگہ قتل نہ کئے جاتے ۔ فرما دیں : اگر تم اپنے گھروں میں بھی ہوتے تب بھی جن کا مارا جانا لکھا جا چکا تھا وہ ضرور اپنی قتل گاہوں کی طرف نکل کر آجاتے ، اور یہ اس لئے کیا گیا ہے کہ جو کچھ تمہارے سینوں میں ہے اللہ اسے آزمائے اور جو وسوسے تمہارے دلوں میں ہیں انہیں خوب صاف کر دے ، اور اللہ سینوں کی بات خوب جانتا ہے ۔',\n",
              " 'بیشک جو لوگ تم میں سے اس دن بھاگ کھڑے ہوئے تھے جب دونوں فوجیں آپس میں گتھم گتھا ہو گئی تھیں تو انہیں محض شیطان نے پھسلا دیا تھا ، ان کے کسی عمل کے باعث جس کے وہ مرتکب ہوئے ، بیشک اللہ نے انہیں معاف فرما دیا ، یقینا اللہ بہت بخشنے والا بڑے حلم والا ہے ۔',\n",
              " 'اے ایمان والو ! تم ان کافروں کی طرح نہ ہو جاؤ جو اپنے ان بھائیوں کے بارے میں یہ کہتے ہیں جو کہیں سفر پر گئے ہوں یا جہاد کر رہے ہوں اور وہاں مر جائیں کہ اگر وہ ہمارے پاس ہوتے تو نہ مرتے اور نہ قتل کئے جاتے ، تاکہ اللہ اس گمان کو ان کے دلوں میں حسرت بنائے رکھے ، اور اللہ ہی زندہ رکھتا اور مارتا ہے ، اور اللہ تمہارے اعمال خوب دیکھ رہا ہے ۔',\n",
              " 'اور اگر تم اللہ کی راہ میں قتل کر دئیے جاؤ یا تمہیں موت آجائے تو اللہ کی مغفرت اور رحمت اس مال و متاع سے بہت بہتر ہے جو تم جمع کرتے ہو ۔',\n",
              " 'اور اگر تم مر جاؤ یا مارے جاؤ تو تم سب اللہ ہی کے حضور جمع کئے جاؤ گے ۔',\n",
              " 'اے حبیبِ والا صفات ! پس اللہ کی کیسی رحمت ہے کہ آپ ان کے لئے نرم طبع ہیں ، اور اگر آپ تُندخُو اور سخت دل ہوتے تو لوگ آپ کے گرد سے چھٹ کر بھاگ جاتے ، سو آپ ان سے درگزر فرمایا کریں اور ان کے لئے بخشش مانگا کریں اور اہم کاموں میں ان سے مشورہ کیا کریں ، پھر جب آپ پختہ ارادہ کر لیں تو اللہ پر بھروسہ کیا کریں ، بیشک اللہ توکّل والوں سے محبت کرتا ہے ۔',\n",
              " 'اگر اللہ تمہاری مدد فرمائے تو تم پر کوئی غالب نہیں آسکتا ، اور اگر وہ تمہیں بے سہارا چھوڑ دے تو پھر کون ایسا ہے جو اس کے بعد تمہاری مدد کر سکے ، اور مؤمنوں کو اللہ ہی پر بھروسہ رکھنا چاہئے ۔',\n",
              " 'اور کسی نبی کی نسبت یہ گمان ہی ممکن نہیں کہ وہ کچھ چھپائے گا ، اور جو کوئی کسی کا حق چھپاتا ہے تو قیامت کے دن اسے وہ لانا پڑے گا جو اس نے چھپایا تھا ، پھر ہر شخص کو اس کے عمل کا پورا بدلہ دیا جائے گا اور ان پر ظلم نہیں کیا جائے گا ۔',\n",
              " 'بھلا وہ شخص جو اللہ کی مرضی کے تابع ہو گیا اس شخص کی طرح کیسے ہو سکتا ہے جو اللہ کے غضب کا سزاوار ہوا اور اس کا ٹھکانا جہنم ہے ، اور وہ بہت ہی بری جگہ ہے ۔',\n",
              " 'اللہ کے حضور ان کے مختلف درجات ہیں ، اور اللہ ان کے اعمال کو خوب دیکھتا ہے ۔',\n",
              " 'بیشک اللہ نے مسلمانوں پر بڑا احسان فرمایا کہ ان میں انہی میں سے عظمت والا رسول صلی اللہ علیہ وآلہ وسلم بھیجا جو ان پر اس کی آیتیں پڑھتا اور انہیں پاک کرتا ہے اور انہیں کتاب و حکمت کی تعلیم دیتا ہے ، اگرچہ وہ لوگ اس سے پہلے کھلی گمراہی میں تھے ۔',\n",
              " 'کیا جب تمہیں ایک مصیبت آپہنچی حالانکہ تم اس سے دو چند دشمن کو پہنچا چکے تھے تو تم کہنے لگے کہ یہ کہاں سے آپڑی ؟ فرما دیں : یہ تمہاری اپنی ہی طرف سے ہے بیشک اللہ ہر چیز پر خوب قدرت رکھتا ہے ۔',\n",
              " 'اور اُس دن جو تکلیف تمہیں پہنچی جب دونوں لشکر باہم مقابل ہو گئے تھے سو وہ اللہ کے حکم ہی سے تھے اور یہ اس لئے کہ اللہ ایمان والوں کی پہچان کرا دے ۔',\n",
              " 'اور ایسے لوگوں کی بھی پہچان کرا دے جو منافق ہیں ، اور جب ان سے کہا گیا کہ آؤ اللہ کی راہ میں جنگ کرو یا دشمن کے حملے کا دفاع کرو ، تو کہنے لگے : اگر ہم جانتے کہ واقعۃً کسی ڈھب کی لڑائی ہوگی یا ہم اسے اللہ کی راہ میں جنگ جانتے تو ضرور تمہاری پیروی کرتے ، اس دن وہ ظاہری ایمان کی نسبت کھلے کفر سے زیادہ قریب تھے ، وہ اپنے منہ سے وہ باتیں کہتے ہیں جو ان کے دلوں میں نہیں ہیں ، اور اللہ ان باتوں کو خوب جانتا ہے جو وہ چھپا رہے ہیں ۔',\n",
              " 'یہ وہی لوگ ہیں جنہوں نے باوجود اس کے کہ خود گھروں میں بیٹھے رہے اپنے بھائیوں کی نسبت کہا کہ اگر وہ ہمارا کہا مانتے تو نہ مارے جاتے ، فرما دیں : تم اپنے آپ کو موت سے بچا لینا اگر تم سچے ہو ۔',\n",
              " 'اور جو لوگ اللہ کی راہ میں قتل کئے جائیں انہیں ہرگز مردہ خیال بھی نہ کرنا ، بلکہ وہ اپنے ربّ کے حضور زندہ ہیں انہیں جنت کی نعمتوں کا رزق دیا جاتا ہے ۔',\n",
              " 'وہ حیاتِ جاودانی کی ان نعمتوں پر فرحاں و شاداں رہتے ہیں جو اللہ نے انہیں اپنے فضل سے عطا فرما رکھی ہیں اور اپنے ان پچھلوں سے بھی جو تاحال ان سے نہیں مل سکے انہیں ایمان اور طاعت کی راہ پر دیکھ کر خوش ہوتے ہیں کہ ان پر بھی نہ کوئی خوف ہو گا اور نہ وہ رنجیدہ ہوں گے ۔',\n",
              " 'وہ اللہ کی تجلیّاتِ قُرب کی نعمت اور لذّاتِ وصال کے فضل سے مسرور رہتے ہیں اور اس پر بھی کہ اللہ ایمان والوں کا اجر ضائع نہیں فرماتا ۔',\n",
              " 'جن لوگوں نے زخم کھا چکنے کے بعد بھی اللہ اور رسول صلی اللہ علیہ وآلہ وسلم کے حکم پر لبیک کہا ، اُن میں جو صاحبانِ اِحسان ہیں اور پرہیزگار ہیں ، ان کے لئے بڑا اَجر ہے ۔',\n",
              " 'یہ وہ لوگ ہیں جن سے لوگوں نے کہا کہ مخالف لوگ تمہارے مقابلے کے لئے بڑی کثرت سے جمع ہو چکے ہیں سو ان سے ڈرو ، تو اس بات نے ان کے ایمان کو اور بڑھا دیا اور وہ کہنے لگے : ہمیں اللہ کافی ہے اور وہ کیا اچھا کارساز ہے ۔',\n",
              " 'پھر وہ مسلمان اللہ کے انعام اور فضل کے ساتھ واپس پلٹے انہیں کوئی گزند نہ پہنچی اور انہوں نے رضائے الٰہی کی پیروی کی اور اللہ بڑے فضل والا ہے ۔',\n",
              " 'بیشک یہ مخبر شیطان ہی ہے جو تمہیں اپنے دوستوں سے دھمکاتا ہے ، پس ان سے مت ڈرا کرو اور مجھ ہی سے ڈرا کرو اگر تم مومن ہو ۔',\n",
              " 'اے غمگسارِ عالم ! جو لوگ کفر کی مدد کرنے میں بہت تیزی کرتے ہیں وہ آپ کو غمزدہ نہ کریں ، وہ اللہ کے دین کا کچھ نہیں بگاڑ سکتے اور اللہ چاہتا ہے کہ ان کے لئے آخرت میں کوئی حصہ نہ رکھے اور ان کے لئے زبردست عذاب ہے ۔',\n",
              " 'بیشک جنہوں نے ایمان کے بدلے کفر خرید لیا ہے وہ اللہ کا کچھ نقصان نہیں کر سکتے اور ان کے لئے دردناک عذاب ہے ۔',\n",
              " 'اور کافر یہ گمان ہرگز نہ کریں کہ ہم جو انہیں مہلت دے رہے ہیں یہ ان کی جانوں کے لئے بہتر ہے ، ہم تو یہ مہلت انہیں صرف اس لئے دے رہے ہیں کہ وہ گناہ میں اور بڑھ جائیں ، اور ان کے لئے بالآخر ذلّت انگیز عذاب ہے ۔',\n",
              " 'اور اللہ مسلمانوں کو ہرگز اس حال پر نہیں چھوڑے گا جس پر تم اس وقت ہو جب تک وہ ناپاک کو پاک سے جدا نہ کر دے ، اور اللہ کی یہ شان نہیں کہ اے عامۃ الناس ! تمہیں غیب پر مطلع فرما دے لیکن اللہ اپنے رسولوں سے جسے چاہے غیب کے علم کے لئے چن لیتا ہے ، سو تم اللہ اور اس کے رسولوں پر ایمان لاؤ ، اور اگر تم ایمان لے آؤ اور تقویٰ اختیار کرو تو تمہارے لئے بڑا ثواب ہے ۔',\n",
              " 'اور جو لوگ اس مال و دولت میں سے دینے میں بخل کرتے ہیں جو اللہ نے انہیں اپنے فضل سے عطا کیا ہے وہ ہرگز اس بخل کو اپنے حق میں بہتر خیال نہ کریں ، بلکہ یہ ان کے حق میں برا ہے ، عنقریب روزِ قیامت انہیں گلے میں اس مال کا طوق پہنایا جائے گا جس میں وہ بخل کرتے رہے ہوں گے ، اور اللہ ہی آسمانوں اور زمین کا وارث ہے یعنی جیسے اب مالک ہے ایسے ہی تمہارے سب کے مر جانے کے بعد بھی وہی مالک رہے گا ، اور اللہ تمہارے سب کاموں سے آگاہ ہے ۔',\n",
              " 'بیشک اللہ نے ان لوگوں کی بات سن لی جو کہتے ہیں کہ اللہ محتاج ہے اور ہم غنی ہیں ، اب ہم ان کی ساری باتیں اور ان کا انبیاءکو ناحق قتل کرنا بھی لکھ رکھیں گے ، اور روزِ قیامت فرمائیں گے کہ اب تم جلا ڈالنے والے عذاب کا مزہ چکھو ۔',\n",
              " 'یہ ان اعمال کا بدلہ ہے جو تمہارے ہاتھ خود آگے بھیج چکے ہیں اور بیشک اللہ بندوں پر ظلم کرنے والا نہیں ہے ۔',\n",
              " 'جو لوگ یعنی یہود حیلہ جوئی کے طور پر یہ کہتے ہیں کہ اللہ نے ہمیں یہ حکم بھیجا تھا کہ ہم کسی پیغمبر پر ایمان نہ لائیں جب تک وہ اپنی رسالت کے ثبوت میں ایسی قربانی نہ لائے جسے آگ آکر کھا جائے ، آپ ان سے فرما دیں : بیشک مجھ سے پہلے بہت سے رسول واضح نشانیاں لے کر آئے اور اس نشانی کے ساتھ بھی آئے جو تم کہہ رہے ہو تو اس کے باوجود تم نے انہیں شہید کیوں کیا اگر تم اتنے ہی سچے ہو ۔',\n",
              " 'پھر بھی اگر آپ کو جھٹلائیں تو محبوب آپ رنجیدہ خاطر نہ ہوں آپ سے پہلے بھی بہت سے رسولوں کو جھٹلایا گیا جو واضح نشانیاں یعنی معجزات اور صحیفے اور روشن کتاب لے کر آئے تھے ۔',\n",
              " 'ہر جان موت کا مزہ چکھنے والی ہے ، اور تمہارے اجر پورے کے پورے تو قیامت کے دن ہی دئیے جائیں گے ، پس جو کوئی دوزخ سے بچا لیا گیا اور جنت میں داخل کیا گیا وہ واقعۃً کامیاب ہو گیا ، اور دنیا کی زندگی دھوکے کے مال کے سوا کچھ بھی نہیں ۔',\n",
              " 'اے مسلمانو ! تمہیں ضرور بالضرور تمہارے اموال اور تمہاری جانوں میں آزمایا جائے گا ، اور تمہیں بہر صورت ان لوگوں سے جنہیں تم سے پہلے کتاب دی گئی تھی اور ان لوگوں سے جو مشرک ہیں بہت سے اذیت ناک طعنے سننے ہوں گے ، اور اگر تم صبر کرتے رہو اور تقوٰی اختیار کئے رکھو تو یہ بڑی ہمت کے کاموں سے ہے ۔',\n",
              " 'اور جب اللہ نے ان لوگوں سے پختہ وعدہ لیا جنہیں کتاب عطا کی گئی تھی کہ تم ضرور اسے لوگوں سے صاف صاف بیان کرو گے اور جو کچھ اس میں بیان ہوا ہے اسے نہیں چھپاؤ گے تو انہوں نے اس عہد کو پسِ پشت ڈال دیا اور اس کے بدلے تھوڑی سی قیمت وصول کر لی ، سو یہ ان کی بہت ہی بُری خریداری ہے ۔',\n",
              " 'آپ ایسے لوگوں کو ہرگز نجات پانے والا خیال نہ کریں جو اپنی کارستانیوں پر خوش ہو رہے ہیں اور ناکردہ اعمال پر بھی اپنی تعریف کے خواہش مند ہیں ، دوبارہ تاکید کے لئے فرمایا : پس آپ انہیں ہرگز عذاب سے نجات پانے والا نہ سمجھیں ، اور ان کے لئے دردناک عذاب ہے ۔',\n",
              " 'اور سب آسمانوں اور زمین کی بادشاہی اللہ ہی کے لئے ہے اور اللہ ہر چیز پر قادر ہے سو تم اپنا دھیان اور توکّل اسی پر رکھو ۔',\n",
              " 'بیشک آسمانوں اور زمین کی تخلیق میں اور شب و روز کی گردش میں عقلِ سلیم والوں کے لئے اللہ کی قدرت کی نشانیاں ہیں ۔',\n",
              " 'یہ وہ لوگ ہیں جو سراپا نیاز بن کر کھڑے اور سراپا ادب بن کر بیٹھے اور ہجر میں تڑپتے ہوئے اپنی کروٹوں پر بھی اللہ کو یاد کرتے رہتے ہیں اور آسمانوں اور زمین کی تخلیق میں کارفرما اس کی عظمت اور حُسن کے جلووں میں فکر کرتے رہتے ہیں ، پھر اس کی معرفت سے لذت آشنا ہو کر پکار اٹھتے ہیں : اے ہمارے رب ! تو نے یہ سب کچھ بے حکمت اور بے تدبیر نہیں بنایا ، تو سب کوتاہیوں اور مجبوریوں سے پاک ہے پس ہمیں دوزخ کے عذاب سے بچا لے ۔',\n",
              " 'اے ہمارے رب ! بیشک تو جسے دوزخ میں ڈال دے تو تُو نے اسے واقعۃً رسوا کر دیا ، اور ظالموں کے لئے کوئی مددگار نہیں ہے ۔',\n",
              " 'اے ہمارے رب ! ہم تجھے بھولے ہوئے تھے سو ہم نے ایک ندا دینے والے کو سنا جو ایمان کی ندا دے رہا تھا کہ لوگو ! اپنے رب پر ایمان لاؤ تو ہم ایمان لے آئے ۔ اے ہمارے رب ! اب ہمارے گناہ بخش دے اور ہماری خطاؤں کو ہمارے نوشتۂ اعمال سے محو فرما دے اور ہمیں نیک لوگوں کی سنگت میں موت دے ۔',\n",
              " 'اے ہمارے رب ! اور ہمیں وہ سب کچھ عطا فرما جس کا تو نے ہم سے اپنے رسولوں کے ذریعے وعدہ فرمایا ہے اور ہمیں قیامت کے دن رسوا نہ کر ، بیشک تو وعدہ کے خلاف نہیں کرتا ۔',\n",
              " 'پھر ان کے رب نے ان کی دعا قبول فرما لی اور فرمایا : یقیناً میں تم میں سے کسی محنت والے کی مزدوری ضائع نہیں کرتا خواہ مرد ہو یا عورت ، تم سب ایک دوسرے میں سے ہی ہو ، پس جن لوگوں نے اللہ کے لئے وطن چھوڑ دیئے اور اسی کے باعث اپنے گھروں سے نکال دیئے گئے اور میری راہ میں ستائے گئے اور میری خاطر لڑے اور مارے گئے تو میں ضرور ان کے گناہ ان کے نامۂ اعمال سے مٹا دوں گا اور انہیں یقیناً ان جنتوں میں داخل کروں گا جن کے نیچے نہریں بہتی ہوں گی ، یہ اللہ کے حضور سے اجر ہے ، اور اللہ ہی کے پاس اس سے بھی بہتر اجر ہے ۔',\n",
              " 'اے اللہ کے بندے ! کافروں کا شہروں میں عیش و عشرت کے ساتھ گھومنا پھرنا تجھے کسی دھوکہ میں نہ ڈال دے ۔',\n",
              " 'یہ تھوڑی سی چند دنوں کی متاع ہے ، پھر ان کا ٹھکانا دوزخ ہوگا ، اور وہ بہت ہی برا ٹھکانا ہے ۔',\n",
              " 'لیکن جو لوگ اپنے رب سے ڈرتے رہے ان کے لئے بہشتیں ہیں جن کے نیچے نہریں بہہ رہی ہیں ، وہ ان میں ہمیشہ رہنے والے ہیں ، اللہ کے ہاں سے ان کی مہمانی ہے اور پھر اس کا حریمِ قُرب ، جلوۂ حُسن اور نعمتِ وصال ، الغرض جو کچھ بھی اللہ کے پاس ہے وہ نیک لوگوں کے لئے بہت ہی اچھا ہے ۔',\n",
              " 'اور بیشک کچھ اہلِ کتاب ایسے بھی ہیں جو اللہ پر ایمان رکھتے ہیں اور اس کتاب پر بھی ایمان لاتے ہیں جو تمہاری طرف نازل کی گئی ہے اور جو ان کی طرف نازل کی گئی اور ان کے دل اللہ کے حضور جھکے رہتے ہیں اور اللہ کی آیتوں کے عوض قلیل دام وصول نہیں کرتے ، یہ وہ لوگ ہیں جن کا اجر ان کے رب کے پاس ہے ، بیشک اللہ حساب میں جلدی فرمانے والا ہے ۔',\n",
              " 'اے ایمان والو ! صبر کرو اور ثابت قدمی میں دشمن سے بھی زیادہ محنت کرو اور جہاد کے لئے خوب مستعد رہو ، اور ہمیشہ اللہ کا تقوٰی قائم رکھو تاکہ تم کامیاب ہو سکو ۔',\n",
              " 'اے لوگو ! اپنے رب سے ڈرو جس نے تمہاری پیدائش کی ابتداء ایک جان سے کی پھر اسی سے اس کا جوڑ پیدا فرمایا پھر ان دونوں میں سے بکثرت مردوں اور عورتوں کی تخلیق کو پھیلا دیا ، اور ڈرو اس اللہ سے جس کے واسطے سے تم ایک دوسرے سے سوال کرتے ہو اور قرابتوں میں بھی تقوٰی اختیار کرو ، بیشک اللہ تم پر نگہبان ہے ۔',\n",
              " 'اور یتیموں کو ان کے مال دے دو اور بُری چیز کو عمدہ چیز سے نہ بدلا کرو اور نہ ان کے مال اپنے مالوں میں ملا کر کھایا کرو ، یقیناً یہ بہت بڑا گناہ ہے ۔',\n",
              " 'اور اگر تمہیں اندیشہ ہو کہ تم یتیم لڑکیوں کے بارے میں انصاف نہ کر سکو گے تو ان عورتوں سے نکاح کرو جو تمہارے لئے پسندیدہ اور حلال ہوں ، دو دو اور تین تین اور چار چار مگر یہ اجازت بشرطِ عدل ہے ، پھر اگر تمہیں اندیشہ ہو کہ تم زائد بیویوں میں عدل نہیں کر سکو گے تو صرف ایک ہی عورت سے نکاح کرو یا وہ کنیزیں جو شرعاً تمہاری ملکیت میں آئی ہوں ، یہ بات اس سے قریب تر ہے کہ تم سے ظلم نہ ہو ۔',\n",
              " 'اور عورتوں کو ان کے مَہر خوش دلی سے ادا کیا کرو ، پھر اگر وہ اس مَہر میں سے کچھ تمہارے لئے اپنی خوشی سے چھوڑ دیں تو تب اسے اپنے لئے سازگار اور خوشگوار سمجھ کر کھاؤ ۔',\n",
              " 'اور تم بے سمجھوں کو اپنے یا ان کے مال سپرد نہ کرو جنہیں اللہ نے تمہاری معیشت کی استواری کا سبب بنایا ہے ۔ ہاں انہیں اس میں سے کھلاتے رہو اور پہناتے رہو اور ان سے بھلائی کی بات کیا کرو ۔',\n",
              " 'اور یتیموں کی تربیتہً جانچ اور آزمائش کرتے رہو یہاں تک کہ نکاح کی عمر کو پہنچ جائیں پھر اگر تم ان میں ہوشیاری اور حُسنِ تدبیر دیکھ لو تو ان کے مال ان کے حوالے کر دو ، اور ان کے مال فضول خرچی اور جلد بازی میں اس اندیشے سے نہ کھا ڈالو کہ وہ بڑے ہو کر واپس لے جائیں گے ، اور جو کوئی خوشحال ہو وہ مالِ یتیم سے بالکل بچا رہے اور جو خود نادار ہو اسے صرف مناسب حد تک کھانا چاہئے ، اور جب تم ان کے مال ان کے سپرد کرنے لگو تو ان پر گواہ بنا لیا کرو ، اور حساب لینے والا اللہ ہی کافی ہے ۔',\n",
              " 'مردوں کے لئے اس مال میں سے حصہ ہے جو ماں باپ اور قریبی رشتہ داروں نے چھوڑا ہو اور عورتوں کے لئے بھی ماں باپ اور قریبی رشتہ داروں کے ترکہ میں سے حصہ ہے ۔ وہ ترکہ تھوڑا ہو یا زیادہ اللہ کا مقرر کردہ حصہ ہے ۔',\n",
              " 'اور اگر تقسیمِ وراثت کے موقع پر غیر وارث رشتہ دار اور یتیم اور محتاج موجود ہوں تو اس میں سے کچھ انہیں بھی دے دو اور ان سے نیک بات کہو ۔',\n",
              " 'اور یتیموں سے معاملہ کرنے والے لوگوں کو ڈرنا چاہئے کہ اگر وہ اپنے پیچھے ناتواں بچے چھوڑ جاتے تو مرتے وقت ان بچوں کے حال پر کتنے خوفزدہ اور فکر مند ہوتے ، سو انہیں یتیموں کے بارے میں اللہ سے ڈرتے رہنا چاہئے اور ان سے سیدھی بات کہنی چاہئے ۔',\n",
              " 'بیشک جو لوگ یتیموں کے مال ناحق طریقے سے کھاتے ہیں وہ اپنے پیٹوں میں نری آگ بھرتے ہیں ، اور وہ جلد ہی دہکتی ہوئی آگ میں جا گریں گے ۔',\n",
              " 'اللہ تمہیں تمہاری اولاد کی وراثت کے بارے میں حکم دیتا ہے کہ لڑکے کے لئے دو لڑکیوں کے برابر حصہ ہے ، پھر اگر صرف لڑکیاں ہی ہوں دو یا دو سے زائد تو ان کے لئے اس ترکہ کا دو تہائی حصہ ہے ، اور اگر وہ اکیلی ہو تو اس کے لئے آدھا ہے ، اور مُورِث کے ماں باپ کے لئے ان دونوں میں سے ہر ایک کو ترکہ کا چھٹا حصہ ملے گا بشرطیکہ مُورِث کی کوئی اولاد ہو ، پھر اگر اس میت مُورِث کی کوئی اولاد نہ ہو اور اس کے وارث صرف اس کے ماں باپ ہوں تو اس کی ماں کے لئے تہائی ہے اور باقی سب باپ کا حصہ ہے ، پھر اگر مُورِث کے بھائی بہن ہوں تو اس کی ماں کے لئے چھٹا حصہ ہے یہ تقسیم اس وصیت کے پورا کرنے کے بعد جو اس نے کی ہو یا قرض کی ادائیگی کے بعد ہو گی ، تمہارے باپ اور تمہارے بیٹے تمہیں معلوم نہیں کہ فائدہ پہنچانے میں ان میں سے کون تمہارے قریب تر ہے ، یہ تقسیم اللہ کی طرف سے فریضہ یعنی مقرر ہے ، بیشک اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اور تمہارے لئے اس مال کا آدھا حصہ ہے جو تمہاری بیویاں چھوڑ جائیں بشرطیکہ ان کی کوئی اولاد نہ ہو ، پھر اگر ان کی کوئی اولاد ہو تو تمہارے لئے ان کے ترکہ سے چوتھائی ہے یہ بھی اس وصیت کے پورا کرنے کے بعد جو انہوں نے کی ہو یا قرض کی ادائیگی کے بعد ، اور تمہاری بیویوں کا تمہارے چھوڑے ہوئے مال میں سے چوتھا حصہ ہے بشرطیکہ تمہاری کوئی اولاد نہ ہو ، پھر اگر تمہاری کوئی اولاد ہو تو ان کے لئے تمہارے ترکہ میں سے آٹھواں حصہ ہے تمہاری اس مال کی نسبت کی ہوئی وصیت پوری کرنے یا تمہارے قرض کی ادائیگی کے بعد ، اور اگر کسی ایسے مرد یا عورت کی وراثت تقسیم کی جا رہی ہو جس کے نہ ماں باپ ہوں نہ کوئی اولاد اور اس کا ماں کی طرف سے ایک بھائی یا ایک بہن ہو یعنی اخیافی بھائی یا بہن تو ان دونوں میں سے ہر ایک کے لئے چھٹا حصہ ہے ، پھر اگر وہ بھائی بہن ایک سے زیادہ ہوں تو سب ایک تہائی میں شریک ہوں گے یہ تقسیم بھی اس وصیت کے بعد ہو گی جو وارثوں کو نقصان پہنچائے بغیر کی گئی ہو یا قرض کی ادائیگی کے بعد ، یہ اللہ کی طرف سے حکم ہے ، اور اللہ خوب علم و حلم والا ہے ۔',\n",
              " 'یہ اللہ کی مقرر کردہ حدیں ہیں ، اور جو کوئی اللہ اور اس کے رسول صلی اللہ علیہ وآلہ وسلم کی فرمانبرداری کرے اسے وہ بہشتوں میں داخل فرمائے گا جن کے نیچے نہریں رواں ہیں ان میں ہمیشہ رہیں گے ، اور یہ بڑی کامیابی ہے ۔',\n",
              " 'اور جو کوئی اللہ اور اس کے رسول صلی اللہ علیہ وآلہ وسلم کی نافرمانی کرے اور اس کی حدود سے تجاوز کرے اسے وہ دوزخ میں داخل کرے گا جس میں وہ ہمیشہ رہے گا ، اور اس کے لئے ذلّت انگیز عذاب ہے ۔',\n",
              " 'اور تمہاری عورتوں میں سے جو بدکاری کا ارتکاب کر بیٹھیں تو ان پر اپنے لوگوں میں سے چار مردوں کی گواہی طلب کرو ، پھر اگر وہ گواہی دے دیں تو ان عورتوں کو گھروں میں بند کر دو یہاں تک کہ موت ان کے عرصۂ حیات کو پورا کر دے یا اللہ ان کے لئے کوئی راہ یعنی نیا حکم مقرر فرما دے ۔',\n",
              " 'اور تم میں سے جو بھی کوئی بدکاری کا ارتکاب کریں تو ان دونوں کو ایذا پہنچاؤ ، پھر اگر وہ توبہ کر لیں اور اپنی اصلاح کر لیں تو انہیں سزا دینے سے گریز کرو ، بیشک اللہ بڑا توبہ قبول فرمانے والا مہربان ہے ۔',\n",
              " 'اللہ نے صرف انہی لوگوں کی توبہ قبول کرنے کا وعدہ فرمایا ہے جو نادانی کے باعث برائی کر بیٹھیں پھر جلد ہی توبہ کر لیں پس اللہ ایسے لوگوں پر اپنی رحمت کے ساتھ رجوع فرمائے گا ، اور اللہ بڑے علم بڑی حکمت والا ہے ۔',\n",
              " 'اور ایسے لوگوں کے لئے توبہ کی قبولیت نہیں ہے جو گناہ کرتے چلے جائیں ، یہاں تک کہ ان میں سے کسی کے سامنے موت آپہنچے تو اس وقت کہے کہ میں اب توبہ کرتا ہوں اور نہ ہی ایسے لوگوں کے لئے ہے جو کفر کی حالت پر مریں ، ان کے لئے ہم نے دردناک عذاب تیار کر رکھا ہے ۔',\n",
              " 'اے ایمان والو ! تمہارے لئے یہ حلال نہیں کہ تم زبردستی عورتوں کے وارث بن جاؤ ، اور انہیں اس غرض سے نہ روک رکھو کہ جو مال تم نے انہیں دیا تھا اس میں سے کچھ واپس لے جاؤ سوائے اس کے کہ وہ کھلی بدکاری کی مرتکب ہوں ، اور ان کے ساتھ اچھے طریقے سے برتاؤ کرو ، پھر اگر تم انہیں نا پسند کرتے ہو تو ممکن ہے کہ تم کسی چیز کو ناپسند کرو اور اللہ اس میں بہت سی بھلائی رکھ دے ۔',\n",
              " 'اور اگر تم ایک بیوی کے بدلے دوسری بیوی بدلنا چاہو اور تم اسے ڈھیروں مال دے چکے ہو تب بھی اس میں سے کچھ واپس مت لو ، کیا تم ناحق الزام اور صریح گناہ کے ذریعے وہ مال واپس لینا چاہتے ہو ۔',\n",
              " 'اور تم اسے کیسے واپس لے سکتے ہو حالانکہ تم ایک دوسرے سے پہلو بہ پہلو مل چکے ہو اور وہ تم سے پختہ عہد بھی لے چکی ہیں ۔',\n",
              " 'اور ان عورتوں سے نکاح نہ کرو جن سے تمہارے باپ دادا نکاح کر چکے ہوں مگر جو اس حکم سے پہلے گزر چکا وہ معاف ہے ، بیشک یہ بڑی بے حیائی اور غضب کا باعث ہے اور بہت بری روِش ہے ۔',\n",
              " 'تم پر تمہاری مائیں اور تمہاری بیٹیاں اور تمہاری بہنیں اور تمہاری پھوپھیاں اور تمہاری خالائیں اور بھتیجیاں اور بھانجیاں اور تمہاری وہ مائیں جنہوں نے تمہیں دودھ پلایا ہو اور تمہاری رضاعت میں شریک بہنیں اور تمہاری بیویوں کی مائیں سب حرام کر دی گئی ہیں ، اور اسی طرح تمہاری گود میں پرورش پانے والی وہ لڑکیاں جو تمہاری ان عورتوں کے بطن سے ہیں جن سے تم صحبت کر چکے ہو بھی حرام ہیں ، پھر اگر تم نے ان سے صحبت نہ کی ہو تو تم پر ان کی لڑکیوں سے نکاح کرنے میں کوئی حرج نہیں ، اور تمہارے ان بیٹوں کی بیویاں بھی تم پر حرام ہیں جو تمہاری پشت سے ہیں ، اور یہ بھی حرام ہے کہ تم دو بہنوں کو ایک ساتھ نکاح میں جمع کرو سوائے اس کے کہ جو دورِ جہالت میں گزر چکا ۔ بیشک اللہ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'اور شوہر والی عورتیں بھی تم پرحرام ہیں سوائے ان جنگی قیدی عورتوں کے جو تمہاری مِلک میں آجائیں ، ان احکامِ حرمت کو اللہ نے تم پر فرض کر دیا ہے ، اور ان کے سوا سب عورتیں تمہارے لئے حلال کر دی گئی ہیں تاکہ تم اپنے اموال کے ذریعے طلبِ نکاح کرو پاک دامن رہتے ہوئے نہ کہ شہوت رانی کرتے ہوئے ، پھر ان میں سے جن سے تم نے اس مال کے عوض فائدہ اٹھایا ہے انہیں ان کا مقرر شدہ مَہر ادا کر دو ، اور تم پر اس مال کے بارے میں کوئی گناہ نہیں جس پر تم مَہر مقرر کرنے کے بعد باہم رضا مند ہو جاؤ ، بیشک اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اور تم میں سے جو کوئی اتنی استطاعت نہ رکھتا ہو کہ آزاد مسلمان عورتوں سے نکاح کر سکے تو ان مسلمان کنیزوں سے نکاح کرلے جو شرعاً تمہاری ملکیت میں ہیں ، اور اللہ تمہارے ایمان کی کیفیت کو خوب جانتا ہے ، تم سب ایک دوسرے کی جنس میں سے ہی ہو ، پس ان کنیزوں سے ان کے مالکوں کی اجازت کے ساتھ نکاح کرو اور انہیں ان کے مَہر حسبِ دستور ادا کرو درآنحالیکہ وہ عفت قائم رکھتے ہوئے قیدِ نکاح میں آنے والی ہوں نہ بدکاری کرنے والی ہوں اور نہ درپردہ آشنائی کرنے والی ہوں ، پس جب وہ نکاح کے حصار میں آجائیں پھر اگر بدکاری کی مرتکب ہوں تو ان پر اس سزا کی آدھی سزا لازم ہے جو آزاد کنواری عورتوں کے لئے مقرر ہے ، یہ اجازت اس شخص کے لئے ہے جسے تم میں سے گناہ کے ارتکاب کا اندیشہ ہو ، اور اگر تم صبر کرو تو یہ تمہارے حق میں بہتر ہے ، اور اللہ بخشنے والا مہر بان ہے ۔',\n",
              " 'اللہ چاہتا ہے کہ تمہارے لئے اپنے احکام کی وضاحت فرما دے اور تمہیں ان نیک لوگوں کی راہوں پر چلائے جو تم سے پہلے ہوگزرے ہیں اور تمہارے اوپر رحمت کے ساتھ رجوع فرمائے ، اور اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اور اللہ تم پر مہربانی فرمانا چاہتا ہے ، اور جو لوگ خواہشاتِ نفسانی کی پیروی کر رہے ہیں وہ چاہتے ہیں کہ تم راہِ راست سے بھٹک کر بہت دور جا پڑو ۔',\n",
              " 'اللہ چاہتا ہے کہ تم سے بوجھ ہلکا کر دے ، اور اِنسان کمزور پیدا کیا گیا ہے ۔',\n",
              " 'اے ایمان والو ! تم ایک دوسرے کا مال آپس میں ناحق طریقے سے نہ کھاؤ سوائے اس کے کہ تمہاری باہمی رضا مندی سے کوئی تجارت ہو ، اور اپنی جانوں کو مت ہلاک کرو ، بیشک اللہ تم پر مہربان ہے ۔',\n",
              " 'اور جو کوئی تعدی اور ظلم سے ایسا کرے گا تو ہم عنقریب اسے دوزخ کی آگ میں ڈال دیں گے ، اور یہ اللہ پر بالکل آسان ہے ۔',\n",
              " 'اگر تم کبیرہ گناہوں سے جن سے تمہیں روکا گیا ہے بچتے رہو تو ہم تم سے تمہاری چھوٹی برائیاں مٹا دیں گے اور تمہیں عزت والی جگہ میں داخل فرما دیں گے ۔',\n",
              " 'اور تم اس چیز کی تمنا نہ کیا کرو جس میں اللہ نے تم میں سے بعض کو بعض پر فضیلت دی ہے ، مردوں کے لئے اس میں سے حصہ ہے جو انہوں نے کمایا ، اور عورتوں کے لئے اس میں سے حصہ ہے جو انہوں نے کمایا ، اور اللہ سے اس کا فضل مانگا کرو ، بیشک اللہ ہر چیز کو خوب جاننے والا ہے ۔',\n",
              " 'اور ہم نے سب کے لئے ماں باپ اور قریبی رشتہ داروں کے چھوڑے ہوئے مال میں حق دار یعنی وارث مقرر کر دیئے ہیں ، اور جن سے تمہارا معاہدہ ہو چکا ہے سو اُنہیں ان کا حصہ دے دو ، بیشک اللہ ہر چیز کا مشاہدہ فرمانے والا ہے ۔',\n",
              " 'مرد عورتوں پر محافظ و منتظِم ہیں اس لئے کہ اللہ نے ان میں سے بعض کو بعض پر فضیلت دی ہے اور اس وجہ سے بھی کہ مرد ان پر اپنے مال خرچ کرتے ہیں ، پس نیک بیویاں اطاعت شعار ہوتی ہیں شوہروں کی عدم موجودگی میں اللہ کی حفاظت کے ساتھ اپنی عزت کی حفاظت کرنے والی ہوتی ہیں ، اور تمہیں جن عورتوں کی نافرمانی و سرکشی کا اندیشہ ہو تو انہیں نصیحت کرو اور اگر نہ سمجھیں تو انہیں خواب گاہوں میں خود سے علیحدہ کر دو اور اگر پھر بھی اصلاح پذیر نہ ہوں تو انہیں تادیباً ہلکا سا مارو ، پھر اگر وہ تمہاری فرمانبردار ہو جائیں تو ان پر ظلم کا کوئی راستہ تلاش نہ کرو ، بیشک اللہ سب سے بلند سب سے بڑا ہے ۔',\n",
              " 'اور اگر تمہیں ان دونوں کے درمیان مخالفت کا اندیشہ ہو تو تم ایک مُنصِف مرد کے خاندان سے اور ایک مُنصِف عورت کے خاندان سے مقرر کر لو ، اگر وہ دونوں مُنصِف صلح کرانے کا اِرادہ رکھیں تو اللہ ان دونوں کے درمیان موافقت پیدا فرما دے گا ، بیشک اللہ خوب جاننے والا خبردار ہے ۔',\n",
              " 'اور تم اللہ کی عبادت کرو اور اس کے ساتھ کسی کو شریک نہ ٹھہراؤ اور ماں باپ کے ساتھ بھلائی کرو اور رشتہ داروں اور یتیموں اور محتاجوں سے اور نزدیکی ہمسائے اور اجنبی پڑوسی اور ہم مجلس اور مسافر سے ، اور جن کے تم مالک ہو چکے ہو ، ان سے نیکی کیا کرو ، بیشک اللہ اس شخص کو پسند نہیں کرتا جو تکبرّ کرنے والا مغرور فخر کرنے والا خود بین ہو ۔',\n",
              " 'جو لوگ خود بھی بخل کرتے ہیں اور لوگوں کو بھی بخل کا حکم دیتے ہیں اور اس نعمت کو چھپاتے ہیں جواللہ نے انہیں اپنے فضل سے عطا کی ہے ، اور ہم نے کافروں کے لئے ذلت انگیز عذاب تیار کر رکھا ہے ۔',\n",
              " 'اور جو لوگ اپنے مال لوگوں کے دکھاوے کے لئے خرچ کرتے ہیں اور نہ اللہ پر ایمان رکھتے ہیں اور نہ یومِ آخرت پر ، اور شیطان جس کا بھی ساتھی ہوگیا تو وہ برا ساتھی ہے ۔',\n",
              " 'اور ان کا کیا نقصان تھا اگر وہ اللہ پر اور یومِ آخرت پر ایمان لے آتے اور جو کچھ اللہ نے انہیں دیا تھا اس میں سے اس کی راہ میں خرچ کرتے ، اور اللہ ان کے حال سے خوب واقف ہے ۔',\n",
              " 'بیشک اللہ ذرّہ برابر بھی ظلم نہیں کرتا ، اور اگر کوئی نیکی ہو تو اسے دوگنا کر دیتا ہے اور اپنے پاس سے بڑا اجر عطا فرماتا ہے ۔',\n",
              " 'پھر اس دن کیا حال ہوگا جب ہم ہر امت سے ایک گواہ لائیں گے اور اے حبیب ! ہم آپ کو ان سب پر گواہ لائیں گے ۔',\n",
              " 'اس دن وہ لوگ جنہوں نے کفر کیا اور رسول صلی اللہ علیہ وآلہ وسلم کی نافرمانی کی ، آرزو کریں گے کہ کاش انہیں مٹی میں دبا کر ان پر زمین برابر کر دی جاتی ، اور وہ اللہ سے کوئی بات نہ چھپا سکیں گے ۔',\n",
              " 'اے ایمان والو ! تم نشہ کی حالت میں نماز کے قریب مت جاؤ یہاں تک کہ تم وہ بات سمجھنے لگو جو کہتے ہو اور نہ حالتِ جنابت میں نماز کے قریب جاؤ تا آنکہ تم غسل کر لو سوائے اس کے کہ تم سفر میں راستہ طے کر رہے ہو ، اور اگر تم بیمار ہو یا سفر میں ہو یا تم میں سے کوئی قضائے حاجت سے لوٹے یا تم نے اپنی عورتوں سے مباشرت کی ہو پھر تم پانی نہ پاسکو تو تم پاک مٹی سے تیمم کر لو پس اپنے چہروں اور اپنے ہاتھوں پر مسح کر لیا کرو ، بیشک اللہ معاف فرمانے والا بہت بخشنے والا ہے ۔',\n",
              " 'کیا آپ نے ان لوگوں کو نہیں دیکھا جنہیں آسمانی کتاب کا ایک حصہ عطا کیا گیا وہ گمراہی خریدتے ہیں اور چاہتے ہیں کہ تم بھی سیدھے راستے سے بہک جاؤ ۔',\n",
              " 'اور اللہ تمہارے دشمنوں کو خوب جانتا ہے ، اور اللہ بطور کارساز کافی ہے اور اللہ بطور مددگار کافی ہے ۔',\n",
              " 'اور کچھ یہودی تورات کے کلمات کو اپنے اصل مقامات سے پھیر دیتے ہیں اور کہتے ہیں : ہم نے سن لیا اور نہیں مانا ، اور یہ بھی کہتے ہیں : سنیئے ! معاذ اللہ ! آپ سنوائے نہ جائیں ، اور اپنی زبانیں مروڑ کر دین میں طعنہ زنی کرتے ہوئے ” رَاعِنَا “ کہتے ہیں ، اور اگر وہ لوگ اس کی جگہ یہ کہتے کہ ہم نے سنا اور ہم نے اطاعت کی اور حضور ! ہماری گزارش سنئے اور ہماری طرف نظرِ کرم فرمائیے تو یہ اُن کے لئے بہتر ہوتا اور یہ قول بھی درست اور مناسب ہوتا ، لیکن اللہ نے ان کے کفر کے باعث ان پر لعنت کی سو تھوڑے لوگوں کے سوا وہ ایمان نہیں لاتے ۔',\n",
              " 'اے اہلِ کتاب ! اس کتاب پر ایمان لاؤ جو ہم نے اب اپنے حبیب محمد صلی اللہ علیہ وآلہ وسلم پر اتاری ہے جو اس کتاب کی اصلاً تصدیق کرتی ہے جو تمہارے پاس ہے ، اس سے قبل کہ ہم بعض چہروں کے نقوش کو مٹا دیں اور انہیں ان کی پشت کی حالت پر پھیر دیں یا ان پر اسی طرح لعنت کریں جیسے ہم نے ہفتہ کے دن نافرمانی کرنے والوں پر لعنت کی تھی اور اللہ کا حکم پورا ہو کر ہی رہتا ہے ۔',\n",
              " 'بیشک اللہ اِس بات کو نہیں بخشتا کہ اس کے ساتھ شرک کیا جائے اور اس سے کم تر جو گناہ بھی ہو جس کے لئے چاہتا ہے بخش دیتا ہے ، اور جس نے اللہ کے ساتھ شرک کیا اس نے واقعۃً زبردست گناہ کا بہتان باندھا ۔',\n",
              " 'کیا آپ نے ایسے لوگوں کو نہیں دیکھا جو خود کو پاک ظاہر کرتے ہیں ، بلکہ اللہ ہی جسے چاہتا ہے پاک فرماتا ہے اور ان پر ایک دھاگے کے برابر بھی ظلم نہیں کیا جائے گا ۔',\n",
              " 'آپ دیکھئے وہ اللہ پر کیسے جھوٹا بہتان باندھتے ہیں ، اور ان کے عذاب کے لئے یہی کھلا گناہ کافی ہے ۔',\n",
              " 'کیا آپ نے ان لوگوں کو نہیں دیکھا جنہیں آسمانی کتاب کا حصہ دیا گیا ہے پھر بھی وہ بتوں اور شیطان پر ایمان رکھتے ہیں اور کافروں کے بارے میں کہتے ہیں کہ مسلمانوں کی نسبت یہ کافر زیادہ سیدھی راہ پر ہیں ۔',\n",
              " 'یہ وہ لوگ ہیں جن پر اللہ نے لعنت کی ، اور جس پر اللہ لعنت کرے تُو اس کے لئے ہرگز کوئی مددگار نہ پائے گا ۔',\n",
              " 'کیا ان کا سلطنت میں کچھ حصہ ہے ؟ اگر ایسا ہو تو یہ اپنے بخل کے باعث لوگوں کو تِل برابر بھی کوئی چیز نہیں دیں گے ۔',\n",
              " 'کیا یہ یہود لوگوں سے ان نعمتوں پر حسد کرتے ہیں جو اللہ نے انہیں اپنے فضل سے عطا فرمائی ہیں ، سو واقعی ہم نے ابراہیم علیہ السلام کے خاندان کو کتاب اور حکمت عطا کی اور ہم نے انہیں بڑی سلطنت بخشی ۔',\n",
              " 'پس ان میں سے کوئی تو اس پر ایمان لے آیا اور ان میں سے کسی نے اس سے روگردانی کی ، اور روگردانی کرنے والے کے لئے دوزخ کی بھڑکتی آگ کافی ہے ۔',\n",
              " 'بیشک جن لوگوں نے ہماری آیتوں سے کفر کیا ہم عنقریب انہیں دوزخ کی آگ میں جھونک دیں گے ، جب ان کی کھالیں جل جائیں گی تو ہم انہیں دوسری کھالیں بدل دیں گے تاکہ وہ مسلسل عذاب کا مزہ چکھتے رہیں ، بیشک اللہ غالب حکمت والا ہے ۔',\n",
              " 'اور جو لوگ ایمان لائے اور نیک عمل کرتے رہے تو ہم انہیں بہشتوں میں داخل کریں گے جن کے نیچے نہریں رواں ہیں وہ ان میں ہمیشہ رہیں گے ، ان کے لئے وہاں پاکیزہ بیویاں ہوں گی اور ہم ان کو بہت گھنے سائے میں داخل کریں گے ۔',\n",
              " 'بیشک اللہ تمہیں حکم دیتا ہے کہ امانتیں انہی لوگوں کے سپرد کرو جو ان کے اہل ہیں ، اور جب تم لوگوں کے درمیان فیصلہ کرو تو عدل کے ساتھ فیصلہ کیا کرو ، بیشک اللہ تمہیں کیا ہی اچھی نصیحت فرماتا ہے ، بیشک اللہ خوب سننے والا خوب دیکھنے والا ہے ۔',\n",
              " 'اے ایمان والو ! اللہ کی اطاعت کرو اور رسول صلی اللہ علیہ وآلہ وسلم کی اطاعت کرو اوراپنے میں سے اہلِ حق صاحبانِ اَمر کی ، پھر اگر کسی مسئلہ میں تم باہم اختلاف کرو تو اسے حتمی فیصلہ کے لئے اللہ اور رسول صلی اللہ علیہ وآلہ وسلم کی طرف لوٹا دو اگر تم اللہ پر اور یومِ آخرت پر ایمان رکھتے ہو ، تو یہی تمہارے حق میں بہتر اور انجام کے لحاظ سے بہت اچھا ہے ۔',\n",
              " 'کیا آپ نے اِن منافقوں کو نہیں دیکھا جو زبان سے دعوٰی کرتے ہیں کہ وہ اس کتاب یعنی قرآن پر ایمان لائے جوآپ کی طرف اتارا گیا اور ان آسمانی کتابوں پر بھی جو آپ سے پہلے اتاری گئیں مگر چاہتے یہ ہیں کہ اپنے مقدمات فیصلے کے لئے شیطان یعنی احکامِ الٰہی سے سرکشی پر مبنی قانون کی طرف لے جائیں حالانکہ انہیں حکم دیا جا چکا ہے کہ اس کا کھلا انکار کر دیں ، اور شیطان تویہی چاہتا ہے کہ انہیں دور دراز گمراہی میں بھٹکاتا رہے ۔',\n",
              " 'اور جب ان سے کہا جاتا ہے کہ اللہ کے نازل کردہ قرآن کی طرف اور رسول صلی اللہ علیہ وآلہ وسلم کی طرف آجاؤ تو آپ منافقوں کو دیکھیں گے کہ وہ آپ کی طرف رجوع کرنے سے گریزاں رہتے ہیں ۔',\n",
              " 'پھر اس وقت ان کی حالت کیا ہوگی جب اپنی کارستانیوں کے باعث ان پر کوئی مصیبت آن پڑے تو اللہ کی قَسمیں کھاتے ہوئے آپ کی خدمت میں حاضر ہوں اور یہ کہیں کہ ہم نے تو صرف بھلائی اور باہمی موافقت کا ہی ارادہ کیا تھا ۔',\n",
              " 'یہ وہ منافق اور مُفسِد لوگ ہیں کہ اللہ ان کے دلوں کی ہر بات کو خوب جانتا ہے ، پس آپ ان سے اِعراض برتیں اور انہیں نصیحت کرتے رہیں اور ان سے ان کے بارے میں مؤثر گفتگو فرماتے رہیں ۔',\n",
              " 'اور ہم نے کوئی پیغمبر نہیں بھیجا مگر اس لئے کہ اللہ کے حکم سے اس کی اطاعت کی جائے ، اور اے حبیب ! اگر وہ لوگ جب اپنی جانوں پر ظلم کر بیٹھے تھے آپ کی خدمت میں حاضر ہو جاتے اوراللہ سے معافی مانگتے اور رسول صلی اللہ علیہ وآلہ وسلم بھی ان کے لئے مغفرت طلب کرتے تو وہ اس وسیلہ اور شفاعت کی بنا پر ضرور اللہ کو توبہ قبول فرمانے والا نہایت مہربان پاتے ۔',\n",
              " 'پس اے حبیب ! آپ کے رب کی قسم یہ لوگ مسلمان نہیں ہوسکتے یہاں تک کہ وہ اپنے درمیان واقع ہونے والے ہر اختلاف میں آپ کو حاکم بنالیں پھر اس فیصلہ سے جو آپ صادر فرما دیں اپنے دلوں میں کوئی تنگی نہ پائیں اور آپ کے حکم کو بخوشی پوری فرمانبرداری کے ساتھ قبول کر لیں ۔',\n",
              " 'اور اگر ہم ان پر فرض کر دیتے کہ تم اپنے آپ کو قتل کر ڈالو یا اپنے گھروں کو چھوڑ کر نکل جاؤ تو ان میں سے بہت تھوڑے لوگ اس پر عمل کرتے ، اورانہیں جو نصیحت کی جاتی ہے اگر وہ اس پر عمل پیرا ہو جاتے تویہ ان کے حق میں بہتر ہوتا اور ایمان پر بہت زیادہ ثابت قدم رکھنے والا ہوتا ۔',\n",
              " 'اور اس وقت ہم بھی انہیں اپنے حضور سے عظیم اجر عطا فرماتے ۔',\n",
              " 'اور ہم انہیں واقعۃً سیدھی راہ پر لگا دیتے ۔',\n",
              " 'اور جو کوئی اللہ اور رسول صلی اللہ علیہ وآلہ وسلم کی اطاعت کرے تو یہی لوگ روزِ قیامت ان ہستیوں کے ساتھ ہوں گے جن پر اللہ نے خاص انعام فرمایا ہے جو کہ انبیاء ، صدیقین ، شہداءاور صالحین ہیں ، اور یہ بہت اچھے ساتھی ہیں ۔',\n",
              " 'یہ فضل خاص اللہ کی طرف سے ہے ، اور اللہ جاننے والا کافی ہے ۔',\n",
              " 'اے ایمان والو ! اپنی حفاظت کا سامان لے لیا کرو پھر جہاد کے لئے متفرق جماعتیں ہو کر نکلو یا سب اکٹھے ہو کر کوچ کرو ۔',\n",
              " 'اور یقیناً تم میں سے بعض ایسے بھی ہیں جو عمداً سستی کرتے ہوئے دیر لگاتے ہیں ، پھر اگر جنگ میں تمہیں کوئی مصیبت پہنچے تو شریک نہ ہونے والا شخص کہتا ہے کہ بیشک اللہ نے مجھ پراحسان فرمایا کہ میں ان کے ساتھ میدانِ جنگ میں حاضر نہ تھا ۔',\n",
              " 'اور اگر تمہیں اللہ کی جانب سے کوئی نعمت نصیب ہو جائے تو پھر یہی منافق افسوس کرتے ہوئے ضرور یوں کہے گا گویا تمہارے اور اس کے درمیان کچھ دوستی ہی نہ تھی کہ اے کاش ! میں ان کے ساتھ ہوتا تو میں بھی بڑی کامیابی حاصل کرتا ۔',\n",
              " 'پس ان مؤمنوں کو اللہ کی راہ میں دین کی سربلندی کے لئے لڑنا چاہئے جو آخرت کے عوض دنیوی زندگی کو بیچ دیتے ہیں ، اور جو کوئی اللہ کی راہ میں جنگ کرے ، خواہ وہ خود قتل ہو جائے یا غالب آجائے توہم دونوں صورتوں میں عنقریب اسے عظیم اجر عطا فرمائیں گے ۔',\n",
              " 'اور مسلمانو ! تمہیں کیا ہو گیا ہے کہ تم اللہ کی راہ میں مظلوموں کی آزادی کے لئے جنگ نہیں کرتے حالاں کہ کم زور ، مظلوم اور مقہور مرد ، عورتیں اور بچے ظلم و ستم سے تنگ آ کر اپنی آزادی کے لئے پکارتے ہیں : اے ہمارے رب ! ہمیں اس بستی سے نکال لے جہاں کے وڈیرے لوگ ظالم ہیں ، اور کسی کو اپنی بارگاہ سے ہمارا کارساز مقرر فرما دے ، اور کسی کو اپنی بارگاہ سے ہمارا مددگار بنا دے ۔',\n",
              " 'جو لوگ ایمان لائے وہ اللہ کی راہ میں نیک مقاصد کے لئے جنگ کرتے ہیں اورجنہوں نے کفر کیا وہ شیطان کی راہ میں طاغوتی مقاصد کے لئے جنگ کرتے ہیں ، پس اے مؤمنو ! تم شیطان کے دوستوں یعنی شیطانی مشن کے مددگاروں سے لڑو ، بیشک شیطان کا داؤ کمزور ہے ۔',\n",
              " 'کیا آپ نے ان لوگوں کا حال نہیں دیکھا جنہیں ابتداءً کچھ عرصہ کے لئے یہ کہا گیا کہ اپنے ہاتھ قتال سے روکے رکھو اور نماز قائم کئے رہواور زکوٰۃ دیتے رہو تو وہ اس پر خوش تھے ، پھر جب ان پر جہاد یعنی کفر اور ظلم سے ٹکرانا فرض کر دیا گیا تو ان میں سے ایک گروہ مخالف لوگوں سے یوں ڈرنے لگا جیسے اللہ سے ڈرا جاتا ہے یا اس سے بھی بڑھ کر ۔ اور کہنے لگے : اے ہمارے رب ! تو نے ہم پر اس قدر جلدی جہاد کیوں فرض کر دیا ؟ تو نے ہمیں مزید تھوڑی مدت تک مہلت کیوں نہ دی ؟ آپ انہیں فرما دیجئے کہ دنیا کا مفاد بہت تھوڑا یعنی معمولی شے ہے ، اور آخرت بہت اچھی نعمت ہے اس کے لئے جو پرہیزگار بن جائے ، وہاں ایک دھاگے کے برابر بھی تمہاری حق تلفی نہیں کی جائے گی ۔',\n",
              " 'اے موت کے ڈر سے جہاد سے گریز کرنے والو ! تم جہاں کہیں بھی ہوگے موت تمہیں وہیں آپکڑے گی خواہ تم مضبوط قلعوں میں ہی ہو ، اور ان کی ذہنیت یہ ہے کہ اگر انہیں کوئی بھلائی فائدہ پہنچے توکہتے ہیں کہ یہ تو اللہ کی طرف سے ہے اس میں رسول صلی اللہ علیہ وآلہ وسلم کی برکت اور واسطے کا کوئی دخل نہیں ، اور اگر انہیں کوئی برائی نقصان پہنچے تو کہتے ہیں : اے رسول ! یہ آپ کی طرف سے یعنی آپ کی وجہ سے ہے ۔ آپ فرما دیں : حقیقۃً سب کچھ اللہ کی طرف سے ہوتا ہے ۔ پس اس قوم کو کیا ہوگیا ہے کہ یہ کوئی بات سمجھنے کے قریب ہی نہیں آتے ۔',\n",
              " 'اے انسان ! اپنی تربیت یوں کر کہ جب تجھے کوئی بھلائی پہنچے تو سمجھ کہ وہ اللہ کی طرف سے ہے اسے اپنے حسنِ تدبیر کی طرف منسوب نہ کر ، اور جب تجھے کوئی برائی پہنچے تو سمجھ کہ وہ تیری اپنی طرف سے ہے یعنی اسے اپنی خرابئ نفس کی طرف منسوب کر ، اور اے محبوب ! ہم نے آپ کو تمام انسانوں کے لئے رسول بنا کر بھیجا ہے ، اور آپ کی رسالت پر اللہ گواہی میں کافی ہے ۔',\n",
              " 'جس نے رسول صلی اللہ علیہ وآلہ وسلم کا حکم مانا بیشک اس نے اللہ ہی کا حکم مانا ، اور جس نے روگردانی کی تو ہم نے آپ کو ان پر نگہبان بنا کر نہیں بھیجا ۔',\n",
              " 'اور ان منافقوں کا یہ حال ہے کہ آپ کے سامنے کہتے ہیں کہ ہم نے آپ کا حکم مان لیا ، پھر وہ آپ کے پاس سے اٹھ کر باہر جاتے ہیں تو ان میں سے ایک گروہ آپ کی کہی ہوئی بات کے برعکس رات کو رائے زنی اور سازشی مشورے کرتا ہے ، اور اللہ وہ سب کچھ لکھ رہا ہے جو وہ رات بھر منصوبے بناتے ہیں ۔ پس اے محبوب ! آپ ان سے رُخِ انور پھیر لیجئے اوراللہ پر بھروسہ رکھئیے ، اور اللہ کافی کارساز ہے ۔',\n",
              " 'تو کیا وہ قرآن میں غور و فکر نہیں کرتے ، اور اگر یہ قرآن غیرِ خدا کی طرف سے آیا ہوتا تو یہ لوگ اس میں بہت سا اختلاف پاتے ۔',\n",
              " 'اور جب ان کے پاس کوئی خبر امن یا خوف کی آتی ہے تو وہ اسے پھیلا دیتے ہیں اور اگر وہ بجائے شہرت دینے کے اسے رسول صلی اللہ علیہ وآلہ وسلم اور اپنے میں سے صاحبانِ امر کی طرف لوٹادیتے تو ضرور ان میں سے وہ لوگ جو کسی بات کانتیجہ اخذ کرسکتے ہیں اس خبر کی حقیقت کو جان لیتے ، اگر تم پر اللہ کا فضل اور اس کی رحمت نہ ہوتی تو یقیناً چند ایک کے سوا تم سب شیطان کی پیروی کرنے لگتے ۔',\n",
              " 'پس اے محبوب ! آپ اللہ کی راہ میں جہاد کیجئے ، آپ کو اپنی جان کے سوا کسی اور کے لئے ذمہ دار نہیں ٹھہرایا جائے گا اور آپ مسلمانوں کو جہاد کے لئے اُبھاریں ، عجب نہیں کہ اللہ کافروں کا جنگی زور توڑ دے ، اور اللہ گرفت میں بھی بہت سخت ہے اور سزا دینے میں بھی بہت سخت ۔',\n",
              " 'جو شخص کوئی نیک سفارش کرے تو اس کے لئے اس کے ثواب سے حصہ مقرر ہے ، اور جو کوئی بری سفارش کرے تو اس کے لئے اس کے گناہ سے حصہ مقرر ہے ، اور اللہ ہر چیز پر قادر ہے ۔',\n",
              " 'اور جب کسی لفظ سلام کے ذریعے تمہاری تکریم کی جائے تو تم جواب میں اس سے بہتر لفظ کے ساتھ سلام پیش کیا کرو یا کم از کم وہی الفاظ جواب میں لوٹا دیا کرو ، بیشک اللہ ہر چیز پر حساب لینے والا ہے ۔',\n",
              " 'اللہ ہے کہ اس کے سوا کوئی لائقِ عبادت نہیں ۔ وہ تمہیں ضرور قیامت کے دن جمع کرے گا جس میں کوئی شک نہیں ، اور اللہ سے بات میں زیادہ سچا کون ہے ۔',\n",
              " 'پس تمہیں کیا ہوگیا ہے کہ منافقوں کے بارے میں تم دو گروہ ہو گئے ہو حالانکہ اللہ نے ان کے اپنے کرتوتوں کے باعث ان کی عقل اور سوچ کو اوندھا کر دیا ہے ۔ کیا تم اس شخص کو راہِ راست پر لانا چاہتے ہو جسے اللہ نے گمراہ ٹھہرا دیا ہے ، اور اے مخاطب ! جسے اللہ گمراہ ٹھہرا دے تو اس کے لئے ہرگز کوئی راہِ ہدایت نہیں پاسکتا ۔',\n",
              " 'وہ منافق تو یہ تمنا کرتے ہیں کہ تم بھی کفر کروجیسے انہوں نے کفر کیا تاکہ تم سب برابر ہو جاؤ ۔ سو تم ان میں سے کسی کو دوست نہ بناؤ یہاں تک کہ وہ اللہ کی راہ میں ہجرت کر کے اپنا ایمان اور اخلاص ثابت کریں ، پھر اگر وہ روگردانی کریں تو انہیں پکڑ لو اور جہاں بھی پاؤ انہیں قتل کر ڈالو اور ان میں سے کسی کو دوست نہ بناؤ اور نہ مددگار ۔',\n",
              " 'مگر ان لوگوں کو قتل نہ کرو جو ایسی قوم سے جا ملے ہوں کہ تمہارے اور ان کے درمیان معاہدۂ امان ہوچکا ہو یا وہ حوصلہ ہار کر تمہارے پاس اس حال میں آجائیں کہ ان کے سینے اس بات سے تنگ آچکے ہوں کہ وہ تم سے لڑیں یا اپنی قوم سے لڑیں ، اور اگر اللہ چاہتا تو ان کے دلوں کو ہمت دیتے ہوئے یقینا انہیں تم پر غالب کر دیتا تو وہ تم سے ضرور لڑتے ، پس اگر وہ تم سے کنارہ کشی کر لیں اور تمہارے ساتھ جنگ نہ کریں اور تمہاری طرف صلح کا پیغام بھیجیں تو اللہ نے تمہارے لئے بھی صلح جوئی کی صورت میں ان پر دست درازی کی کوئی راہ نہیں بنائی ۔',\n",
              " 'اب تم کچھ دوسرے لوگوں کو بھی پاؤ گے جو چاہتے ہیں کہ منافقانہ طریقے سے ایمان ظاہر کرکے تم سے بھی امن میں رہیں اور پوشیدہ طریقے سے کفر کی موافقت کرکے اپنی قوم سے بھی امن میں رہیں ، مگر ان کی حالت یہ ہے کہ جب بھی مسلمانوں کے خلاف فتنہ انگیزی کی طرف پھیرے جاتے ہیں تو وہ اس میں اوندھے کود پڑتے ہیں ، سو اگر یہ لوگ تم سے لڑنے سے کنارہ کش نہ ہوں اور نہ ہی تمہاری طرف صلح کا پیغام بھیجیں اور نہ ہی اپنے ہاتھ فتنہ انگیزی سے روکیں تو تم انہیں پکڑ کر قید کر لو اور انہیں قتل کر ڈالو جہاں کہیں بھی انہیں پاؤ ، اور یہ وہ لوگ ہیں جن پر ہم نے تمہیں کھلا اختیار دیا ہے ۔',\n",
              " 'اور کسی مسلمان کے لئے جائز نہیں کہ وہ کسی مسلمان کو قتل کر دے مگر بغیر قصد غلطی سے ، اور جس نے کسی مسلمان کو نادانستہ قتل کر دیا تو اس پر ایک مسلمان غلام / باندی کا آزاد کرنا اور خون بہا کا ادا کرنا جو مقتول کے گھر والوں کے سپرد کیا جائے لازم ہے مگر یہ کہ وہ معاف کر دیں ، پھر اگر وہ مقتول تمہاری دشمن قوم سے ہو اور وہ مومن بھی ہو تو صرف ایک غلام / باندی کا آزاد کرنا ہی لازم ہے اور اگر وہ مقتول اس قوم میں سے ہو کہ تمہارے اور ان کے درمیان صلح کا معاہدہ ہے تو خون بہا بھی جو اس کے گھر والوں کے سپرد کیا جائے اور ایک مسلمان غلام / باندی کا آزاد کرنا بھی لازم ہے ۔ پھر جس شخص کو غلام / باندی میسر نہ ہو تو اس پر پے در پے دو مہینے کے روزے لازم ہیں ۔ اللہ کی طرف سے یہ اس کی توبہ ہے ، اور اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اور جو شخص کسی مسلمان کو قصداً قتل کرے تو اس کی سزا دوزخ ہے کہ مدتوں اس میں رہے گا اور اس پر اللہ غضبناک ہوگا اور اس پر لعنت کرے گا اور اس نے اس کے لئے زبردست عذاب تیار کر رکھا ہے ۔',\n",
              " 'اے ایمان والو ! جب تم اللہ کی راہ میں جہاد کے لئے سفر پر نکلو تو تحقیق کر لیا کرو اور اس کو جو تمہیں سلام کرے یہ نہ کہو کہ تو مسلمان نہیں ہے ، تم ایک مسلمان کو کافر کہہ کر مارنے کے بعد مالِ غنیمت کی صورت میں دنیوی زندگی کا سامان تلاش کرتے ہو تو یقین کرو اللہ کے پاس بہت اَموالِ غنیمت ہیں ۔ اس سے پیشتر تم بھی توایسے ہی تھے پھر اللہ نے تم پر احسان کیا اور تم مسلمان ہوگئے پس دوسروں کے بارے میں بھی تحقیق کر لیا کرو ۔ بیشک اللہ تمہارے کاموں سے خبردار ہے ۔',\n",
              " 'مسلمانوں میں سے وہ لوگ جو جہاد سے جی چرا کر بغیر کسی عذر تکلیف کے گھروں میں بیٹھ رہنے والے ہیں اور وہ لوگ جو اللہ کی راہ میں اپنے مالوں اور اپنی جانوں سے جہاد کرنے والے ہیں یہ دونوں درجہ و ثواب میں برابر نہیں ہوسکتے ۔ اللہ نے اپنے مالوں اور اپنی جانوں سے جہاد کرنے والوں کو بیٹھ رہنے والوں پر مرتبہ میں فضیلت بخشی ہے اوراللہ نے سب ایمان والوں سے وعدہ تو بھلائی کا ہی فرمایا ہے ، اور اللہ نے جہاد کرنے والوں کو بہر طور بیٹھ رہنے والوں پر زبردست اجر و ثواب کی فضیلت دی ہے ۔',\n",
              " 'اس کی طرف سے ان کے لئے بہت درجات ہیں اور بخشائش اور رحمت ہے ، اور اللہ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'بیشک جن لوگوں کی روح فرشتے اس حال میں قبض کرتے ہیں کہ وہ اپنی جانوں پر ظلم کرنے والے ہیں تو وہ ان سے دریافت کرتے ہیں کہ تم کس حال میں تھے تم نے اِقامتِ دین کی جد و جہد کی نہ سرزمینِ کُفر کو چھوڑا ؟ وہ معذرۃً کہتے ہیں کہ ہم زمین میں کمزور و بے بس تھے ، فرشتے جواباً کہتے ہیں : کیا اللہ کی زمین فراخ نہ تھی کہ تم اس میں کہیں ہجرت کر جاتے ، سو یہی وہ لوگ ہیں جن کا ٹھکانا جہنم ہے ، اور وہ بہت ہی برا ٹھکانا ہے ۔',\n",
              " 'سوائے ان واقعی مجبور و بے بس مردوں اور عورتوں اور بچوں کے ، جو نہ کسی تدبیر پر قدرت رکھتے ہیں اور نہ وہاں سے نکلنے کا کوئی راستہ جانتے ہیں ۔',\n",
              " 'سو یہ وہ لوگ ہیں کہ یقیناً اللہ ان سے درگزر فرمائے گا ، اور اللہ بڑا معاف فرمانے والا بخشنے والا ہے ۔',\n",
              " 'اور جو کوئی اللہ کی راہ میں گھر بار چھوڑ کرنکلے وہ زمین میں ہجرت کے لئے بہت سی جگہیں اور معاش کے لئے کشائش پائے گا ، اور جو شخص بھی اپنے گھر سے اللہ اور اس کے رسول صلی اللہ علیہ وآلہ وسلم کی طرف ہجرت کرتے ہوئے نکلے پھر اسے راستے میں ہی موت آپکڑے تو اس کا اجر اللہ کے ذمے ثابت ہو گیا ، اور اللہ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'اور جب تم زمین میں سفر کرو تو تم پر کوئی گناہ نہیں کہ تم نماز میں قصر کرو یعنی چار رکعت فرض کی جگہ دو پڑھو اگر تمہیں اندیشہ ہے کہ کافر تمہیں تکلیف میں مبتلا کر دیں گے ۔ بیشک کفار تمہارے کھلے دشمن ہیں ۔',\n",
              " 'اور اے محبوب ! جب آپ ان مجاہدوں میں تشریف فرما ہوں تو ان کے لئے نماز کی جماعت قائم کریں پس ان میں سے ایک جماعت کو پہلے آپ کے ساتھ اقتداءً کھڑا ہونا چاہئے اور انہیں اپنے ہتھیار بھی لئے رہنا چاہئیں ، پھر جب وہ سجدہ کر چکیں تو ہٹ کر تم لوگوں کے پیچھے ہو جائیں اور اب دوسری جماعت کو جنہوں نے ابھی نماز نہیں پڑھی آجانا چاہیے پھر وہ آپ کے ساتھ مقتدی بن کر نماز پڑھیں اور چاہئے کہ وہ بھی بدستور اپنے اسبابِ حفاظت اور اپنے ہتھیار لئے رہیں ، کافر چاہتے ہیں کہ کہیں تم اپنے ہتھیاروں اور اپنے اسباب سے غافل ہو جاؤ تو وہ تم پر دفعۃً حملہ کر دیں ، اور تم پر کچھ مضائقہ نہیں کہ اگر تمہیں بارش کی وجہ سے کوئی تکلیف ہو یا بیمار ہو تو اپنے ہتھیار اُتار کر رکھ دو ، اوراپنا سامانِ حفاظت لئے رہو ۔ بیشک اللہ نے کافروں کے لئے ذلّت انگیز عذاب تیار کر رکھا ہے ۔',\n",
              " 'پھر اے مسلمانو ! جب تم نماز ادا کر چکو تو اللہ کو کھڑے اور بیٹھے اور اپنے پہلوؤں پر لیٹے ہر حال میں یاد کرتے رہو ، پھر جب تم حالتِ خوف سے نکل کر اطمینان پالو تو نماز کو حسبِ دستور قائم کرو ۔ بیشک نماز مومنوں پر مقررہ وقت کے حساب سے فرض ہے ۔',\n",
              " 'اور تم دشمن قوم کی تلاش میں سستی نہ کرو ۔ اگر تمہیں پیچھا کرنے میں تکلیف پہنچتی ہے تو انہیں بھی تو ایسی ہی تکلیف پہنچتی ہے جیسی تکلیف تمہیں پہنچ رہی ہے حالانکہ تم اللہ سے اجر و ثواب کی وہ امیدیں رکھتے ہو جو اُمیدیں وہ نہیں رکھتے ۔ اور اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اے رسولِ گرامی ! بیشک ہم نے آپ کی طرف حق پر مبنی کتاب نازل کی ہے تاکہ آپ لوگوں میں اس حق کے مطابق فیصلہ فرمائیں جو اللہ نے آپ کو دکھایا ہے ، اور آپ کبھی بددیانت لوگوں کی طرف داری میں بحث کرنے والے نہ بنیں ۔',\n",
              " 'اور آپ اللہ سے بخشش طلب کریں ، بیشک اللہ بڑا بخشنے والا مہربان ہے ۔',\n",
              " 'اور آپ ایسے لوگوں کی طرف سے دفاعاً نہ جھگڑیں جو اپنی ہی جانوں سے دھوکہ کر رہے ہیں ۔ بیشک اللہ کسی ایسے شخص کو پسند نہیں فرماتا جو بڑا بددیانت اور بدکار ہے ۔',\n",
              " 'وہ لوگوں سے شرماتے ہوئے اپنی دغابازی کو چھپاتے ہیں اور اللہ سے نہیں شرماتے درآنحالیکہ وہ ان کے ساتھ ہوتا ہے جب وہ رات کو کسی ایسی بات سے متعلق چھپ کر مشورہ کرتے ہیں جسے اللہ ناپسند فرماتا ہے ، اور اللہ جو کچھ وہ کرتے ہیں اسے احاطہ کئے ہوئے ہے ۔',\n",
              " 'خبردار ! تم وہ لوگ ہو جو دنیا کی زندگی میں ان کی طرف سے جھگڑے ۔ پھر کون ایسا شخص ہے جو قیامت کے دن بھی ان کی طرف سے اللہ کے ساتھ جھگڑے گا یا کون ہے جو اس دن بھی ان پر وکیل ہوگا ؟ ۔',\n",
              " 'اور جو کوئی برا کام کرے یا اپنی جان پر ظلم کرے پھر اللہ سے بخشش طلب کرے وہ اللہ کو بڑا بخشنے والا نہایت مہربان پائے گا ۔',\n",
              " 'اور جو شخص کوئی گناہ کرے تو بس وہ اپنی ہی جان پر اس کا وبال عائد کر رہا ہے اور اللہ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اور جو شحص کسی خطا یا گناہ کا ارتکاب کرے پھر اس کی تہمت کسی بے گناہ پرلگا دے تو اس نے یقیناً ایک بہتان اور کھلے گناہ کے بوجھ کو اٹھا لیا ۔',\n",
              " 'اور اے حبیب ! اگر آپ پر اللہ کا فضل اور اس کی رحمت نہ ہوتی تو ان دغابازوں میں سے ایک گروہ یہ ارادہ کر چکا تھا کہ آپ کو بہکا دیں ، جب کہ وہ محض اپنے آپ کو ہی گمراہ کر رہے ہیں اور آپ کا تو کچھ بگاڑ ہی نہیں سکتے ، اور اللہ نے آپ پر کتاب اور حکمت نازل فرمائی ہے اور اس نے آپ کو وہ سب علم عطا کر دیا ہے جوآپ نہیں جانتے تھے ، اورآپ پر اللہ کا بہت بڑا فضل ہے ۔',\n",
              " 'ان کے اکثر خفیہ مشوروں میں کوئی بھلائی نہیں سوائے اس شخص کے مشورے کے جو کسی خیرات کا یا نیک کام کا یا لوگوں میں صلح کرانے کا حکم دیتا ہے اور جو کوئی یہ کام اللہ کی رضا جوئی کے لئے کرے تو ہم اس کو عنقریب عظیم اجر عطا کریں گے ۔',\n",
              " 'اور جو شخص رسول صلی اللہ علیہ وآلہ وسلم کی مخالفت کرے اس کے بعد کہ اس پر ہدایت کی راہ واضح ہو چکی اور مسلمانوں کی راہ سے جدا راہ کی پیروی کرے تو ہم اسے اسی گمراہی کی طرف پھیرے رکھیں گے جدھر وہ خود پھر گیا ہے اور بالآخر اسے دوزخ میں ڈالیں گے ، اور وہ بہت ہی برا ٹھکانا ہے ۔',\n",
              " 'بیشک اللہ اس بات کو معاف نہیں کرتا کہ اس کے ساتھ کسی کو شریک ٹھہرایا جائے اور جو گناہ اس سے نیچے ہے جس کے لئے چاہے معاف فرما دیتا ہے ، اور جو کوئی اللہ کے ساتھ شرک کرے وہ واقعی دور کی گمراہی میں بھٹک گیا ۔',\n",
              " 'یہ مشرکین اللہ کے سوا محض زنانی چیزوں ہی کی پرستش کرتے ہیں اور یہ فقط سرکش شیطان ہی کی پوجا کرتے ہیں ۔',\n",
              " 'جس پراللہ نے لعنت کی ہے اور جس نے کہا تھا کہ میں تیرے بندوں میں سے ایک معیّن حصہ اپنے لئے ضرور لے لوں گا ۔',\n",
              " 'میں انہیں ضرور گمراہ کردوں گا اور ضرور انہیں غلط اُمیدیں دلاؤں گا اور انہیں ضرور حکم دیتا رہوں گا سو وہ یقیناً جانوروں کے کان چیرا کریں گے اور میں انہیں ضرور حکم دیتا رہوں گا سو وہ یقیناً اللہ کی بنائی ہوئی چیزوں کو بدلا کریں گے ، اور جو کوئی اللہ کو چھوڑ کر شیطان کو دوست بنالے تو واقعی وہ صریح نقصان میں رہا ۔',\n",
              " 'شیطان انہیں غلط وعدے دیتا ہے اور انہیں جھوٹی اُمیدیں دلاتا ہے اور شیطان فریب کے سوا ان سے کوئی وعدہ نہیں کرتا ۔',\n",
              " 'یہ وہ لوگ ہیں جن کا ٹھکانا دوزخ ہے اور وہ وہاں سے بھاگنے کی کوئی جگہ نہ پائیں گے ۔',\n",
              " 'اور جو لوگ ایمان لائے اور نیک عمل کرتے رہے ہم انہیں عنقریب بہشتوں میں داخل کریں گے جن کے نیچے نہریں بہہ رہی ہوں گی وہ ان میں ہمیشہ ہمیشہ رہیں گے ۔ یہ اللہ کا سچا وعدہ ہے ، اور اللہ سے زیادہ بات کا سچا کون ہوسکتا ہے ۔',\n",
              " 'اللہ کا وعدۂ مغفرت نہ تمہاری خواہشات پر موقوف ہے اور نہ اہلِ کتاب کی خواہشات پر ، جو کوئی برا عمل کرے گا اسے اس کی سزا دی جائے گی اور نہ وہ اللہ کے سوا اپنا کوئی حمایتی پائے گا اور نہ مددگار ۔',\n",
              " 'اور جو کوئی نیک اعمال کرے گا خواہ مرد ہو یا عورت درآنحالیکہ وہ مومن ہے پس وہی لوگ جنت میں داخل ہوں گے اوران کی تِل برابر بھی حق تلفی نہیں کی جائے گے ۔',\n",
              " 'اور دین اختیار کرنے کے اعتبار سے اُس شخص سے بہتر کون ہو سکتا ہے جس نے اپنا رُوئے نیاز اللہ کے لئے جھکا دیا اور وہ صاحبِ احسان بھی ہوا ، اور وہ دینِ ابراہیم علیہ السلام کی پیروی کرتا رہا جو اللہ کے لئے یک سُو اور راست رَو تھے ، اور اللہ نے ابراہیم علیہ السلام کو اپنا مخلص دوست بنا لیا تھا سو وہ شخص بھی حضرت ابراہیم علیہ السلام کی نسبت سے اللہ کا دوست ہو گیا ۔',\n",
              " 'اور سب اللہ ہی کا ہے جو کچھ آسمانوں میں اور جو کچھ زمین میں ہے اور اللہ ہر چیز کا احاطہ فرمائے ہوئے ہے ۔',\n",
              " 'اور اے پیغمبر ! لوگ آپ سے یتیم عورتوں کے بارے میں فتویٰ پوچھتے ہیں ۔ آپ فرما دیں کہ اللہ تمہیں ان کے بارے میں حکم دیتا ہے اور جو حکم تم کو پہلے سے کتابِ مجید میں سنایا جا رہا ہے وہ بھی ان یتیم عورتوں ہی کے بارے میں ہے جنہیں تم وہ حقوق نہیں دیتے جو ان کے لئے مقرر کئے گئے ہیں اور چاہتے ہو کہ ان کا مال قبضے میں لینے کی خاطر ان کے ساتھ خود نکاح کر لو اور نیز بے بس بچوں کے بارے میں بھی حکم ہے کہ یتیموں کے معاملے میں انصاف پر قائم رہا کرو ، اور تم جو بھلائی بھی کروگے تو بیشک اللہ اسے خوب جاننے والا ہے ۔',\n",
              " 'اور اگر کوئی عورت اپنے شوہر کی جانب سے زیادتی یا بے رغبتی کا خوف رکھتی ہو تو دونوں میاں بیوی پر کوئی حرج نہیں کہ وہ آپس میں کسی مناسب بات پر صلح کر لیں ، اور صلح حقیقت میں اچھی چیز ہے اور طبیعتوں میں تھوڑا بہت بخل ضرور رکھ دیا گیا ہے ، اور اگر تم احسان کرو اور پرہیزگاری اختیار کرو تو بیشک اللہ ان کاموں سے جو تم کر رہے ہو اچھی طرح خبردار ہے ۔',\n",
              " 'اور تم ہرگز اس بات کی طاقت نہیں رکھتے کہ ایک سے زائد بیویوں کے درمیان پورا پورا عدل کر سکو اگرچہ تم کتنا بھی چاہو ۔ پس ایک کی طرف پورے میلان طبع کے ساتھ یوں نہ جھک جاؤ کہ دوسری کو درمیان میں لٹکتی ہوئی چیز کی طرح چھوڑ دو ۔ اور اگر تم اصلاح کر لو اور حق تلفی و زیادتی سے بچتے رہو تو اللہ بڑا بخشنے والا نہایت مہربان ہے ۔',\n",
              " 'اور اگر دونوں میاں بیوی جدا ہو جائیں تواللہ ہر ایک کو اپنی کشائش سے ایک دوسرے سے بے نیاز کر دے گا اور اللہ بڑی وسعت والا بڑی حکمت والا ہے ۔',\n",
              " 'اور اللہ ہی کا ہے جو کچھ آسمانوں میں اورجو کچھ زمین میں ہے ۔ اور بیشک ہم نے ان لوگوں کو بھی جنہیں تم سے پہلے کتاب دی گئی حکم دیا ہے اور تمہیں بھی کہ اللہ سے ڈرتے رہا کرو ۔ اور اگر تم نافرمانی کرو گے تو بیشک سب کچھ اللہ ہی کا ہے جو آسمانوں میں اورجو زمین میں ہے اوراللہ بے نیاز ، ستودہ صفات ہے ۔',\n",
              " 'اوراللہ ہی کا ہے جو آسمانوں میں ہے اور جو زمین میں ہے ، اور اللہ کا کارساز ہونا کافی ہے ۔',\n",
              " 'اے لوگو ! اگر وہ چاہے تو تمہیں نابود کر دے اور تمہاری جگہ دوسروں کو لے آئے ، اور اللہ اس پر بڑی قدرت والا ہے ۔',\n",
              " 'جو کوئی دنیا کا انعام چاہتا ہے تو اللہ کے پاس دنیا و آخرت دونوں کاانعام ہے ، اور اللہ خوب سننے والا خوب دیکھنے والا ہے ۔',\n",
              " 'اے ایمان والو ! تم انصاف پر مضبوطی کے ساتھ قائم رہنے والے محض اللہ کے لئے گواہی دینے والے ہو جاؤ خواہ گواہی خود تمہارے اپنے یا تمہارے والدین یا تمہارے رشتہ داروں کے ہی خلاف ہو ، اگرچہ جس کے خلاف گواہی ہو مال دار ہے یا محتاج ، اللہ ان دونوں کا تم سے زیادہ خیر خواہ ہے ۔ سو تم خواہشِ نفس کی پیروی نہ کیا کرو کہ عدل سے ہٹ جاؤ گے ، اور اگر تم گواہی میں پیچ دار بات کرو گے یا حق سے پہلو تہی کرو گے تو بیشک اللہ ان سب کاموں سے جو تم کر رہے ہو خبردار ہے ۔',\n",
              " 'اے ایمان والو ! تم اللہ پر اور اس کے رسول صلی اللہ علیہ وآلہ وسلم پر اور اس کتاب پر جو اس نے اپنے رسول صلی اللہ علیہ وآلہ وسلم پر نازل فرمائی ہے اور اس کتاب پر جو اس نے اس سے پہلے اتاری تھی ایمان لاؤ ، اور جو کوئی اللہ کا اور اس کے فرشتوں کا اور اس کی کتابوں کا اور اس کے رسولوں کا اور آخرت کے دن کا انکار کرے تو بیشک وہ دور دراز کی گمراہی میں بھٹک گیا ۔',\n",
              " 'بیشک جو لوگ ایمان لائے پھر کافر ہوگئے ، پھر ایمان لائے پھر کافر ہوگئے ، پھر کفر میں اوربڑھ گئے تواللہ ہرگز یہ ارادہ فرمانے والا نہیں کہ انہیں بخش دے اور نہ یہ کہ انہیں سیدھا راستہ دکھائے ۔',\n",
              " 'اے نبی ! آپ منافقوں کو یہ خبر سنا دیں کہ ان کے لئے دردناک عذاب ہے ۔',\n",
              " 'یہ ایسے لوگ ہیں جو مسلمانوں کی بجائے کافروں کو دوست بناتے ہیں ، کیا یہ ان کے پاس عزت تلاش کرتے ہیں ؟ پس عزت تو ساری اللہ تعالٰی کے لئے ہے ۔',\n",
              " 'اور بیشک اللہ نے تم پر کتاب میں یہ حکم نازل فرمایا ہے کہ جب تم سنو کہ اللہ کی آیتوں کا انکار کیا جا رہا ہے اور ان کا مذاق اُڑایا جا رہا ہے تو تم ان لوگوں کے ساتھ مت بیٹھو یہاں تک کہ وہ انکار اور تمسخر کو چھوڑ کر کسی دوسری بات میں مشغول ہو جائیں ۔ ورنہ تم بھی انہی جیسے ہو جاؤ گے ۔ بیشک اللہ منافقوں اور کافروں سب کو دوزخ میں جمع کرنے والا ہے ۔',\n",
              " 'وہ منافق جو تمہاری فتح و شکست کی تاک میں رہتے ہیں ، پھر اگر تمہیں اللہ کی طرف سے فتح نصیب ہو جائے تو کہتے ہیں : کیا ہم تمہارے ساتھ نہ تھے ؟ اور اگر کافروں کو ظاہری فتح میں سے کچھ حصہ مل گیا تو ان سے کہتے ہیں : کیا ہم تم پر غالب نہیں ہو گئے تھے اور اس کے باوجود کیا ہم نے تمہیں مسلمانوں کے ہاتھوں نقصان سے نہیں بچایا ؟ پس اللہ تمہارے درمیان قیامت کے دن فیصلہ فرمائے گا ، اور اللہ کافروں کو مسلمانوں پر غلبہ پانے کی ہرگز کوئی راہ نہ دے گا ۔',\n",
              " 'بیشک منافق بزعمِ خویش اللہ کو دھوکہ دینا چاہتے ہیں حالانکہ وہ انہیں اپنے ہی دھوکے کی سزا دینے والا ہے ، اور جب وہ نماز کے لئے کھڑے ہوتے ہیں تو سستی کے ساتھ محض لوگوں کو دکھانے کیلئے کھڑے ہوتے ہیں اور اللہ کویاد بھی نہیں کرتے مگر تھوڑا ۔',\n",
              " 'اس کفر اور ایمان کے درمیان تذبذب میں ہیں نہ ان کافروں کی طرف ہیں اور نہ ان مؤمنوں کی طرف ہیں ، اورجسے اللہ گمراہ ٹھہرا دے تو آپ ہرگز اس کے لئے کوئی ہدایت کی راہ نہ پائیں گے ۔',\n",
              " 'اے ایمان والو ! مسلمانوں کے سوا کافروں کو دوست نہ بناؤ ، کیا تم چاہتے ہو کہ نافرمانوں کی دوستی کے ذریعے اپنے خلاف اللہ کی صریح حجت قائم کر لو ۔',\n",
              " 'بیشک منافق لوگ دوزخ کے سب سے نچلے درجے میں ہوں گے اور آپ ان کے لئے ہرگز کوئی مددگار نہ پائیں گے ۔',\n",
              " 'مگر وہ لوگ جنہوں نے توبہ کر لی وہ سنور گئے اورانہوں نے اللہ سے مضبوط تعلق جوڑ لیا اور انہوں نے اپنا دین اللہ کے لئے خالص کر لیا تو یہ مؤمنوں کی سنگت میں ہوں گے اور عنقریب اللہ مومنوں کو عظیم اجر عطا فرمائے گا ۔',\n",
              " 'اللہ تمہیں عذاب دے کر کیا کرے گا اگر تم شکر گزار بن جاؤ اور ایمان لے آؤ ، اور اللہ ہر حق کا قدر شناس ہے ہر عمل کا خوب جاننے والا ہے ۔',\n",
              " 'اﷲ کسی کی بری بات کا بآوازِ بلند ظاہراً و علانیۃً کہنا پسند نہیں فرماتا سوائے اس کے جس پر ظلم ہوا ہو اسے ظالم کا ظلم آشکار کرنے کی اجازت ہے ، اور اﷲ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'اگر تم کسی کارِ خیر کو ظاہر کرو یا اسے مخفی رکھو یا کسی کی برائی سے در گزر کرو تو بیشک اﷲ بڑا معاف فرمانے والا بڑی قدرت والا ہے ۔',\n",
              " 'بلا شبہ جو لوگ اﷲ اور اس کے رسولوں کے ساتھ کفر کرتے ہیں اور چاہتے ہیں کہ اﷲ اور اس کے رسولوں کے درمیان تفریق کریں اور کہتے ہیں کہ ہم بعض کو مانتے ہیں اور بعض کو نہیں مانتے اور چاہتے ہیں کہ اس ایمان و کفر کے درمیان کوئی راہ نکال لیں ۔',\n",
              " 'ایسے ہی لوگ درحقیقت کافر ہیں ، اور ہم نے کافروں کے لئے رُسوا کن عذاب تیار کر رکھا ہے ۔',\n",
              " 'اور جو لوگ اﷲ اور اس کے سب رسولوں پر ایمان لائے اور ان پیغمبروں میں سے کسی کے درمیان ایمان لانے میں فرق نہ کیا تو عنقریب وہ انہیں ان کے اجر عطا فرمائے گا ، اور اﷲ بڑا بخشنے والا نہایت مہربان ہے ۔',\n",
              " 'اے حبیب ! آپ سے اہلِ کتاب سوال کرتے ہیں کہ آپ ان پر آسمان سے ایک ہی دفعہ پوری لکھی ہوئی کوئی کتاب اتار لائیں ، تو وہ موسٰی علیہ السلام سے اس سے بھی بڑا سوال کر چکے ہیں ، انہوں نے کہا تھا کہ ہمیں اﷲ کی ذات کھلم کھلا دکھا دو ، پس ان کے اس ظلم یعنی گستاخانہ سوال کی وجہ سے انہیں آسمانی بجلی نے آپکڑا جس کے باعث وہ مرگئے ، پھر موسٰی علیہ السلام کی دعا سے زندہ ہوئے ، پھر انہوں نے بچھڑے کو اپنا معبود بنا لیا اس کے بعد کہ ان کے پاس حق کی نشاندہی کرنے والی واضح نشانیاں آچکی تھیں ، پھر ہم نے اس جرم سے بھی درگزر کیا اور ہم نے موسٰی علیہ السلام کو ان پر واضح غلبہ عطا فرمایا ۔',\n",
              " 'اور جب یہود تورات کے احکام سے پھر انکاری ہوگئے تو ہم نے ان سے پختہ عہد لینے کے لئے کوہِ طور کو ان کے اوپر اٹھا کر معلّق کر دیا ، اور ہم نے ان سے فرمایا کہ تم اس شہر کے دروازے یعنی بابِ ایلیاء میں سجدۂ شکر کرتے ہوئے داخل ہونا ، اور ہم نے ان سے مزید فرمایا کہ ہفتہ کے دن مچھلی کے شکار کی ممانعت کے حکم میں بھی تجاوز نہ کرنا اور ہم نے ان سے بڑا تاکیدی عہد لیا تھا ۔',\n",
              " 'پس انہیں جو سزائیں ملیں وہ ان کی اپنی عہد شکنی پر اور آیاتِ الٰہی سے انکار کے سبب اور انبیاء کو ان کے ناحق قتل کر ڈالنے کے باعث ، نیز ان کی اس بات کے سبب سے کہ ہمارے دلوں پر غلاف چڑھے ہوئے ہیں ، حقیقت میں ایسا نہ تھا بلکہ اﷲ نے ان کے کفر کے باعث ان کے دلوں پر مُہر لگا دی ہے ، سو وہ چند ایک کے سوا ایمان نہیں لائیں گے ۔',\n",
              " 'اور مزید یہ کہ ان کے اس کفر اور قول کے باعث جو انہوں نے مریم علیہا السلام پر زبردست بہتان لگایا ۔',\n",
              " 'اور ان کے اس کہنے یعنی فخریہ دعوٰی کی وجہ سے بھی کہ ہم نے اﷲ کے رسول ، مریم کے بیٹے عیسٰی مسیح کو قتل کر ڈالا ہے ، حالانکہ انہوں نے نہ ان کو قتل کیا اور نہ انہیں سولی چڑھایا مگر ہوا یہ کہ ان کے لئے کسی کو عیسٰی علیہ السلام کا ہم شکل بنا دیا گیا ، اور بیشک جو لوگ ان کے بارے میں اختلاف کر رہے ہیں وہ یقیناً اس قتل کے حوالے سے شک میں پڑے ہوئے ہیں ، انہیں حقیقتِ حال کا کچھ بھی علم نہیں مگر یہ کہ گمان کی پیروی کر رہے ہیں ، اور انہوں نے عیسٰی علیہ السلام کو یقیناً قتل نہیں کیا ۔',\n",
              " 'بلکہ اﷲ نے انہیں اپنی طرف آسمان پر اٹھا لیا ، اور اﷲ غالب حکمت والا ہے ۔',\n",
              " 'اور قربِ قیامت نزولِ مسیح علیہ السلام کے وقت اہلِ کتاب میں سے کوئی فرد یا فرقہ نہ رہے گا مگر وہ عیسٰی علیہ السلام پر ان کی موت سے پہلے ضرور صحیح طریقے سے ایمان لے آئے گا ، اور قیامت کے دن عیسٰی علیہ السلام ان پر گواہ ہوں گے ۔',\n",
              " 'پھر یہودیوں کے ظلم ہی کی وجہ سے ہم نے ان پر کئی پاکیزہ چیزیں حرام کر دیں جو پہلے ان کے لئے حلال کی جاچکی تھیں ، اور اس وجہ سے بھی کہ وہ لوگوں کو اﷲ کی راہ سے بکثرت روکتے تھے ۔',\n",
              " 'اور ان کے سود لینے کے سبب سے ، حالانکہ وہ اس سے روکے گئے تھے ، اور ان کے لوگوں کا ناحق مال کھانے کی وجہ سے بھی انہیں سزا ملی اور ہم نے ان میں سے کافروں کے لئے دردناک عذاب تیار کر رکھا ہے ۔',\n",
              " 'لیکن ان میں سے پختہ علم والے اور مومن لوگ اس وحی پر جو آپ کی طرف نازل کی گئی ہے اور اس وحی پر جو آپ سے پہلے نازل کی گئی برابر ایمان لاتے ہیں ، اور وہ کتنے اچھے ہیں کہ نماز قائم کرنے والے ہیں اور زکوٰۃ دینے والے ہیں اور اﷲ اور قیامت کے دن پر ایمان رکھنے والے ہیں ۔ ایسے ہی لوگوں کو ہم عنقریب بڑا اجر عطا فرمائیں گے ۔',\n",
              " 'اے حبیب ! بیشک ہم نے آپ کی طرف اُسی طرح وحی بھیجی ہے جیسے ہم نے نوح علیہ السلام کی طرف اور ان کے بعد دوسرے پیغمبروں کی طرف بھیجی تھی ۔ اور ہم نے ابراہیم و اسماعیل اور اسحاق و یعقوب اور ان کی اولاد اور عیسٰی اور ایوب اور یونس اور ہارون اور سلیمان علیھم السلام کی طرف بھی وحی فرمائی ، اور ہم نے داؤد علیہ السلام کو بھی زبور عطا کی تھی ۔',\n",
              " 'اور ہم نے کئی ایسے رسول بھیجے ہیں جن کے حالات ہم اس سے پہلے آپ کو سنا چکے ہیں اور کئی ایسے رسول بھی بھیجے ہیں جن کے حالات ہم نے ابھی تک آپ کو نہیں سنائے اور اﷲ نے موسٰی علیہ السلام سے بلاواسطہ گفتگو بھی فرمائی ۔',\n",
              " 'رسول جو خوشخبری دینے والے اور ڈر سنانے والے تھے اس لئے بھیجے گئے تاکہ ان پیغمبروں کے آجانے کے بعد لوگوں کے لئے اﷲ پر کوئی عذر باقی نہ رہے ، اور اﷲ بڑا غالب حکمت والا ہے ۔',\n",
              " 'اے حبیب ! کوئی آپ کی نبوت پر ایمان لائے یا نہ لائے مگر اﷲ خود اس بات کی گواہی دیتا ہے کہ جو کچھ اس نے آپ کی طرف نازل فرمایا ہے ، اسے اپنے علم سے نازل فرمایا ہے اور فرشتے بھی آپ کی خاطر گواہی دیتے ہیں ، اور اﷲ کا گواہ ہونا ہی کافی ہے ۔',\n",
              " 'بیشک جنہوں نے کفر کیا یعنی نبوتِ محمدی صلی اللہ علیہ وآلہ وسلم کی تکذیب کی اور لوگوں کو اﷲ کی راہ سے روکا ، یقینا وہ حق سے بہت دور کی گمراہی میں جا بھٹکے ۔',\n",
              " 'بیشک جنہوں نے اﷲ کی گواہی کو نہ مان کر کفر کیا اور رسول کی شان کو نہ مان کر ظلم کیا ، اﷲ ہرگز ایسا نہیں کہ انہیں بخش دے اور نہ ایسا ہے کہ آخرت میں انہیں کوئی راستہ دکھائے ۔',\n",
              " 'سوائے جہنم کے راستے کے جس میں وہ ہمیشہ ہمیشہ رہیں گے ، اور یہ کام اﷲ پر آسان ہے ۔',\n",
              " 'اے لوگو ! بیشک تمہارے پاس یہ رسول صلی اللہ علیہ وآلہ وسلم تمہارے رب کی طرف سے حق کے ساتھ تشریف لایا ہے ، سو تم ان پر اپنی بہتری کے لئے ایمان لے آؤ اور اگر تم کفر یعنی ان کی رسالت سے انکار کرو گے تو جان لو وہ تم سے بے نیاز ہے کیونکہ جو کچھ آسمانوں اور زمین میں ہے یقیناً وہ سب اﷲ ہی کا ہے اور اﷲ خوب جاننے والا بڑی حکمت والا ہے ۔',\n",
              " 'اے اہلِ کتاب ! تم اپنے دین میں حد سے زائد نہ بڑھو اور اﷲ کی شان میں سچ کے سوا کچھ نہ کہو ، حقیقت صرف یہ ہے کہ مسیح عیسٰی ابن مریم علیہما السلام اﷲ کا رسول اور اس کا کلمہ ہے جسے اس نے مریم کی طرف پہنچا دیا اور اس کی طرف سے ایک روح ہے ۔ پس تم اﷲ اور اس کے رسولوں پر ایمان لاؤ اور مت کہو کہ معبود تین ہیں ، اس عقیدہ سے باز آجاؤ ، یہ تمہارے لئے بہتر ہے ۔ بیشک اﷲ ہی یکتا معبود ہے ، وہ اس سے پاک ہے کہ اس کے لئے کوئی اولاد ہو ، سب کچھ اسی کا ہے جو کچھ آسمانوں میں ہے اور جو کچھ زمین میں ہے ، اور اﷲ کا کارساز ہونا کافی ہے ۔',\n",
              " 'مسیح علیہ السلام اس بات سے ہرگز عار نہیں رکھتا کہ وہ اﷲ کا بندہ ہو اور نہ ہی مقرّب فرشتوں کو اس سے کوئی عار ہے ، اور جو کوئی اس کی بندگی سے عار محسوس کرے اور تکبر کرے تو وہ ایسے تمام لوگوں کو عنقریب اپنے پاس جمع فرمائے گا ۔',\n",
              " 'پس جو لوگ ایمان لائے اور نیک عمل کرتے رہے وہ انہیں پورے پورے اجر عطا فرمائے گا اور پھر اپنے فضل سے انہیں اور زیادہ دے گا ، اور وہ لوگ جنہوں نے اﷲ کی عبادت سے عار محسوس کی اور تکبرّ کیا تو وہ انہیں دردناک عذاب دے گا ، اور وہ اپنے لئے اﷲ کے سوا نہ کوئی دوست پائیں گے اور نہ کوئی مددگار ۔',\n",
              " 'اے لوگو ! بیشک تمہارے پاس تمہارے رب کی جانب سے ذاتِ محمدی صلی اللہ علیہ وآلہ وسلم کی صورت میں ذاتِ حق جل مجدہ کی سب سے زیادہ مضبوط ، کامل اور واضح دلیلِ قاطع آگئی ہے اور ہم نے تمہاری طرف اسی کے ساتھ قرآن کی صورت میں واضح اور روشن نُور بھی اتار دیا ہے ۔',\n",
              " 'پس جو لوگ اﷲ پر ایمان لائے اور اس کے دامن کو مضبوطی سے پکڑے رکھا تو عنقریب اﷲ انہیں اپنی خاص رحمت اور فضل میں داخل فرمائے گا ، اور انہیں اپنی طرف پہنچنے کا سیدھا راستہ دکھائے گا ۔',\n",
              " 'لوگ آپ سے فتویٰ یعنی شرعی حکم دریافت کرتے ہیں ۔ فرما دیجئے کہ اﷲ تمہیں بغیر اولاد اور بغیر والدین کے فوت ہونے والے کلالہ کی وراثت کے بارے میں یہ حکم دیتا ہے کہ اگر کوئی ایسا شخص فوت ہو جائے جو بے اولاد ہو مگر اس کی ایک بہن ہو تو اس کے لئے اس مال کا آدھا حصہ ہے جو اس نے چھوڑا ہے ، اور اگر اس کے برعکس بہن کلالہ ہو تو اس کے مرنے کی صورت میں اس کا بھائی اس بہن کا وارث کامل ہوگا اگر اس بہن کی کوئی اولاد نہ ہو ، پھر اگر کلالہ بھائی کی موت پر دو بہنیں وارث ہوں تو ان کے لئے اس مال کا دو تہائی حصہ ہے جو اس نے چھوڑا ہے ، اور اگر بصورتِ کلالہ مرحوم کے چند بھائی بہن مرد بھی اور عورتیں بھی وارث ہوں تو پھر ہر ایک مرد کا حصہ دو عورتوں کے حصہ کے برابر ہوگا ۔ یہ احکام اﷲ تمہارے لئے کھول کر بیان فرما رہا ہے تاکہ تم بھٹکتے نہ پھرو ، اور اﷲ ہر چیز کو خوب جاننے والا ہے ۔',\n",
              " 'اے ایمان والو ! اپنے عہد پورے کرو ۔ تمہارے لئے چوپائے جانور یعنی مویشی حلال کر دیئے گئے ہیں سوائے ان جانوروں کے جن کا بیان تم پر آئندہ کیا جائے گا لیکن جب تم اِحرام کی حالت میں ہو ، شکار کو حلال نہ سمجھنا ۔ بیشک اﷲ جو چاہتا ہے حکم فرماتا ہے ۔',\n",
              " 'اے ایمان والو ! اﷲ کی نشانیوں کی بے حرمتی نہ کرو اور نہ حرمت و ادب والے مہینے کی یعنی ذوالقعدہ ، ذوالحجہ ، محرم اور رجب میں سے کسی ماہ کی اور نہ حرمِ کعبہ کو بھیجے ہوئے قربانی کے جانوروں کی اور نہ مکّہ لائے جانے والے ان جانوروں کی جن کے گلے میں علامتی پٹے ہوں اور نہ حرمت والے گھر یعنی خانہ کعبہ کا قصد کرکے آنے والوں کے جان و مال اور عزت و آبرو کی بے حرمتی کرو کیونکہ یہ وہ لوگ ہیں جو اپنے رب کا فضل اور رضا تلاش کر رہے ہیں ، اور جب تم حالتِ اِحرام سے باہر نکل آؤ تو تم شکار کرسکتے ہو ، اور تمہیں کسی قوم کی یہ دشمنی کہ انہوں نے تم کو مسجدِ حرام یعنی خانہ کعبہ کی حاضری سے روکا تھا اس بات پر ہرگز نہ ابھارے کہ تم ان کے ساتھ زیادتی کرو ، اور نیکی اور پرہیزگاری کے کاموں پر ایک دوسرے کی مدد کیا کرو اور گناہ اور ظلم کے کاموں پر ایک دوسرے کی مدد نہ کرو اور اﷲ سے ڈرتے رہو ۔ بیشک اﷲ نافرمانی کرنے والوں کو سخت سزا دینے والا ہے ۔',\n",
              " 'تم پر مردار یعنی بغیر شرعی ذبح کے مرنے والا جانور حرام کر دیا گیا ہے اور بہایا ہوا خون اور سؤر کا گوشت اور وہ جانور جس پر ذبح کے وقت غیر اﷲ کا نام پکارا گیا ہو اور گلا گھٹ کر مرا ہوا جانور اور دھار دار آلے کے بغیر کسی چیز کی ضرب سے مرا ہوا اور اوپر سے گر کر مرا ہوا اور کسی جانور کے سینگ مارنے سے مرا ہوا اور وہ جانور جسے درندے نے پھاڑ کھایا ہو سوائے اس کے جسے مرنے سے پہلے تم نے ذبح کر لیا ، اور وہ جانور بھی حرام ہے جو باطل معبودوں کے تھانوں یعنی بتوں کے لئے مخصوص کی گئی قربان گاہوں پر ذبح کیا گیا ہو اور یہ بھی حرام ہے کہ تم پانسوں یعنی فال کے تیروں کے ذریعے قسمت کا حال معلوم کرو یا حصے تقسیم کرو ، یہ سب کام گناہ ہیں ۔',\n",
              " 'آج کافر لوگ تمہارے دین کے غالب آجانے کے باعث اپنے ناپاک ارادوں سے مایوس ہو گئے ، سو اے مسلمانو ! تم ان سے مت ڈرو اور مجھ ہی سے ڈرا کرو ۔',\n",
              " 'آج میں نے تمہارے لئے تمہارا دین مکمل کر دیا اور تم پر اپنی نعمت پوری کر دی اور تمہارے لئے اسلام کو بطور دین یعنی مکمل نظامِ حیات کی حیثیت سے پسند کر لیا ۔ پھر اگر کوئی شخص بھوک اور پیاس کی شدت میں اضطراری یعنی انتہائی مجبوری کی حالت کو پہنچ جائے اس شرط کے ساتھ کہ گناہ کی طرف مائل ہونے والا نہ ہو یعنی حرام چیز گناہ کی رغبت کے باعث نہ کھائے تو بیشک اﷲ بہت بخشنے والا نہایت مہربان ہے ۔',\n",
              " 'لوگ آپ سے سوال کرتے ہیں کہ ان کے لئے کیا چیزیں حلال کی گئی ہیں ، آپ ان سے فرما دیں کہ تمہارے لئے پاک چیزیں حلال کر دی گئی ہیں اور وہ شکاری جانور جنہیں تم نے شکار پر دوڑاتے ہوئے یوں سدھار لیا ہے کہ تم انہیں شکار کے وہ طریقے سکھاتے ہو جو تمہیں اﷲ نے سکھائے ہیں ، سو تم اس شکار میں سے بھی کھاؤ جو وہ شکاری جانور تمہارے لئے مار کر روک رکھیں اور شکار پر چھوڑتے وقت اس شکاری جانور پر اﷲ کا نام لیا کرو اور اﷲ سے ڈرتے رہو ۔ بیشک اﷲ حساب میں جلدی فرمانے والا ہے ۔',\n",
              " 'آج تمہارے لئے پاکیزہ چیزیں حلال کر دی گئیں ، اور ان لوگوں کا ذبیحہ بھی جنہیں اِلہامی کتاب دی گئی تمہارے لئے حلال ہے اور تمہارا ذبیحہ ان کے لئے حلال ہے ، اور اسی طرح پاک دامن مسلمان عورتیں اور ان لوگوں میں سے پاک دامن عورتیں جنہیں تم سے پہلے کتاب دی گئی تھی تمہارے لئے حلال ہیں جب کہ تم انہیں ان کے مَہر ادا کر دو ، مگر شرط یہ کہ تم انہیں قیدِ نکاح میں لانے والے عفت شعار بنو نہ کہ محض ہوس رانی کی خاطر اِعلانیہ بدکاری کرنے والے اور نہ خفیہ آشنائی کرنے والے ، اور جو شخص اَحکامِ الٰہی پر ایمان لانے سے انکار کرے تو اس کا سارا عمل برباد ہوگیا اور وہ آخرت میں بھی نقصان اٹھانے والوں میں سے ہوگا ۔',\n",
              " 'اے ایمان والو ! جب تمہارا نماز کیلئے کھڑے ہونے کا ارادہ ہو تو وضو کے لئے اپنے چہروں کو اور اپنے ہاتھوں کو کہنیوں سمیت دھو لو اور اپنے سروں کا مسح کرو اور اپنے پاؤں بھی ٹخنوں سمیت دھو لو ، اور اگر تم حالتِ جنابت میں ہو تو نہا کر خوب پاک ہو جاؤ ، اور اگر تم بیمار ہو یا سفر میں ہو یا تم سے کوئی رفعِ حاجت سے فارغ ہو کر آیا ہو یا تم نے عورتوں سے قربت مجامعت کی ہو پھر تم پانی نہ پاؤ تو اندریں صورت پاک مٹی سے تیمم کر لیا کرو ۔ پس تیمم یہ ہے کہ اس پاک مٹی سے اپنے چہروں اور اپنے پورے ہاتھوں کا مسح کر لو ۔ اﷲ نہیں چاہتا کہ وہ تمہارے اوپر کسی قسم کی سختی کرے لیکن وہ یہ چاہتا ہے کہ تمہیں پاک کردے اور تم پر اپنی نعمت پوری کر دے تاکہ تم شکر گزار بن جاؤ ۔',\n",
              " 'اور اﷲ کی اس نعمت کو یاد کرو جو تم پر کی گئی ہے اور اس کے عہد کو بھی یاد کرو جو اس نے تم سے پختہ طریقے سے لیا تھا جب کہ تم نے اقراراً کہا تھا کہ ہم نے اﷲ کے حکم کو سنا اور ہم نے اس کی اطاعت کی اور اﷲ سے ڈرتے رہو ، بیشک اﷲ سینوں کی پوشیدہ باتوں کو خوب جانتا ہے ۔',\n",
              " 'اے ایمان والو ! اﷲ کے لئے مضبوطی سے قائم رہتے ہوئے انصاف پر مبنی گواہی دینے والے ہو جاؤ اور کسی قوم کی سخت دشمنی بھی تمہیں اس بات پر برانگیختہ نہ کرے کہ تم اس سے عدل نہ کرو ۔ عدل کیا کرو کہ وہ پرہیزگاری سے نزدیک تر ہے ، اور اﷲ سے ڈرا کرو ، بیشک اﷲ تمہارے کاموں سے خوب آگاہ ہے ۔',\n",
              " 'اﷲ نے ایسے لوگوں سے جو ایمان لائے اور نیک عمل کرتے رہے وعدہ فرمایا ہے کہ ان کے لئے بخشش اور بڑا اجر ہے ۔',\n",
              " 'اور جن لوگوں نے کفر کیا اور ہماری آیتوں کو جھٹلایا وہی لوگ دوزخ میں جلنے والے ہیں ۔',\n",
              " 'اے ایمان والو ! تم اﷲ کے اُس انعام کو یاد کرو جو تم پر ہوا جب قوم کفّار نے یہ ارادہ کیا کہ اپنے ہاتھ قتل و ہلاکت کے لئے تمہاری طرف دراز کریں تو اﷲ نے ان کے ہاتھ تم سے روک دیئے ، اور اﷲ سے ڈرتے رہو ، اور ایمان والوں کو اﷲ ہی پر بھروسہ رکھنا چاہئے ۔',\n",
              " 'اور بیشک اﷲ نے بنی اسرائیل سے پختہ عہد لیا اور اس کی تعمیل ، تنفیذ اور نگہبانی کے لئے ہم نے ان میں بارہ سردار مقرر کئے ، اور اﷲ نے بنی اسرائیل سے فرمایا کہ میں تمہارے ساتھ ہوں یعنی میری خصوصی مدد و نصرت تمہارے ساتھ رہے گی ، اگر تم نے نماز قائم رکھی اور تم زکوٰۃ دیتے رہے اور میرے رسولوں پر ہمیشہ ایمان لاتے رہے اور ان کے پیغمبرانہ مشن کی مدد کرتے رہے اور اﷲ کو اس کے دین کی حمایت و نصرت میں مال خرچ کرکے قرضِ حسن دیتے رہے تو میں تم سے تمہارے گناہوں کو ضرور مٹا دوں گا اور تمہیں یقیناً ایسی جنتوں میں داخل کر دوں گا جن کے نیچے نہریں جاری ہیں ۔ پھر اس کے بعد تم میں سے جس نے بھی کفر یعنی عہد سے انحراف کیا تو بیشک وہ سیدھی راہ سے بھٹک گیا ۔',\n",
              " 'پھر ان کی اپنی عہد شکنی کی وجہ سے ہم نے ان پر لعنت کی یعنی وہ ہماری رحمت سے محروم ہوگئے ، اور ہم نے ان کے دلوں کو سخت کر دیا یعنی وہ ہدایت اور اثر پذیری سے محروم ہوگئے ، چنانچہ وہ لوگ کتابِ الٰہی کے کلمات کو ان کے صحیح مقامات سے بدل دیتے ہیں اور اس رہنمائی کا ایک بڑا حصہ بھول گئے ہیں جس کی انہیں نصیحت کی گئی تھی ، اور آپ ہمیشہ ان کی کسی نہ کسی خیانت پر مطلع ہوتے رہیں گے سوائے ان میں سے چند ایک کے جو ایمان لا چکے ہیں سو آپ انہیں معاف فرما دیجئے اور درگزر فرمائیے ، بیشک اﷲ احسان کرنے والوں کو پسند فرماتا ہے ۔',\n",
              " 'اور ہم نے ان لوگوں سے بھی اسی قسم کا عہد لیا تھا جو کہتے ہیں : ہم نصاریٰ ہیں ، پھر وہ بھی اس رہنمائی کا ایک بڑا حصہ فراموش کر بیٹھے جس کی انہیں نصیحت کی گئی تھی ۔ سو اس بدعہدی کے باعث ہم نے ان کے درمیان دشمنی اور کینہ روزِ قیامت تک ڈال دیا ، اور عنقریب اﷲ انہیں ان اعمال کی حقیقت سے آگاہ فرما دے گا جو وہ کرتے رہتے تھے ۔',\n",
              " 'اے اہلِ کتاب ! بیشک تمہارے پاس ہمارے یہ رسول تشریف لائے ہیں جو تمہارے لئے بہت سی ایسی باتیں واضح طور پر ظاہر فرماتے ہیں جو تم کتاب میں سے چھپائے رکھتے تھے اور تمہاری بہت سی باتوں سے درگزر بھی فرماتے ہیں ۔ بیشک تمہارے پاس اﷲ کی طرف سے ایک نور یعنی حضرت محمد صلی اللہ علیہ وآلہ وسلم آگیا ہے اور ایک روشن کتاب یعنی قرآن مجید ۔',\n",
              " 'اﷲ اس کے ذریعے ان لوگوں کو جو اس کی رضا کے پیرو ہیں ، سلامتی کی راہوں کی ہدایت فرماتا ہے اور انہیں اپنے حکم سے کفر و جہالت کی تاریکیوں سے نکال کر ایمان و ہدایت کی روشنی کی طرف لے جاتا ہے اور انہیں سیدھی راہ کی سمت ہدایت فرماتا ہے ۔',\n",
              " 'بیشک ان لوگوں نے کفر کیا جو کہتے ہیں کہ یقیناً اﷲ مسیح ابن مریم ہی تو ہے ، آپ فرما دیں : پھر کون ایسا شخص ہے جو اﷲ کی مشیت میں سے کسی شے کا مالک ہو ؟ اگر وہ اس بات کا ارادہ فرمالے کہ مسیح ابن مریم اور اس کی ماں اور سب زمین والوں کو ہلاک فرما دے گا تو اس کے فیصلے کے خلاف انہیں کون بچا سکتا ہے ؟ اور آسمانوں اور زمین اور جو کائنات ان دونوں کے درمیان ہے سب کی بادشاہی اﷲ ہی کے لئے ہے ، وہ جو چاہتا ہے پیدا فرماتا ہے ، اور اﷲ ہر چیز پر بڑا قادر ہے ۔',\n",
              " 'اور یہود اور نصارٰی نے کہا : ہم اﷲ کے بیٹے اور اس کے محبوب ہیں ۔ آپ فرما دیجئے : اگر تمہاری بات درست ہے تو وہ تمہارے گناہوں پر تمہیں عذاب کیوں دیتا ہے ؟ بلکہ حقیقت یہ ہے کہ جن مخلوقات کو اﷲ نے پیدا کیا ہے تم بھی ان ہی میں سے بشر ہو یعنی دیگر طبقاتِ انسانی ہی کی مانند ہو ، وہ جسے چاہے بخشش سے نوازتا ہے اور جسے چاہے عذاب سے دوچار کرتا ہے ، اور آسمانوں اور زمین اور وہ کائنات جو دونوں کے درمیان ہے سب کی بادشاہی اﷲ ہی کے لئے ہے اور ہر ایک کو اسی کی طرف پلٹ کر جانا ہے ۔',\n",
              " 'اے اہلِ کتاب ! بیشک تمہارے پاس ہمارے یہ آخر الزمان رسول صلی اللہ علیہ وآلہ وسلم پیغمبروں کی آمد کے سلسلے کے منقطع ہونے کے موقع پر تشریف لائے ہیں ، جو تمہارے لئے ہمارے احکام خوب واضح کرتے ہیں ، اس لئے کہ تم عذر کرتے ہوئے یہ کہہ دوگے کہ ہمارے پاس نہ تو کوئی خوشخبری سنانے والا آیا ہے اور نہ ڈر سنانے والا ۔ اب تمہارا یہ عذر بھی ختم ہو چکا ہے کیونکہ بلاشبہ تمہارے پاس آخری خوشخبری سنانے اور ڈر سنانے والا بھی آگیا ہے ، اور اﷲ ہر چیز پر بڑا قادر ہے ۔',\n",
              " 'اور وہ وقت بھی یاد کریں جب موسٰی علیہ السلام نے اپنی قوم سے کہا : اے میری قوم ! تم اپنے اوپر کیا گیا اﷲ کا وہ انعام یاد کرو جب اس نے تم میں انبیاء پیدا فرمائے اور تمہیں بادشاہ بنایا اور تمہیں وہ کچھ عطا فرمایا جو تمہارے زمانے میں تمام جہانوں میں سے کسی کو نہیں دیا تھا ۔',\n",
              " 'اے میری قوم ! ملکِ شام یا بیت المقدس کی اس مقدس سرزمین میں داخل ہو جاؤ جو اﷲ نے تمہارے لئے لکھ دی ہے اور اپنی پشت پر پیچھے نہ پلٹنا ورنہ تم نقصان اٹھانے والے بن کر پلٹو گے ۔',\n",
              " 'انہوں نے جوابًا کہا : اے موسٰی ! اس میں تو زبردست ظالم لوگ رہتے ہیں اور ہم اس میں ہرگز داخل نہیں ہوں گے یہاں تک کہ وہ اس زمین سے نکل جائیں ، پس اگر وہ یہاں سے نکل جائیں تو ہم ضرور داخل ہو جائیں گے ۔',\n",
              " 'ان چند لوگوں میں سے جو اﷲ سے ڈرتے تھے دو ایسے شخص بول اٹھے جن پر اﷲ نے انعام فرمایا تھا اپنی قوم سے کہنے لگے : تم ان لوگوں پر بلا خوف حملہ کرتے ہوئے شہر کے دروازے سے داخل ہو جاؤ ، سو جب تم اس دروازے میں داخل ہو جاؤ گے تو یقیناً تم غالب ہو جاؤ گے ، اور اﷲ ہی پر توکل کرو بشرطیکہ تم ایمان والے ہو ۔',\n",
              " 'انہوں نے کہا : اے موسٰی ! جب تک وہ لوگ اس سرزمین میں ہیں ہم ہرگز کبھی بھی وہاں داخل نہیں ہوں گے ، پس تم جاؤ اور تمہارا رب ساتھ جائے سو تم دونوں ہی ان سے جنگ کرو ، ہم تو یہیں بیٹھے ہیں ۔',\n",
              " 'موسٰی علیہ السلام نے عرض کیا : اے میرے رب ! میں اپنی ذات اور اپنے بھائی ہارون علیہ السلام کے سوا کسی پر اختیار نہیں رکھتا پس تو ہمارے اور اس نافرمان قوم کے درمیان اپنے حکم سے جدائی فرما دے ۔',\n",
              " 'ربّ نے فرمایا : پس یہ سرزمین ان نافرمان لوگوں پر چالیس سال تک حرام کر دی گئی ہے ، یہ لوگ زمین میں پریشان حال سرگرداں پھرتے رہیں گے ، سو اے موسٰی ! اب اس نافرمان قوم کے عبرت ناک حال پر افسوس نہ کرنا ۔',\n",
              " 'اے نبی مکرم ! آپ ان لوگوں کو آدم علیہ السلام کے دو بیٹوں ہابیل و قابیل کی خبر سنائیں جو بالکل سچی ہے ۔ جب دونوں نے اﷲ کے حضور ایک ایک قربانی پیش کی سو ان میں سے ایک ہابیل کی قبول کر لی گئی اور دوسرے قابیل سے قبول نہ کی گئی تو اس قابیل نے ہابیل سے حسداً و انتقاماً کہا : میں تجھے ضرور قتل کر دوں گا ، اس ہابیل نے جواباً کہا : بیشک اﷲ پرہیزگاروں سے ہی نیاز قبول فرماتا ہے ۔',\n",
              " 'اگر تو اپنا ہاتھ مجھے قتل کرنے کے لئے میری طرف بڑھائے گا تو پھر بھی میں اپنا ہاتھ تجھے قتل کرنے کے لئے تیری طرف نہیں بڑھاؤں گا کیونکہ میں اﷲ سے ڈرتا ہوں جو تمام جہانوں کا پروردگار ہے ۔',\n",
              " 'میں چاہتا ہوں کہ مجھ سے کوئی زیادتی نہ ہو اور میرا گناہ ِ قتل اور تیرا اپنا سابقہ گناہ جس کے باعث تیری قربانی نامنظور ہوئی سب توہی حاصل کرلے پھر تو اہلِ جہنم میں سے ہو جائے گا ، اور یہی ظالموں کی سزا ہے ۔',\n",
              " 'پھر اس قابیل کے نفس نے اس کے لئے اپنے بھائی ہابیل کا قتل آسان اور مرغوب کر دکھایا ، سو اس نے اس کو قتل کردیا ، پس وہ نقصان اٹھانے والوں میں سے ہوگیا ۔',\n",
              " 'پھر اﷲ نے ایک کوّا بھیجا جو زمین کریدنے لگا تاکہ اسے دکھائے کہ وہ اپنے بھائی کی لاش کس طرح چھپائے ، یہ دیکھ کر اس نے کہا : ہائے افسوس ! کیا میں اس کوّے کی مانند بھی نہ ہوسکا کہ اپنے بھائی کی لاش چھپا دیتا ، سو وہ پشیمان ہونے والوں میں سے ہوگیا ۔',\n",
              " 'اسی وجہ سے ہم نے بنی اسرائیل پر نازل کی گئی تورات میں یہ حکم لکھ دیا تھا کہ جس نے کسی شخص کو بغیر قصاص کے یا زمین میں فساد پھیلانے یعنی خونریزی اور ڈاکہ زنی وغیرہ کی سزا کے بغیر ناحق قتل کر دیا تو گویا اس نے معاشرے کے تمام لوگوں کو قتل کر ڈالا اور جس نے اسے ناحق مرنے سے بچا کر زندہ رکھا تو گویا اس نے معاشرے کے تمام لوگوں کو زندہ رکھا یعنی اس نے حیاتِ انسانی کا اجتماعی نظام بچا لیا ، اور بیشک ان کے پاس ہمارے رسول واضح نشانیاں لے کر آئے پھر بھی اس کے بعد ان میں سے اکثر لوگ یقیناً زمین میں حد سے تجاوز کرنے والے ہیں ۔',\n",
              " 'بیشک جو لوگ اﷲ اور اس کے رسول سے جنگ کرتے ہیں اور زمین میں فساد انگیزی کرتے پھرتے ہیں یعنی مسلمانوں میں خونریز رہزنی اور ڈاکہ زنی وغیرہ کے مرتکب ہوتے ہیں ان کی سزا یہی ہے کہ وہ قتل کئے جائیں یا پھانسی دیئے جائیں یا ان کے ہاتھ اور ان کے پاؤں مخالف سمتوں سے کاٹے جائیں یا وطن کی زمین میں چلنے پھرنے سے دور یعنی ملک بدر یاقید کر دیئے جائیں ۔ یہ تو ان کے لئے دنیا میں رسوائی ہے اور ان کے لئے آخرت میں بھی بڑا عذاب ہے ۔',\n",
              " 'مگر جن لوگوں نے ، قبل اس کے کہ تم ان پر قابو پا جاؤ ، توبہ کرلی ، سو جان لو کہ اﷲ بہت بخشنے والا نہایت مہربان ہے ۔',\n",
              " 'اے ایمان والو ! اﷲ سے ڈرتے رہو اور اس کے حضور تک تقرب اور رسائی کا وسیلہ تلاش کرو اور اس کی راہ میں جہاد کرو تاکہ تم فلاح پاجاؤ ۔',\n",
              " 'بیشک جو لوگ کفر کے مرتکب ہو رہے ہیں اگر ان کے پاس وہ سب کچھ مال و متاع اور خزانہ موجود ہو جو روئے زمین میں ہے بلکہ اس کے ساتھ اتنا اور بھی تاکہ وہ روزِ قیامت کے عذاب سے نجات کے لئے اسے فدیہ یعنی اپنی جان کے بدلہ میں دے دیں تو وہ سب کچھ بھی ان سے قبول نہیں کیا جائے گا ، اور ان کے لئے درد ناک عذاب ہے ۔',\n",
              " 'وہ چاہیں گے کہ کسی طرح دوزخ سے نکل جائیں جب کہ وہ اس سے نہیں نکل سکیں گے اور ان کے لئے دائمی عذاب ہے ۔',\n",
              " 'اور چوری کرنے والا مرد اور چوری کرنے والی عورت سو دونوں کے ہاتھ کاٹ دو اس جرم کی پاداش میں جو انہوں نے کمایا ہے ۔ یہ اﷲ کی طرف سے عبرت ناک سزا ہے ، اور اﷲ بڑا غالب ہے بڑی حکمت والا ہے ۔',\n",
              " 'پھر جو شخص اپنے اس ظلم کے بعد توبہ اور اصلاح کرلے تو بیشک اﷲ اس پر رحمت کے ساتھ رجوع فرمانے والا ہے ۔ یقیناً اﷲ بڑا بخشنے والا بہت رحم فرمانے والا ہے ۔',\n",
              " 'اے انسان ! کیا تو نہیں جانتا کہ آسمانوں اور زمین کی ساری بادشاہت اﷲ ہی کے لئے ہے ، وہ جسے چاہتا ہے عذاب دیتا ہے اور جسے چاہتا ہے بخش دیتا ہے ، اور اللہ ہر چیز پر خوب قدرت رکھتا ہے ۔',\n",
              " 'اے رسول ! وہ لوگ آپ کور نجیدہ خاطر نہ کریں جو کفر میں تیزی سے پیش قدمی کرتے ہیں ان میں ایک وہ منافق ہیں جو اپنے منہ سے کہتے ہیں کہ ہم ایمان لائے حالانکہ ان کے دل ایمان نہیں لائے ، اور ان میں دوسرے یہودی ہیں ، یہ جھوٹی باتیں بنانے کے لئے آپ کو خوب سنتے ہیں یہ حقیقت میں دوسرے لوگوں کے لئے جاسوسی کی خاطر سننے والے ہیں جو ابھی تک آپ کے پاس نہیں آئے ، یہ وہ لوگ ہیں جو اﷲ کے کلمات کوان کے مواقع مقرر ہونے کے بعد بھی بدل دیتے ہیں اور کہتے ہیں : اگر تمہیں یہ حکم جو ان کی پسند کا ہو دیا جائے تو اسے اختیار کرلو اور اگر تمہیں یہ حکم نہ دیا جائے تو اس سے احتراز کرو ، اور اﷲ جس شخص کی گمراہی کا ارادہ فرمالے تو تم اس کے لئے اﷲ کے حکم کو روکنے کا ہرگز کوئی اختیار نہیں رکھتے ۔ یہی وہ لوگ ہیں جن کے دلوں کو پاک کرنے کااﷲ نے ارادہ ہی نہیں فرمایا ۔ ان کے لئے دنیا میں کفر کی ذلّت ہے اور ان کے لئے آخرت میں بڑا عذاب ہے ۔',\n",
              " 'یہ لوگ جھوٹی باتیں بنانے کے لئے جاسوسی کرنے والے ہیں مزید یہ کہ حرام مال خوب کھانے والے ہیں ۔ سو اگر یہ لوگ آپ کے پاس کوئی نزاعی معاملہ لے کر آئیں تو آپ کو اختیار ہے کہ ان کے درمیان فیصلہ فرمادیں یا ان سے گریز فرما لیں ، اور اگر آپ ان سے گریز بھی فرمالیں تو تب بھی یہ آپ کو ہرگز کوئی ضرر نہیں پہنچا سکتے ، اور اگر آپ فیصلہ فرمائیں تو ان کے درمیان بھی عدل سے ہی فیصلہ فرمائیں یعنی ان کی دشمنی عادلانہ فیصلے میں رکاوٹ نہ بنے ، بیشک اﷲ عدل کرنے والوں کو پسند فرماتا ہے ۔',\n",
              " 'اور یہ لوگ آپ کو کیوں کر حاکم مان سکتے ہیں در آنحالیکہ ان کے پاس تورات موجود ہے جس میں اللہ کا حکم مذکور ہے ، پھر یہ اس کے بعد بھی حق سے رُوگردانی کرتے ہیں ، اور وہ لوگ بالکل ایمان لانے والے نہیں ہیں ۔',\n",
              " 'بیشک ہم نے تورات نازل فرمائی جس میں ہدایت اور نور تھا ، اس کے مطابق انبیاء جو اﷲ کے فرمانبردار بندے تھے یہودیوں کو حکم دیتے رہے اور اﷲ والے یعنی ان کے اولیاء اور علماء بھی اسی کے مطابق فیصلے کرتے رہے ، اس وجہ سے کہ وہ اﷲ کی کتاب کے محافظ بنائے گئے تھے اور وہ اس پر نگہبان و گواہ تھے ۔ پس تم اقامتِ دین اور احکامِ الٰہی کے نفاذ کے معاملے میں لوگوں سے مت ڈرو اور صرف مجھ سے ڈرا کرو اور میری آیات یعنی احکام کے بدلے دنیا کی حقیر قیمت نہ لیا کرو ، اور جو شخص اللہ کے نازل کردہ حکم کے مطابق فیصلہ و حکومت نہ کرے سو وہی لوگ کافر ہیں ۔',\n",
              " 'اور ہم نے اس تورات میں ان پر فرض کردیا تھا کہ جان کے بدلے جان اور آنکھ کے عوض آنکھ اور ناک کے بدلے ناک اور کان کے عوض کان اور دانت کے بدلے دانت اور زخموں میں بھی بدلہ ہے ، تو جو شخص اس قصاص کو صدقہ یعنی معاف کر دے تو یہ اس کے گناہوں کے لئے کفارہ ہوگا ، اور جو شخص اللہ کے نازل کردہ حکم کے مطابق فیصلہ و حکومت نہ کرے سو وہی لوگ ظالم ہیں ۔',\n",
              " 'اور ہم نے ان پیغمبروں کے پیچھے ان ہی کے نقوشِ قدم پر عیسٰی ابن مریم علیھما السلام کو بھیجا جو اپنے سے پہلے کی کتاب تورات کی تصدیق کرنے والے تھے اور ہم نے ان کو انجیل عطا کی جس میں ہدایت اور نور تھا اور یہ انجیل بھی اپنے سے پہلے کی کتاب تورات کی تصدیق کرنے والی تھی اور سراسر ہدایت تھی اور پرہیز گاروں کے لئے نصیحت تھی ۔',\n",
              " 'اور اہلِ انجیل کو بھی اس حکم کے مطابق فیصلہ کرنا چاہئے جو اللہ نے اس میں نازل فرمایا ہے ، اور جو شخص اللہ کے نازل کردہ حکم کے مطابق فیصلہ و حکومت نہ کرے سو وہی لوگ فاسق ہیں ۔',\n",
              " 'اور اے نبئ مکرّم ! ہم نے آپ کی طرف بھی سچائی کے ساتھ کتاب نازل فرمائی ہے جو اپنے سے پہلے کی کتاب کی تصدیق کرنے والی ہے اور اس کے اصل احکام و مضامین پر نگہبان ہے ، پس آپ ان کے درمیان ان احکام کے مطابق فیصلہ فرمائیں جو اﷲ نے نازل فرمائے ہیں اور آپ ان کی خواہشات کی پیروی نہ کریں ، اس حق سے دور ہو کر جو آپ کے پاس آچکا ہے ۔ ہم نے تم میں سے ہر ایک کے لئے الگ شریعت اور کشادہ راہِ عمل بنائی ہے ، اور اگر اﷲ چاہتا تو تم سب کو ایک شریعت پر متفق ایک ہی امّت بنا دیتا لیکن وہ تمہیں ان الگ الگ احکام میں آزمانا چاہتا ہے جو اس نے تمہیں تمہارے حسبِ حال دیئے ہیں ، سو تم نیکیوں میں جلدی کرو ۔ اﷲ ہی کی طرف تم سب کو پلٹنا ہے ، پھر وہ تمہیں ان سب باتوں میں حق و باطل سے آگاہ فرمادے گا جن میں تم اختلاف کرتے رہتے تھے ۔',\n",
              " 'اور اے حبیب ! ہم نے یہ حکم کیا ہے کہ آپ ان کے درمیان اس فرمان کے مطابق فیصلہ فرمائیں جو اﷲ نے نازل فرمایا ہے اور ان کی خواہشات کی پیروی نہ کریں اور آپ ان سے بچتے رہیں کہیں وہ آپ کو ان بعض احکام سے جو اللہ نے آپ کی طرف نازل فرمائے ہیں پھیر نہ دیں ، پھر اگر وہ آپ کے فیصلہ سے روگردانی کریں تو آپ جان لیں کہ بس اﷲ ان کے بعض گناہوں کے باعث انہیں سزا دینا چاہتا ہے ، اور لوگوں میں سے اکثر نافرمان ہوتے ہیں ۔',\n",
              " 'کیا یہ لوگ زمانۂ جاہلیت کا قانون چاہتے ہیں ، اور یقین رکھنے والی قوم کے لئے حکم دینے میں اﷲ سے بہتر کون ہو سکتا ہے ۔',\n",
              " 'اے ایمان والو ! یہود اور نصارٰی کو دوست مت بناؤ یہ سب تمہارے خلاف آپس میں ایک دوسرے کے دوست ہیں ، اور تم میں سے جو شخص ان کو دوست بنائے گا بیشک وہ بھی ان میں سے ہو جائے گا ، یقیناً اﷲ ظالم قوم کو ہدایت نہیں فرماتا ۔',\n",
              " 'سو آپ ایسے لوگوں کو دیکھیں گے جن کے دلوں میں نفاق اور ذہنوں میں غلامی کی بیماری ہے کہ وہ ان یہود و نصارٰی میں شامل ہونے کے لئے دوڑتے ہیں ، کہتے ہیں : ہمیں خوف ہے کہ ہم پر کوئی گردش نہ آجائے یعنی ان کے ساتھ ملنے سے شاید ہمیں تحفظ مل جائے ، تو بعید نہیں کہ اﷲ واقعۃً مسلمانوں کی فتح لے آئے یا اپنی طرف سے کوئی امر فتح و کامرانی کا نشان بنا کر بھیج دے تو یہ لوگ اس منافقانہ سوچ پر جسے یہ اپنے دلوں میں چھپائے ہوئے ہیں شرمندہ ہوکر رہ جائیں گے ۔',\n",
              " 'اور اس وقت ایمان والے یہ کہیں گے کیا یہی وہ لوگ ہیں جنہوں نے بڑے تاکیدی حلف کی صورت میں اﷲ کی قَسمیں کھائی تھیں کہ بیشک وہ ضرور تمہارے ہی ساتھ ہیں ، مگر ان کے سارے اعمال اکارت گئے ، سو وہ نقصان اٹھانے والے ہوگئے ۔',\n",
              " 'اے ایمان والو ! تم میں سے جو شخص اپنے دین سے پھر جائے گا تو عنقریب اﷲ ان کی جگہ ایسی قوم کو لائے گا جن سے وہ خود محبت فرماتا ہوگا اور وہ اس سے محبت کرتے ہوں گے وہ مومنوں پر نرم اور کافروں پر سخت ہوں گے اﷲ کی راہ میں خوب جہاد کریں گے اور کسی ملامت کرنے والے کی ملامت سے خوفزدہ نہیں ہوں گے ۔ یہ انقلابی کردار اللہ کافضل ہے وہ جسے چاہتا ہے عطا فرماتا ہے اور اﷲ وسعت والا ہے خوب جاننے والا ہے ۔',\n",
              " 'بیشک تمہارا مددگار دوست تو اﷲ اور اس کا رسول صلی اللہ علیہ وآلہ وسلم ہی ہے اور ساتھ وہ ایمان والے ہیں جو نماز قائم رکھتے ہیں اور زکوٰۃ ادا کرتے ہیں اور وہ اﷲ کے حضور عاجزی سے جھکنے والے ہیں ۔',\n",
              " 'اور جو شخص اﷲ اور اس کے رسول صلی اللہ علیہ وآلہ وسلم اور ایمان والوں کو دوست بنائے گا تو وہی اﷲ کی جماعت ہے اور اللہ کی جماعت کے لوگ ہی غالب ہونے والے ہیں ۔',\n",
              " 'اے ایمان والو ! ایسے لوگوں میں سے جنہیں تم سے پہلے کتاب دی گئی تھی ، ان کو جو تمہارے دین کو ہنسی اور کھیل بنائے ہوئے ہیں اور کافروں کو دوست مت بناؤ ، اور اﷲ سے ڈرتے رہو بشرطیکہ تم واقعی صاحبِ ایمان ہو ۔',\n",
              " 'اور جب تم نماز کے لئے لوگوں کو بصورتِ اذان پکارتے ہو تو یہ لوگ اسے ہنسی اور کھیل بنا لیتے ہیں ۔ یہ اس لئے کہ وہ ایسے لوگ ہیں جو بالکل عقل ہی نہیں رکھتے ۔',\n",
              " 'اے نبئ مکرّم ! آپ فرما دیجئے : اے اہلِ کتاب ! تمہیں ہماری کون سی بات بری لگی ہے بجز اس کے کہ ہم اﷲ پر اور اس کتاب پر جو ہماری طرف نازل کی گئی ہے اور ان کتابوں پر جو پہلے نازل کی جا چکی ہیں ایمان لائے ہیں اور بیشک تمہارے اکثر لوگ نافرمان ہیں ۔',\n",
              " 'فرما دیجئے : کیا میں تمہیں اس شخص سے آگاہ کروں جو سزا کے اعتبار سے اللہ کے نزدیک اس سے بھی برا ہے جسے تم برا سمجھتے ہو ، اور یہ وہ شخص ہی جس پر اللہ نے لعنت کی ہے اور اس پر غضب ناک ہوا ہے اور اس نے ان برے لوگوں میں سے بعض کو بندر اور بعض کو سؤر بنا دیا ہے ، اور یہ ایسا شخص ہے جس نے شیطان کی اطاعت و پرستش کی ہے ، یہی لوگ ٹھکانے کے اعتبار سے بدترین اور سیدھی راہ سے بہت ہی بھٹکے ہوئے ہیں ۔',\n",
              " 'اور جب وہ منافق تمہارے پاس آتے ہیں تو کہتے ہیں : ہم ایمان لے آئے ہیں حالانکہ وہ تمہاری مجلس میں کفر کے ساتھ ہی داخل ہوئے اور اسی کفر کے ساتھ ہی نکل گئے ، اور اﷲ ان باتوں کو خوب جانتا ہے جنہیں وہ چھپائے پھرتے ہیں ۔',\n",
              " 'اور آپ ان میں بکثرت ایسے لوگ دیکھیں گے جو گناہ اور ظلم اور اپنی حرام خوری میں بڑی تیزی سے کوشاں ہوتے ہیں ۔ بیشک وہ جو کچھ کررہے ہیں بہت برا ہے ۔',\n",
              " 'انہیں روحانی درویش اور دینی علماء ان کے قولِ گناہ اور اکلِ حرام سے منع کیوں نہیں کرتے ؟ بیشک وہ بھی برائی کے خلاف آواز بلند نہ کر کے جو کچھ تیار کر رہے ہیں بہت برا ہے ۔',\n",
              " 'اور یہود کہتے ہیں کہ اﷲ کا ہاتھ بندھا ہوا ہے یعنی معاذ اﷲ وہ بخیل ہے ، ان کے اپنے ہاتھ باندھے جائیں اور جو کچھ انہوں نے کہا اس کے باعث ان پر لعنت کی گئی ، بلکہ حق یہ ہے کہ اس کے دونوں ہاتھ جود و سخا کے لئے کشادہ ہیں ، وہ جس طرح چاہتا ہے خرچ یعنی بندوں پر عطائیں فرماتا ہے ، اور اے حبیب ! جو کتاب آپ کی طرف آپ کے ربّ کی جانب سے نازل کی گئی ہے یقیناً ان میں سے اکثر لوگوں کو حسداً سر کشی اور کفر میں اور بڑھا دے گی ، اور ہم نے ان کے درمیان روزِ قیامت تک عداوت اور بغض ڈال دیا ہے ، جب بھی یہ لوگ جنگ کی آگ بھڑکاتے ہیں اﷲ اسے بجھا دیتا ہے اور یہ روئے زمین میں فساد انگیزی کرتے رہتے ہیں ، اور اﷲ فساد کرنے والوں کو پسند نہیں کرتا ۔',\n",
              " 'اور اگر اہلِ کتاب حضرت محمد مصطفی صلی اللہ علیہ وآلہ وسلم پر ایمان لے آتے اور تقوٰی اختیار کر لیتے تو ہم ان کے دامن سے ان کے سارے گناہ مٹا دیتے اور انہیں یقیناً نعمت والی جنتوں میں داخل کردیتے ۔',\n",
              " 'اور اگر وہ لوگ تورات اور انجیل اور جو کچھ مزید ان کی طرف ان کے رب کی جانب سے نازل کیا گیا تھا نافذ اور قائم کردیتے تو انہیں مالی وسائل کی اس قدر وسعت عطا ہوجاتی کہ وہ اپنے اوپر سے بھی اور اپنے پاؤں کے نیچے سے بھی کھاتے مگر رزق ختم نہ ہوتا ۔ ان میں سے ایک گروہ میانہ رَو یعنی اعتدال پسند ہے ، اور ان میں سے اکثر لوگ جو کچھ کررہے ہیں نہایت ہی برا ہے ۔',\n",
              " 'اے برگزیدہ رسول ! جو کچھ آپ کی طرف آپ کے رب کی جانب سے نازل کیا گیا ہے وہ سارا لوگوں کو پہنچا دیجئے ، اور اگر آپ نے ایسا نہ کیا تو آپ نے اس ربّ کا پیغام پہنچایا ہی نہیں ، اور اﷲ مخالف لوگوں سے آپ کی جان کی خود حفاظت فرمائے گا ۔ بیشک اﷲ کافروں کو راہِ ہدایت نہیں دکھاتا ۔',\n",
              " 'فرما دیجئے : اے اہلِ کتاب ! تم دین میں سے کسی شے پر بھی نہیں ہو ، یہاں تک کہ تم تورات اور انجیل اور جو کچھ تمہاری طرف تمہارے رب کی جانب سے نازل کیا گیا ہے نافذ اور قائم کر دو ، اور اے حبیب ! جو کتاب آپ کی طرف آپ کے رب کی جانب سے نازل کی گئی ہے یقیناً ان میں سے اکثر لوگوں کو حسداً سرکشی اور کفر میں بڑھا دے گی ، سو آپ گروہِ کفار کی حالت پر افسوس نہ کیا کریں ۔',\n",
              " 'بیشک خود کو مسلمان کہنے والے اور یہودی اور صابی یعنی ستارہ پرست اور نصرانی جو بھی سچے دل سے تعلیماتِ محمدی کے مطابق اللہ پر اور یومِ آخرت پر ایمان لائے اور نیک عمل کرتے رہے تو ان پر نہ کوئی خوف ہوگا اور نہ وہ غمگین ہوں گے ۔',\n",
              " 'بیشک ہم نے بنی اسرائیل سے عہد بھی لیا اور ہم نے ان کی طرف بہت سے پیغمبر بھی بھیجے ، مگر جب بھی ان کے پاس کوئی پیغمبر ایسا حکم لایا جسے ان کے نفس نہیں چاہتے تھے تو انہوں نے انبیاء کی ایک جماعت کو جھٹلایا اور ایک کو مسلسل قتل کرتے رہے ۔',\n",
              " 'اور وہ ساتھ یہ خیال کرتے رہے کہ انبیاء کے قتل و تکذیب سے کوئی عذاب نہیں آئے گا ، سو وہ اندھے اور بہرے ہوگئے تھے ۔ پھر اﷲ نے ان کی توبہ قبول فرما لی ، پھر ان میں سے اکثر لوگ دوبارہ اندھے اور بہرے یعنی حق دیکھنے اور سننے سے قاصر ہوگئے ، اور اﷲ ان کاموں کو خوب دیکھ رہا ہے جو وہ کر رہے ہیں ۔',\n",
              " 'درحقیقت ایسے لوگ کافر ہوگئے ہیں جنہوں نے کہا کہ اﷲ ہی مسیح ابنِ مریم علیہما السلام ہے حالانکہ مسیح علیہ السلام نے تو یہ کہا تھا : اے بنی اسرائیل ! تم اللہ کی عبادت کرو جو میرا بھی ربّ ہے اور تمہارا بھی ربّ ہے ۔ بیشک جو اللہ کے ساتھ شرک کرے گا تو یقیناً اﷲ نے اس پر جنت حرام فرما دی ہے اور اس کا ٹھکانا دوزخ ہے ، اور ظالموں کے لئے کوئی بھی مدد گار نہ ہوگا ۔',\n",
              " 'بیشک ایسے لوگ بھی کافر ہوگئے ہیں جنہوں نے کہا کہ اللہ تین معبودوں میں سے تیسرا ہے ، حالانکہ معبودِ یکتا کے سوا کوئی عبادت کے لائق نہیں ، اور اگر وہ ان بیہودہ باتوں سے جو وہ کہہ رہے ہیں بازنہ آئے تو ان میں سے کافروں کو دردناک عذاب ضرور پہنچے گا ۔',\n",
              " 'کیا یہ لوگ اللہ کی بارگاہ میں رجوع نہیں کرتے اور اس سے مغفرت طلب نہیں کرتے ، حالانکہ اﷲ بڑا بخشنے والا بہت رحم فرمانے والا ہے ۔',\n",
              " 'مسیح ابنِ مریم علیھما السلام رسول کے سوا کچھ نہیں ہیں یعنی خدا یا خدا کا بیٹا اور شریک نہیں ہیں ، یقیناً ان سے پہلے بھی بہت سے رسول گزر چکے ہیں ، اور ان کی والدہ بڑی صاحبِ صدق ولیّہ تھیں ، وہ دونوں مخلوق تھے کیونکہ کھانا بھی کھایا کرتے تھے ۔ اے حبیب ! دیکھئے ہم ان کی رہنمائی کے لئے کس طرح آیتوں کو وضاحت سے بیان کرتے ہیں پھر ملاحظہ فرمائیے کہ اس کے باوجود وہ کس طرح حق سے پھرے جارہے ہیں ۔',\n",
              " 'فرما دیجئے : کیا تم اللہ کے سوا اس کی عبادت کرتے ہو جو نہ تمہارے لئے کسی نقصان کا مالک ہے نہ نفع کا ، اور اﷲ ہی تو خوب سننے والا اور خوب جاننے والا ہے ۔',\n",
              " 'فرما دیجئیے : اے اہلِ کتاب ! تم اپنے دین میں ناحق حد سے تجاوز نہ کیا کرو اور نہ ان لوگوں کی خواہشات کی پیروی کیا کرو جو بعثتِ محمدی صلی اللہ علیہ وآلہ وسلم سے پہلے ہی گمراہ ہو چکے تھے اور بہت سے اور لوگوں کو بھی گمراہ کرگئے اور بعثتِ محمدی صلی اللہ علیہ وآلہ وسلم کے بعد بھی سیدھی راہ سے بھٹکے رہے ۔',\n",
              " 'بنی اسرائیل میں سے جن لوگوں نے کفر کیا تھا انہیں داؤد اور عیسٰی ابن مریم علیھما السلام کی زبان پر سے لعنت کی جا چکی ہے ۔ یہ اس لئے کہ انہوں نے نافرمانی کی اور حد سے تجاوز کرتے تھے ۔',\n",
              " 'اور اس لعنت کا ایک سبب یہ بھی تھا کہ وہ جو برا کام کرتے تھے ایک دوسرے کو اس سے منع نہیں کرتے تھے ۔ بیشک وہ کام برے تھے جنہیں وہ انجام دیتے تھے ۔',\n",
              " 'آپ ان میں سے اکثر لوگوں کو دیکھیں گے کہ وہ کافروں سے دوستی رکھتے ہیں ۔ کیا ہی بری چیز ہے جو انہوں نے اپنے حسابِ آخرت کے لئے آگے بھیج رکھی ہے اور وہ یہ کہ اﷲ ان پر سخت ناراض ہوگیا ، اور وہ لوگ ہمیشہ عذاب ہی میں گرفتار رہنے والے ہیں ۔',\n",
              " 'اور اگر وہ اللہ پر اور نبی آخرالزماں صلی اللہ علیہ وآلہ وسلم پر اور اس کتاب پر جو ان کی طرف نازل کی گئی ہے ایمان لے آتے تو ان دشمنانِ اسلام کو دوست نہ بناتے ، لیکن ان میں سے اکثر لوگ نافرمان ہیں ۔',\n",
              " 'آپ یقیناً ایمان والوں کے حق میں بلحاظِ عداوت سب لوگوں سے زیادہ سخت یہودیوں اور مشرکوں کو پائیں گے ، اور آپ یقیناً ایمان والوں کے حق میں بلحاظِ محبت سب سے قریب تر ان لوگوں کو پائیں گے جو کہتے ہیں : بیشک ہم نصاریٰ ہیں ۔ یہ اس لئے کہ ان میں علماءِ شریعت بھی ہیں اور عبادت گزار گوشہ نشین بھی ہیں اور نیز وہ تکبر نہیں کرتے ۔',\n",
              " 'اور یہی وجہ ہے کہ ان میں سے بعض سچے عیسائی جب اس قرآن کو سنتے ہیں جو رسول صلی اللہ علیہ وآلہ وسلم کی طرف اتارا گیا ہے تو آپ ان کی آنکھوں کو اشک ریز دیکھتے ہیں ۔ یہ آنسوؤں کا چھلکنا اس حق کے باعث ہے جس کی انہیں معرفت نصیب ہوگئی ہے ۔ ساتھ یہ عرض کرتے ہیں : اے ہمارے رب ! ہم تیرے بھیجے ہوئے حق پر ایمان لے آئے ہیں سو تو ہمیں بھی حق کی گواہی دینے والوں کے ساتھ لکھ لے ۔',\n",
              " 'اور ہمیں کیا ہے کہ ہم اللہ پر اور اس حق یعنی حضرت محمد مصطفیٰ صلی اللہ علیہ وآلہ وسلم اور قرآن مجید پر جو ہمارے پاس آیا ہے ، ایمان نہ لائیں حالانکہ ہم بھی یہ طمع رکھتے ہیں کہ ہمارا رب ہمیں نیک لوگوں کے ساتھ اپنی رحمت و جنت میں داخل فرما دے ۔',\n",
              " 'سو اللہ نے ان کی اس مومنانہ بات کے عوض انہیں ثواب میں جنتیں عطا فرما دیں جن کے نیچے نہریں بہہ رہی ہیں ۔ وہ ان میں ہمیشہ رہنے والے ہیں ، اور یہی نیکوکاروں کی جزا ہے ۔',\n",
              " 'اور جن لوگوں نے کفر کیا اور ہماری آیتوں کو جھٹلایا وہی لوگ دوزخ میں رہنے والے ہیں ۔',\n",
              " 'اے ایمان والو ! جو پاکیزہ چیزیں اللہ نے تمہارے لئے حلال کی ہیں انہیں اپنے اوپر حرام مت ٹھہراؤ اور نہ ہی حد سے بڑھو ، بیشک اللہ حد سے تجاوز کرنے والوں کو پسند نہیں فرماتا ۔',\n",
              " 'اور جو حلال پاکیزہ رزق اللہ نے تمہیں عطا فرمایا ہے اس میں سے کھایا کرو اور اللہ سے ڈرتے رہو جس پر تم ایمان رکھتے ہو ۔',\n",
              " 'اللہ تمہاری بے مقصد اور غیر سنجیدہ قَسموں میں تمہاری گرفت نہیں فرماتا لیکن تمہاری ان سنجیدہ قَسموں پر گرفت فرماتا ہے جنہیں تم ارادی طور پر مضبوط کرلو ، اگر تم ایسی قَسم کو توڑ ڈالو تو اس کا کفّارہ دس مسکینوں کو اوسط درجہ کا کھانا کھلانا ہے جو تم اپنے گھر والوں کو کھلاتے ہو یا اسی طرح ان مسکینوں کو کپڑے دینا ہے یا ایک گردن یعنی غلام یا باندی کو آزاد کرنا ہے ، پھر جسے یہ سب کچھ میسر نہ ہو تو تین دن روزہ رکھنا ہے ۔ یہ تمہاری قَسموں کا کفّارہ ہے جب تم کھالو اور پھر توڑ بیٹھو ، اور اپنی قَسموں کی حفاظت کیا کرو ، اسی طرح اللہ تمہارے لئے اپنی آیتیں خوب واضح فرماتا ہے تاکہ تم اس کے احکام کی اطاعت کر کے شکر گزار بن جاؤ ۔',\n",
              " 'اے ایمان والو ! بیشک شراب اور جُوا اور عبادت کے لئے نصب کئے گئے بُت اور قسمت معلوم کرنے کے لئے فال کے تیر سب ناپاک شیطانی کام ہیں ۔ سو تم ان سے کلیتاً پرہیز کرو تاکہ تم فلاح پا جاؤ ۔',\n",
              " 'شیطان یہی چاہتا ہے کہ شراب اور جوئے کے ذریعے تمہارے درمیان عداوت اور کینہ ڈلوا دے اور تمہیں اللہ کے ذکر سے اور نماز سے روک دے ۔ کیا تم ان شرانگیز باتوں سے باز آؤ گے ۔',\n",
              " 'اور تم اللہ کی اطاعت کرو اور رسول صلی اللہ علیہ وآلہ وسلم کی اطاعت کرو اور خدا اور رسول صلی اللہ علیہ وآلہ وسلم کی مخالفت سے بچتے رہو ، پھر اگر تم نے رُوگردانی کی تو جان لو کہ ہمارے رسول صلی اللہ علیہ وآلہ وسلم پر صرف احکام کا واضح طور پر پہنچا دینا ہی ہے اور وہ یہ فریضہ ادا فرما چکے ہیں ۔',\n",
              " 'ان لوگوں پر جو ایمان لائے اور نیک عمل کرتے رہے اس حرام میں کوئی گناہ نہیں جو وہ حکمِ حرمت اترنے سے پہلے کھا پی چکے ہیں جب کہ وہ بقیہ معاملات میں بچتے رہے اور دیگر اَحکامِ اِلٰہی پر ایمان لائے اور اَعمالِ صالحہ پر عمل پیرا رہے ، پھر اَحکامِ حرمت کے آجانے کے بعد بھی ان سب حرام اَشیاء سے پرہیز کرتے رہے اور اُن کی حرمت پر صدقِ دل سے ایمان لائے ، پھر صاحبانِ تقویٰ ہوئے اور بالآخر صاحبانِ اِحسان یعنی اﷲ کے خاص محبوب و مقرب و نیکوکار بندے بن گئے ، اور اﷲ اِحسان والوں سے محبت فرماتا ہے ۔',\n",
              " 'اے ایمان والو ! اللہ کسی قدر ایسے شکار سے تمہیں ضرور آزمائے گا جس تک تمہارے ہاتھ اور تمہارے نیزے پہنچ سکتے ہیں تاکہ اللہ اس شخص کی پہچان کروا دے جو اس سے غائبانہ ڈرتا ہے پھر جو شخص اس کے بعد بھی حد سے تجاوز کر جائے تو اس کے لئے دردناک عذاب ہے ۔',\n",
              " 'اے ایمان والو ! تم احرام کی حالت میں شکار کو مت مارا کرو ، اور تم میں سے جس نے بحالتِ احرام قصداً اسے مار ڈالا تو اس کا بدلہ مویشیوں میں سے اسی کے برابر کوئی جانور ہے جسے اس نے قتل کیا ہے جس کی نسبت تم میں سے دو عادل شخص فیصلہ کریں کہ واقعی یہ جانور اس شکار کے برابر ہے بشرطیکہ وہ قربانی کعبہ پہنچنے والی ہو یا اس کا کفّارہ چند محتاجوں کا کھانا ہے یعنی جانور کی قیمت کے برابر معمول کا کھانا جتنے بھی محتاجوں کو پورا آجائے یا اس کے برابر یعنی جتنے محتاجوں کا کھانا بنے اس قدر روزے ہیں تاکہ وہ اپنے کیے کے بوجھ کا مزہ چکھے ۔ جو کچھ اس سے پہلے ہو گزرا اللہ نے اسے معاف فرما دیا ، اور جو کوئی ایسا کام دوبارہ کرے گا تو اللہ اس سے نافرمانی کا بدلہ لے لے گا ، اور اللہ بڑا غالب بدلہ لینے والا ہے ۔',\n",
              " 'تمہارے لئے دریا کا شکار اور اس کا کھانا تمہارے اور مسافروں کے فائدے کی خاطر حلال کر دیا گیا ہے ، اور خشکی کا شکار تم پر حرام کیا گیا ہے جب تک کہ تم حالتِ احرام میں ہو ، اور اللہ سے ڈرتے رہو جس کی بارگاہ کی طرف تم سب جمع کئے جاؤ گے ۔',\n",
              " 'اللہ نے عزت و ادب والے گھر کعبہ کو لوگوں کے دینی و دنیوی امور میں قیام امن کا باعث بنا دیا ہے اور حرمت والے مہینے کو اور کعبہ کی قربانی کو اور گلے میں علامتی پٹے والے جانوروں کو بھی جو حرمِ مکہ میں لائے گئے ہوں سب کو اسی نسبت سے عزت و احترام عطا کر دیا گیا ہے ، یہ اس لئے کہ تمہیں علم ہو جائے کہ جو کچھ آسمانوں میں ہے اور جو کچھ زمین میں ہے اللہ خوب جانتا ہے اور اللہ ہر چیز سے بہت واقف ہے ۔',\n",
              " 'جان لو کہ اللہ سخت گرفت والا ہے اور یہ کہ اللہ بڑا بخشنے والا بہت رحم فرمانے والا بھی ہے ۔',\n",
              " 'رسول صلی اللہ علیہ وآلہ وسلم پر احکام کاملاً پہنچا دینے کے سوا کوئی اور ذمہ داری نہیں ، اور اللہ وہ سب کچھ جانتا ہے جو تم ظاہر کرتے ہو اور جو تم چھپاتے ہو ۔',\n",
              " 'فرما دیجئے : پاک اور ناپاک دونوں برابر نہیں ہو سکتے اے مخاطب ! اگرچہ تمہیں ناپاک چیزوں کی کثرت بھلی لگے ۔ پس اے عقلمند لوگو ! تم کثرت و قلت کا فرق دیکھنے کی بجائے اللہ سے ڈرا کرو تاکہ تم فلاح پا جاؤ ۔',\n",
              " 'اے ایمان والو ! تم ایسی چیزوں کی نسبت سوال مت کیا کرو جن پر قرآن خاموش ہو کہ اگر وہ تمہارے لئے ظاہر کر دی جائیں تو تمہیں مشقت میں ڈال دیں اور تمہیں بری لگیں ، اور اگر تم ان کے بارے میں اس وقت سوال کرو گے جبکہ قرآن نازل کیا جا رہا ہے تو وہ تم پر نزولِ حکم کے ذریعے ظاہر یعنی متعیّن کر دی جائیں گی جس سے تمہاری صواب دید ختم ہو جائے گی اور تم ایک ہی حکم کے پابند ہو جاؤ گے ۔ اللہ نے ان باتوں اور سوالوں سے اب تک درگزر فرمایا ہے ، اور اللہ بڑا بخشنے والا بردبار ہے ۔',\n",
              " 'بیشک تم سے پہلے ایک قوم نے ایسی ہی باتیں پوچھی تھیں ، جب وہ بیان کر دی گئیں پھر وہ ان کے منکر ہوگئے ۔',\n",
              " 'اللہ نے نہ تو بحیرہ کو اَمرِ شرعی مقرر کیا ہے اور نہ سائبہ کو اور نہ وصیلہ کو اور نہ حام کو ، لیکن کافر لوگ اللہ پر جھوٹا بہتان باندھتے ہیں ، اور ان میں سے اکثر عقل نہیں رکھتے ۔',\n",
              " 'اور جب ان سے کہا جاتا ہے کہ اس قرآن کی طرف جسے اللہ نے نازل فرمایا ہے اور رسولِ مکرّم صلی اللہ علیہ وآلہ وسلم کی طرف رجوع کرو تو کہتے ہیں : ہمیں وہی طریقہ کافی ہے جس پر ہم نے اپنے باپ دادا کو پایا ۔ اگرچہ ان کے باپ دادا نہ کچھ دین کا علم رکھتے ہوں اور نہ ہی ہدایت یافتہ ہوں ۔',\n",
              " 'اے ایمان والو ! تم اپنی جانوں کی فکر کرو ، تمہیں کوئی گمراہ نقصان نہیں پہنچا سکتا اگر تم ہدایت یافتہ ہو چکے ہو ، تم سب کو اللہ ہی کی طرف پلٹنا ہے ، پھر وہ تمہیں ان کاموں سے خبردار فرما دے گا جو تم کرتے رہے تھے ۔',\n",
              " 'اے ایمان والو ! جب تم میں سے کسی کی موت آئے تو وصیت کرتے وقت تمہارے درمیان گواہی کے لئے تم میں سے دو عادل شخص ہوں یا تمہارے غیروں میں سے کوئی دوسرے دو شخص ہوں اگر تم ملک میں سفر کر رہے ہو پھر اسی حال میں تمہیں موت کی مصیبت آپہنچے تو تم ان دونوں کو نماز کے بعد روک لو ، اگر تمہیں ان پر شک گزرے تو وہ دونوں اللہ کی قَسمیں کھائیں کہ ہم اس کے عوض کوئی قیمت حاصل نہیں کریں گے خواہ کوئی کتنا ہی قرابت دار ہو اور نہ ہم اللہ کی مقرر کردہ گواہی کو چھپائیں گے اگر چھپائیں تو ہم اسی وقت گناہگاروں میں ہو جائیں گے ۔',\n",
              " 'پھر اگر اس بات کی اطلاع ہو جائے کہ وہ دونوں صحیح گواہی چھپانے کے باعث گناہ کے سزاوار ہو گئے ہیں تو ان کی جگہ دو اور گواہ ان لوگوں میں سے کھڑے ہو جائیں جن کا حق پہلے دو گواہوں نے دبایا ہے وہ میت کے زیادہ قرابت دار ہوں پھر وہ اللہ کی قَسم کھائیں کہ بیشک ہماری گواہی ان دونوں کی گواہی سے زیادہ سچی ہے اور ہم حق سے تجاوز نہیں کر رہے ، اگر ایسا کریں تو ہم اسی وقت ظالموں میں سے ہو جائیں گے ۔',\n",
              " 'یہ طریقہ اس بات سے قریب تر ہے کہ لوگ صحیح طور پر گواہی ادا کریں یا اس بات سے خوفزدہ ہوں کہ غلط گواہی کی صورت میں ان کی قََسموں کے بعد وہی قَسمیں زیادہ قریبی ورثاء کی طرف لوٹائی جائیں گی ، اور اللہ سے ڈرتے رہو اور اس کے احکام کو غور سے سنا کرو ، اور اللہ نافرمان قوم کو ہدایت نہیں دیتا ۔',\n",
              " 'اس دن سے ڈرو جس دن اللہ تمام رسولوں کوجمع فرمائے گا پھر ان سے فرمائے گا کہ تمہیں تمہاری امتوں کی طرف سے دعوتِ دین کا کیا جواب دیا گیا تھا ؟ وہ حضورِ الٰہی میں عرض کریں گے : ہمیں کچھ علم نہیں ، بیشک تو ہی غیب کی سب باتوں کا خوب جاننے والا ہے ۔',\n",
              " 'جب اللہ فرمائے گا : اے عیسٰی ابن مریم ! تم اپنے اوپر اور اپنی والدہ پر میرا احسان یاد کرو جب میں نے پاک روح جبرائیل کے ذریعے تمہیں تقویت بخشی ، تم گہوارے میں بعہدِ طفولیت اور پختہ عمری میں بعہدِ تبلیغ و رسالت یکساں انداز سے لوگوں سے گفتگو کرتے تھے ، اور جب میں نے تمہیں کتاب اور حکمت و دانائی اور تورات اور انجیل سکھائی ، اور جب تم میرے حکم سے مٹی کے گارے سے پرندے کی شکل کی مانند مورتی بناتے تھے پھر تم اس میں پھونک مارتے تھے تو وہ مورتی میرے حکم سے پرندہ بن جاتی تھی ، اور جب تم مادر زاد اندھوں اور کوڑھیوں یعنی برص زدہ مریضوں کو میرے حکم سے اچھا کر دیتے تھے ، اور جب تم میرے حکم سے مُردوں کو زندہ کر کے قبر سے نکال کھڑا کر دیتے تھے ، اور جب میں نے بنی اسرائیل کو تمہارے قتل سے روک دیا تھا جب کہ تم ان کے پاس واضح نشانیاں لے کر آئے تو ان میں سے کافروں نے یہ کہہ دیا کہ یہ تو کھلے جادو کے سوا کچھ نہیں ۔',\n",
              " 'اور جب میں نے حواریوں کے دل میں یہ ڈال دیا کہ تم مجھ پر اور میرے پیغمبر عیسٰی علیہ السلام پر ایمان لاؤ ، تو انہوں نے کہا : ہم ایمان لے آئے اور تو گواہ ہو جا کہ ہم یقیناً مسلمان ہیں ۔',\n",
              " 'اور یہ بھی یاد کرو جب حواریوں نے کہا : اے عیسٰی ابن مریم ! کیا تمہارا رب ایسا کر سکتا ہے کہ ہم پر آسمان سے کھانے کا خوان اتار دے ، تو عیسٰی علیہ السلام نے جواباً کہا : لوگو ! اللہ سے ڈرو اگر تم صاحبِ ایمان ہو ۔',\n",
              " 'وہ کہنے لگے : ہم تو صرف یہ چاہتے ہیں کہ اس میں سے کھائیں اور ہمارے دل مطمئن ہو جائیں اور ہم مزید یقین سے جان لیں کہ آپ نے ہم سے سچ کہا ہے اور ہم اس خوانِ نعمت کے اترنے پر گواہ ہو جائیں ۔',\n",
              " 'عیسٰی ابن مریم علیہ السلام نے عرض کیا : اے اﷲ ! اے ہمارے رب ! ہم پر آسمان سے خوانِ نعمت نازل فرما دے کہ اس کے اترنے کا دن ہمارے لئے عید ہوجائے ہمار ے اگلوں کے لئے بھی اور ہمارے پچھلوں کے لئے بھی اور وہ خوان تیری طرف سے نشانی ہو ، اور ہمیں رزق عطا کر اور تو سب سے بہتر رزق دینے والا ہے ۔',\n",
              " 'اﷲ نے فرمایا : بیشک میں اسے تم پر نازل فرماتا ہوں ، پھر تم میں سے جو شخص اس کے بعد کفر کرے گا تو یقیناً میں اسے ایسا عذاب دوں گا کہ تمام جہان والوں میں سے کسی کو بھی ایسا عذاب نہ دوں گا ۔',\n",
              " 'اور جب اﷲ فرمائے گا : اے عیسٰی ابن مریم ! کیا تم نے لوگوں سے کہا تھا کہ تم مجھ کو اور میری ماں کو اﷲ کے سوا دو معبود بنا لو ، وہ عرض کریں گے : تو پاک ہے ، میرے لئے یہ روا نہیں کہ میں ایسی بات کہوں جس کا مجھے کوئی حق نہیں ۔ اگر میں نے یہ بات کہی ہوتی تو یقیناً تو اسے جانتا ، تو ہر اس بات کو جانتا ہے جو میرے دل میں ہے اور میں ان باتوں کو نہیں جانتا جو تیرے علم میں ہیں ۔ بیشک تو ہی غیب کی سب باتوں کو خوب جاننے والا ہے ۔',\n",
              " 'میں نے انہیں سوائے اس بات کے کچھ نہیں کہا تھا جس کا تو نے مجھے حکم دیا تھا کہ تم صرف اﷲ کی عبادت کیا کرو جو میرا بھی رب ہے اور تمہارا بھی رب ہے ، اور میں ان کے عقائد و اعمال پر اس وقت تک خبردار رہا جب تک میں ان لوگوں میں موجود رہا ، پھر جب تو نے مجھے اٹھا لیا تو تو ہی ان کے حالات پر نگہبان تھا ، اور تو ہر چیز پر گواہ ہے ۔',\n",
              " 'اگر توانہیں عذاب دے تو وہ تیرے ہی بندے ہیں اور اگر تو انہیں بخش دے تو بیشک تو ہی بڑا غالب حکمت والا ہے ۔',\n",
              " 'اللہ فرمائے گا : یہ ایسا دن ہے جس میں سچے لوگوں کو ان کا سچ فائدہ دے گا ، ان کے لئے جنتیں ہیں جن کے نیچے نہریں جاری ہیں ، وہ ان میں ہمیشہ ہمیشہ رہنے والے ہیں ۔ اﷲ ان سے راضی ہوگیا اور وہ اس سے راضی ہوگئے ، یہی رضائے الٰہی سب سے بڑی کامیابی ہے ۔',\n",
              " 'تمام آسمانوں اور زمین کی اور جو کچھ ان میں ہے سب کی بادشاہی اﷲ ہی کے لئے ہے ، اور وہ ہر چیز پر بڑا قادر ہے ۔',\n",
              " 'تمام تعریفیں اﷲ ہی کے لئے ہیں جس نے آسمانوں اور زمین کو پیدا فرمایا اور تاریکیوں اور روشنی کو بنایا ، پھر بھی کافر لوگ معبودانِ باطلہ کو اپنے رب کے برابر ٹھہراتے ہیں ۔',\n",
              " 'اﷲ وہی ہے جس نے تمہیں مٹی کے گارے سے پیدا فرمایا یعنی کرّۂ اَرضی پر حیاتِ انسانی کی کیمیائی ابتداء اس سے کی ۔ پھر اس نے تمہاری موت کی میعاد مقرر فرما دی ، اور انعقادِ قیامت کا معیّنہ وقت اسی کے پاس مقرر ہے پھر بھی تم شک کرتے ہو ۔',\n",
              " 'اور آسمانوں میں اور زمین میں وہی اﷲ ہی معبودِ برحق ہے ، جو تمہاری پوشیدہ اور تمہاری ظاہر سب باتوں کو جانتا ہے اور جو کچھ تم کما رہے ہو وہ اسے بھی جانتا ہے ۔',\n",
              " 'اور ان کے رب کی نشانیوں میں سے ان کے پاس کوئی نشانی نہیں آتی مگر یہ کہ وہ اس سے روگردانی کرتے ہیں ۔',\n",
              " 'پھر بیشک انہوں نے اسی طرح حق یعنی قرآن کو بھی جھٹلا دیا جب وہ ان کے پاس اُلوہی نشانی کے طور پر آیا ، پس عنقریب ان کے پاس اس کی خبریں آیا چاہتی ہیں جس کا وہ مذاق اڑاتے تھے ۔',\n",
              " 'کیا انہوں نے نہیں دیکھا کہ ہم نے ان سے پہلے کتنی ہی قوموں کو ہلاک کردیا جنہیں ہم نے زمین میں ایسا مستحکم اقتدار دیا تھا کہ ایسا اقتدار اور جماؤ تمہیں بھی نہیں دیا اور ہم نے ان پر لگا تار برسنے والی بارش بھیجی اور ہم نے ان کے مکانات و محلّات کے نیچے سے نہریں بہائیں پھر اتنی پُرعشرت زندگی دینے کے باوجود ہم نے ان کے گناہوں کے باعث انہیں ہلاک کردیا اور ان کے بعد ہم نے دوسری اُمتوں کو پیدا کیا ۔',\n",
              " 'اور ہم اگر آپ پر کاغذ پہ لکھی ہوئی کتاب نازل فرما دیتے پھر یہ لوگ اسے اپنے ہاتھوں سے چھو بھی لیتے تب بھی کافر لوگ یہی کہتے کہ یہ صریح جادو کے سوا کچھ نہیں ۔',\n",
              " 'اور وہ کفّار کہتے ہیں کہ اس رسولِ مکرّم پر کوئی فرشتہ کیوں نہ اتارا گیا جسے ہم ظاہراً دیکھ سکتے اور وہ ان کی تصدیق کردیتا ، اور ہم اگر فرشتہ اتار دیتے تو ان کا کام ہی تمام ہوچکا ہوتا پھر انہیں ذرا بھی مہلت نہ دی جاتی ۔',\n",
              " 'اور اگر ہم رسول کو فرشتہ بناتے تو اسے بھی آدمی ہی کی صورت بناتے اور ہم ان پر تب بھی وہی شبہ وارد کردیتے جو شبہ و التباس وہ اب کر رہے ہیں یعنی اس کی بھی ظاہری صورت دیکھ کر کہتے کہ یہ ہماری مثل بشر ہے ۔',\n",
              " 'اور بیشک آپ سے پہلے بھی رسولوں کے ساتھ مذاق کیا جاتا رہا ، پھر ان میں سے مسخرہ پن کرنے والوں کو حق کے اسی عذاب نے آگھیرا جس کا وہ مذاق اڑاتے تھے ۔',\n",
              " 'فرمادیجئے کہ تم زمین پر چلو پھرو ، پھر نگاہِ عبرت سے دیکھو کہ حق کو جھٹلانے والوں کا انجام کیسا ہوا ۔',\n",
              " 'آپ ان سے سوال فرمائیں کہ آسمانوں اور زمین میں جو کچھ ہے کس کا ہے ؟ پھر یہ بھی فرما دیں کہ اﷲ ہی کا ہے ، اس نے اپنی ذات کے ذمہ کرم پر رحمت لازم فرمالی ہے ، وہ تمہیں روزِ قیامت جس میں کوئی شک نہیں ضرور جمع فرمائے گا ، جنہوں نے اپنی جانوں کو دائمی خسارے میں ڈال دیا ہے سو وہ ایمان نہیں لائیں گے ۔',\n",
              " 'اور وہ ساری مخلوق جو رات میں اور دن میں آرام کرتی ہے ، اسی کی ہے ، اور وہ خوب سننے والا جاننے والا ہے ۔',\n",
              " 'فرما دیجئے : کیا میں کسی دوسرے کو عبادت کے لئے اپنا دوست بنا لوں اس اﷲ کے سوا جو آسمانوں اور زمین کا پیدا کرنے والا ہے اور وہ سب کو کھلاتا ہے اور خود اسے کھلایا نہیں جاتا ۔ فرما دیں : مجھے حکم دیا گیا ہے کہ میں اس کے حضور سب سے پہلا سرجھکانے والا مسلمان ہوجاؤں اور یہ بھی فرمادیا گیا ہے کہ تم مشرکوں میں سے ہرگز نہ ہوجانا ۔',\n",
              " 'فرما دیجئے کہ بیشک میں تو بڑے عذاب کے دن سے ڈرتا ہوں ، اگر میں اپنے رب کی نافرمانی کروں سو یہ کیسے ممکن ہے ؟ ۔',\n",
              " 'اس دن جس شخص سے وہ عذاب پھیر دیا گیا تو بیشک اﷲ نے اس پر رحم فرمایا ، اور یہی اُخروی بخشش کھلی کامیابی ہے ۔',\n",
              " 'اور اگر اﷲ تجھے کوئی تکلیف پہنچائے تو اس کے سوا اسے کوئی دور کرنے والا نہیں ، اور اگر وہ تجھے کوئی بھلائی پہنچائے تو وہ ہر چیز پر خوب قادر ہے ۔',\n",
              " 'اور وہی اپنے بندوں پر غالب ہے ، اور وہ بڑی حکمت والا خبردار ہے ۔',\n",
              " 'آپ ان سے دریافت فرمائیے کہ گواہی دینے میں سب سے بڑھ کر کون ہے ؟ آپ ہی فرما دیجئے کہ اﷲ میرے اور تمہارے درمیان گواہ ہے ، اور میری طرف یہ قرآن اس لئے وحی کیا گیا ہے کہ اس کے ذریعے تمہیں اور ہر اس شخص کو جس تک یہ قرآن پہنچے ڈر سناؤں ۔ کیا تم واقعی اس بات کی گواہی دیتے ہو کہ اﷲ کے ساتھ دوسرے معبود بھی ہیں ؟ آپ فرما دیں : میں تو اس غلط بات کی گواہی نہیں دیتا ، فرما دیجئے : بس معبود تو وہی ایک ہی ہے اور میں ان سب چیزوں سے بیزار ہوں جنہیں تم اﷲ کا شریک ٹھہراتے ہو ۔',\n",
              " 'وہ لوگ جنہیں ہم نے کتاب دی تھی اس نبئ آخر الزماں صلی اللہ علیہ وآلہ وسلم کو ویسے ہی پہچانتے ہیں جیسے اپنے بیٹوں کو پہچانتے ہیں ، جنہوں نے اپنی جانوں کو دائمی خسارے میں ڈال دیا ہے سو وہ ایمان نہیں لائیں گے ۔',\n",
              " 'اور اس سے بڑا ظالم کون ہوسکتا ہے جس نے اﷲ پر جھوٹا بہتان باندھا یا اس نے اس کی آیتوں کو جھٹلایا ؟ بیشک ظالم لوگ فلاح نہیں پائیں گے ۔',\n",
              " 'اور جس دن ہم سب کو جمع کریں گے پھر ہم ان لوگوں سے کہیں گے جو شرک کرتے تھے : تمہارے وہ شریک کہاں ہیں جنہیں تم معبود خیال کرتے تھے ۔',\n",
              " 'پھر ان کی کوئی معذرت نہ رہے گی بجز اس کے کہ وہ کہیں گے : ہمیں اپنے رب اﷲ کی قَسم ہے ! ہم مشرک نہ تھے ۔',\n",
              " 'دیکھئے انہوں نے خود اپنے اوپر کیسا جھوٹ بولا اور جو بہتان وہ دنیا میں تراشا کرتے تھے وہ ان سے غائب ہوگیا ۔',\n",
              " 'اور ان میں کچھ وہ بھی ہیں جو آپ کی طرف کان لگائے رہتے ہیں اور ہم نے ان کے دلوں پر ان کی اپنی بدنیتی کے باعث پردے ڈال دیئے ہیں سو اب ان کے لئے ممکن نہیں کہ وہ اس قرآن کو سمجھ سکیں اور ہم نے ان کے کانوں میں ڈاٹ دے دی ہے ، اور اگر وہ تمام نشانیوں کو کھلا بھی دیکھ لیں تو بھی اس پر ایمان نہیں لائیں گے ۔ حتیٰ کہ جب آپ کے پاس آتے ہیں ، آپ سے جھگڑا کرتے ہیں اس وقت کافر لوگ کہتے ہیں کہ یہ قرآن پہلے لوگوں کی جھوٹی کہانیوں کے سوا کچھ نہیں ۔',\n",
              " 'اور وہ دوسروں کو اس نبی کی اتباع اور قرآن سے روکتے ہیں اور خود بھی اس سے دور بھاگتے ہیں ، اور وہ محض اپنی ہی جانوں کو ہلاک کررہے ہیں اور وہ اس ہلاکت کا شعور بھی نہیں رکھتے ۔',\n",
              " 'اگر آپ انہیں اس وقت دیکھیں جب وہ آگ کے کنارے پر کھڑے کئے جائیں گے تو کہیں گے : اے کاش ! ہم دنیا میں پلٹا دیئے جائیں تو اب ہم اپنے رب کی آیتوں کو کبھی نہیں جھٹلائیں گے اور ایمان والوں میں سے ہو جائیں گے ۔',\n",
              " 'اس اقرار میں کوئی سچائی نہیں بلکہ ان پر وہ سب کچھ ظاہر ہوگیا ہے جو وہ پہلے چھپایا کرتے تھے ، اور اگر وہ دنیا میں لوٹا بھی دیئے جائیں تو پھر وہی دہرائیں گے جس سے وہ روکے گئے تھے اور بیشک وہ پکے جھوٹے ہیں ۔',\n",
              " 'اور وہ یہی کہتے رہیں گے جیسے انہوں نے پہلے کہا تھا کہ ہماری اس دنیوی زندگی کے سوا اور کوئی زندگی نہیں اور ہم مرنے کے بعد نہیں اٹھائے جائیں گے ۔',\n",
              " 'اور اگر آپ انہیں اس وقت دیکھیں جب وہ اپنے رب کے حضور کھڑے کئے جائیں گے ، اور انہیں اﷲ فرمائے گا : کیا یہ زندگی حق نہیں ہے ؟ تو کہیں گے : کیوں نہیں ! ہمارے رب کی قسم یہ حق ہے ، پھر اﷲ فرمائے گا : پس اب تم عذاب کا مزہ چکھو اس وجہ سے کہ تم کفر کیا کرتے تھے ۔',\n",
              " 'پس ایسے لوگ نقصان میں رہے جنہوں نے اﷲ کی ملاقات کو جھٹلا دیا یہاں تک کہ جب ان کے پاس اچانک قیامت آپہنچے گی تو کہیں گے : ہائے افسوس ! ہم پر جو ہم نے اس قیامت پر ایمان لانے کے بارے میں تقصیر کی ، اور وہ اپنی پیٹھوں پر اپنے گناہوں کے بوجھ لادے ہوئے ہوں گے ، سن لو ! وہ بہت برا بوجھ ہے جو یہ اٹھا رہے ہیں ۔',\n",
              " 'اور دنیوی زندگی کی عیش و عشرت کھیل اور تماشے کے سوا کچھ نہیں ، اور یقیناً آخرت کا گھر ہی ان لوگوں کے لئے بہتر ہے جو تقویٰ اختیار کرتے ہیں ، کیا تم یہ حقیقت نہیں سمجھتے ۔',\n",
              " 'اے حبیب ! بیشک ہم جانتے ہیں کہ وہ بات یقیناً آپ کو رنجیدہ کررہی ہے کہ جو یہ لوگ کہتے ہیں ، پس یہ آپ کو نہیں جھٹلا رہے لیکن حقیقت یہ ہے کہ ظالم لوگ اﷲ کی آیتوں سے ہی انکار کررہے ہیں ۔',\n",
              " 'اور بیشک آپ سے قبل بھی بہت سے رسول جھٹلائے گئے مگر انہوں نے جھٹلائے جانے اور اذیت پہنچائے جانے پر صبر کیا حتٰی کہ انہیں ہماری مدد آپہنچی ، اور اﷲ کی باتوں یعنی وعدوں کو کوئی بدلنے والا نہیں ، اور بیشک آپ کے پاس تسکینِ قلب کے لیے رسولوں کی خبریں آچکی ہیں ۔',\n",
              " 'اور اگر آپ پر ان کی رُوگردانی شاق گزر رہی ہے اور آپ بہر صورت ان کے ایمان لانے کے خواہش مند ہیں تو اگر آپ سے یہ ہو سکے کہ زمین میں اترنے والی کوئی سرنگ یا آسمان میں چڑھنے والی کوئی سیڑھی تلاش کرلیں پھر انہیں دکھانے کے لیے ان کے پاس کوئی خاص نشانی لے آئیں وہ تب بھی ایمان نہیں لائیں گے ، اور اگر اﷲ چاہتا تو ان کو ہدایت پر ضرور جمع فرما دیتا پس آپ اپنی رحمت و شفقت کے بے پایاں جوش کے باعث ان کی بدبختی سے بے خبر نہ ہوجائیں ۔',\n",
              " 'بات یہ ہے کہ دعوتِ حق صرف وہی لوگ قبول کرتے ہیں جو اسے سچے دل سے سنتے ہیں ، اور مُردوں یعنی حق کے منکروں کو اﷲ حالتِ کفر میں ہی قبروں سے اٹھائے گا پھر وہ اسی رب کی طرف جس کا انکار کرتے تھے لوٹائے جائیں گے ۔',\n",
              " 'اور انہوں نے کہا کہ اس رسول صلی اللہ علیہ وآلہ وسلم پراس کے رب کی طرف سے ہروقت ساتھ رہنے والی کوئی نشانی کیوں نہیں اتاری گئی ؟ فرما دیجئے : بیشک اﷲ اس بات پر بھی قادر ہے کہ وہ ایسی کوئی نشانی اتار دے لیکن ان میں سے اکثر لوگ اس کی حکمتوں کو نہیں جانتے ۔',\n",
              " 'اور اے انسانو ! کوئی بھی چلنے پھرنے والا جانور اور پرندہ جو اپنے دو بازوؤں سے اڑتا ہو ایسا نہیں ہے مگر یہ کہ بہت سی صفات میں وہ سب تمہارے ہی مماثل طبقات ہیں ، ہم نے کتاب میں کوئی چیز نہیں چھوڑی جسے صراحۃً یا اشارۃً بیان نہ کردیا ہو پھر سب لوگ اپنے رب کے پاس جمع کئے جائیں گے ۔',\n",
              " 'اور جن لوگوں نے ہماری آیتوں کو جھٹلایا وہ بہرے اور گونگے ہیں ، تاریکیوں میں بھٹک رہے ہیں ۔ اﷲ جسے چاہتا ہے اسے انکارِ حق اور ضد کے باعث گمراہ کردیتا ہے ، اور جسے چاہتا ہے اسے قبولِ حق کے باعث سیدھی راہ پر لگا دیتا ہے ۔',\n",
              " 'آپ ان کافروں سے فرمائیے : ذرا یہ تو بتاؤ اگر تم پر اﷲ کا عذاب آجائے یا تم پر قیامت آپہنچے تو کیا اس وقت عذاب سے بچنے کے لیے اﷲ کے سوا کسی اور کو پکارو گے ؟ بتاؤ اگر تم سچے ہو ۔',\n",
              " 'ایسا ہرگز ممکن نہیں بلکہ تم اب بھی اسی اﷲ کو ہی پکارتے ہو پھر اگر وہ چاہے تو ان مصیبتوں کو دور فرما دیتا ہے جن کے لئے تم اسے پکارتے ہو اور اس وقت تم ان بتوں کو بھول جاتے ہو جنہیں اﷲ کا شریک ٹھہراتے ہو ۔',\n",
              " 'اور بیشک ہم نے آپ سے پہلے بہت سی اُمتوں کی طرف رسول بھیجے ، پھر ہم نے ان کو نافرمانی کے باعث تنگ دستی اور تکلیف کے ذریعے پکڑ لیا تاکہ وہ عجز و نیاز کے ساتھ گِڑگڑائیں ۔',\n",
              " 'پھر جب ان تک ہمارا عذاب آپہنچا تو انہوں نے عاجزی و زاری کیوں نہ کی ؟ لیکن حقیقت یہ ہے کہ ان کے دل سخت ہوگئے تھے اور شیطان نے ان کے لئے وہ گناہ آراستہ کر دکھائے تھے جو وہ کیا کرتے تھے ۔',\n",
              " 'پھر جب انہوں نے اس نصیحت کو فراموش کردیا جو ان سے کی گئی تھی تو ہم نے انہیں اپنے انجام تک پہنچانے کے لیے ان پر ہر چیز کی فراوانی کے دروازے کھول دیئے ، یہاں تک کہ جب وہ ان چیزوں کی لذتوں اور راحتوں سے خوب خوش ہو کر مدہوش ہو گئے جو انہیں دی گئی تھیں تو ہم نے اچانک انہیں عذاب میں پکڑ لیا تو اس وقت وہ مایوس ہوکر رہ گئے ۔',\n",
              " 'پس ظلم کرنے والی قوم کی جڑ کاٹ دی گئی ، اور تمام تعریفیں اﷲ ہی کے لئے ہیں جو سارے جہانوں کا پروردگار ہے ۔',\n",
              " 'ان سے فرما دیجئے کہ تم یہ تو بتاؤ اگر اﷲ تمہاری سماعت اور تمہاری آنکھیں لے لے اور تمہارے دلوں پر مُہر لگا دے تو اﷲ کے سوا کون معبود ایسا ہے جو یہ نعمتیں دوبارہ تمہارے پاس لے آئے ؟ دیکھئے ہم کس طرح گونا گوں آیتیں بیان کرتے ہیں پھر بھی وہ روگردانی کئے جاتے ہیں ۔',\n",
              " 'آپ ان سے یہ بھی فرما دیجئے کہ تم مجھے بتاؤ اگر تم پر اﷲ کا عذاب اچانک یا کھلم کھلا آن پڑے تو کیا ظالم قوم کے سوا کوئی اور ہلاک کیا جائے گا ۔',\n",
              " 'اور ہم پیغمبروں کو نہیں بھیجتے مگر خوشخبری سنانے والے اور ڈر سنانے والے بنا کر ، سو جو شخص ایمان لے آیا اور عملاً درست ہوگیا تو ان پرنہ کوئی خوف ہوگا اور نہ ہی وہ غمگین ہوں گے ۔',\n",
              " 'اور جن لوگوں نے ہماری آیتوں کو جھٹلایا انہیں عذاب چھو کر رہے گا ، اس وجہ سے کہ وہ نافرمانی کیا کرتے تھے ۔',\n",
              " 'آپ ان کافروں سے فرما دیجئے کہ میں تم سے یہ نہیں کہتا کہ میرے پاس اﷲ کے خزانے ہیں اور نہ میں اَز خود غیب جانتا ہوں اور نہ میں تم سے یہ کہتا ہوں کہ میں فرشتہ ہوں ، میں تو صرف اسی حکم کی پیروی کرتا ہوں جو میری طرف وحی کیا جاتاہے ۔ فرما دیجئے : کیا اندھا اور بینا برابر ہوسکتے ہیں ؟ سو کیا تم غور نہیں کرتے ۔',\n",
              " 'اور آپ اس قرآن کے ذریعے ان لوگوں کو ڈر سنائیے جو اپنے رب کے پاس اس حال میں جمع کئے جانے سے خوف زدہ ہیں کہ ان کے لئے اس کے سوا نہ کوئی مددگار ہو اور نہ کوئی سفارشی تاکہ وہ پرہیزگار بن جائیں ۔',\n",
              " 'اور آپ ان شکستہ دل اور خستہ حال لوگوں کو اپنی صحبت و قربت سے دور نہ کیجئے جو صبح و شام اپنے رب کو صرف اس کی رضا چاہتے ہوئے پکارتے رہتے ہیں ، ان کے عمل و جزا کے حساب میں سے آپ پر کوئی چیز واجب نہیں اور نہ آپ کے حساب میں سے کوئی چیز ان پر واجب ہے اگر پھر بھی آپ انہیں اپنے لطف و کرم سے دور کردیں تو آپ حق تلفی کرنے والوں میں سے ہوجائیں گے جوآپ کے شایانِ شان نہیں ۔',\n",
              " 'اور اسی طرح ہم ان میں سے بعض کو بعض کے ذریعے آزماتے ہیں تاکہ وہ دولت مند کافر غریب مسلمانوں کو دیکھ کر استہزاءً یہ کہیں : کیا ہم میں سے یہی وہ لوگ ہیں جن پر اﷲ نے احسان کیا ہے ؟ کیا اﷲ شکر گزاروں کو خوب جاننے والا نہیں ہے ۔',\n",
              " 'اور جب آپ کے پاس وہ لوگ آئیں جو ہماری آیتوں پرایمان رکھتے ہیں تو آپ ان سے شفقتًا فرمائیں کہ تم پر سلام ہو تمہارے رب نے اپنی ذات کے ذمّہ کرم پر رحمت لازم کرلی ہے ، سو تم میں سے جو شخص نادانی سے کوئی برائی کر بیٹھے پھر اس کے بعد توبہ کرلے اور اپنی اصلاح کر لے تو بیشک وہ بڑا بخشنے والا بہت رحم فرمانے والا ہے ۔',\n",
              " 'اور اسی طرح ہم آیتوں کو تفصیلاً بیان کرتے ہیں اور یہ اس لئے کہ مجرموں کا راستہ سب پر ظاہر ہوجائے ۔',\n",
              " 'فرمادیجئے کہ مجھے اس بات سے روک دیا گیا ہے کہ میں ان جھوٹے معبودوں کی عبادت کروں جن کی تم اﷲ کے سوا پرستش کرتے ہو ۔ فرما دیجئے کہ میں تمہاری خواہشات کی پیروی نہیں کرسکتا اگر ایسے ہو تو میں یقیناً بہک جاؤں اور میں ہدایت یافتہ لوگوں سے بھی نہ رہوں جو کہ ناممکن ہے ۔',\n",
              " 'فرما دیجئے : کافرو ! بیشک میں اپنے رب کی طرف سے روشن دلیل پر قائم ہوں اور تم اسے جھٹلاتے ہو ۔ میرے پاس وہ عذاب نہیں ہے جس کی تم جلدی مچا رہے ہو ۔ حکم صرف اللہ ہی کا ہے ۔ وہ حق بیان فرماتا ہے اور وہی بہتر فیصلہ فرمانے والاہے ۔',\n",
              " 'ان سے فرما دیں : اگر وہ عذاب میرے پاس ہوتا جسے تم جلدی چاہتے ہو تو یقیناً میر ے اور تمہارے درمیان کام تمام ہوچکا ہوتا ۔ اور اﷲ ظالموں کو خوب جاننے والا ہے ۔',\n",
              " 'اور غیب کی کُنجیاں یعنی وہ راستے جن سے غیب کسی پر آشکار کیا جاتا ہے اسی کے پاس اس کی قدرت و ملکیت میں ہیں ، انہیں اس کے سوا اَز خود کوئی نہیں جانتا ، اور وہ ہر اس چیز کو بلاواسطہ جانتا ہے جو خشکی میں اور دریاؤں میں ہے ، اور کوئی پتّا نہیں گرتا مگر یہ کہ وہ اسے جانتا ہے اور نہ زمین کی تاریکیوں میں کوئی ایسا دانہ ہے اور نہ کوئی تر چیز ہے اور نہ کوئی خشک چیز مگر روشن کتاب میں سب کچھ لکھ دیا گیا ہے ۔',\n",
              " 'اور وہی ہے جو رات کے وقت تمہاری روحیں قبض فرما لیتا ہے اور جو کچھ تم دن کے وقت کماتے ہو وہ جانتا ہے پھر وہ تمہیں دن میں اٹھا دیتا ہے تاکہ تمہاری زندگی کی معینّہ میعاد پوری کر دی جائے پھر تمہارا پلٹنا اسی کی طرف ہے ، پھر وہ روزِ محشر تمہیں ان تمام اعمال سے آگاہ فرما دے گا جو تم اس زندگانی میں کرتے رہے تھے ۔',\n",
              " 'اور وہی اپنے بندوں پر غالب ہے اور وہ تم پر فرشتوں کو بطور نگہبان بھیجتا ہے ، یہاں تک کہ جب تم میں سے کسی کو موت آتی ہے تو ہمارے بھیجے ہوئے فرشتے اس کی روح قبض کرلیتے ہیں اور وہ خطا یا کوتاہی نہیں کرتے ۔',\n",
              " 'پھر وہ سب اللہ کے حضور لوٹائے جائیں گے جو ان کا مالکِ حقیقی ہے ، جان لو ! حکم فرمانا اسی کا کام ہے ، اور وہ سب سے جلد حساب کرنے والا ہے ۔',\n",
              " 'آپ ان سے دریافت فرمائیں کہ بیابان اور دریا کی تاریکیوں سے تمہیں کون نجات دیتا ہے ؟ اس وقت تو تم گڑگڑا کر بھی اور چپکے چپکے بھی اسی کو پکارتے ہو کہ اگر وہ ہمیں اس مصیبت سے نجات دے دے تو ہم ضرور شکر گزاروں میں سے ہو جائیں گے ۔',\n",
              " 'فرما دیجئے کہ اﷲ ہی تمہیں اس مصیبت سے اور ہر تکلیف سے نجات دیتا ہے تم پھر بھی شرک کرتے ہو ۔',\n",
              " 'فرما دیجئے : وہ اس پر قادر ہے کہ تم پر عذاب بھیجے خواہ تمہارے اوپر کی طرف سے یا تمہارے پاؤں کے نیچے سے یا تمہیں فرقہ فرقہ کر کے آپس میں بھڑائے اور تم میں سے بعض کو بعض کی لڑائی کا مزہ چکھا دے ۔ دیکھئے ! ہم کس کس طرح آیتیں بیان کرتے ہیں تاکہ یہ لوگ سمجھ سکیں ۔',\n",
              " 'اور آپ کی قوم نے اس قرآن کو جھٹلا ڈالا حالانکہ وہ سراسر حق ہے ۔ فرما دیجئے : میں تم پر نگہبان نہیں ہوں ۔',\n",
              " 'ہر خبر کے واقع ہونے کا وقت مقرر ہے اور تم عنقریب جان لو گے ۔',\n",
              " 'اور جب تم ایسے لوگوں کو دیکھو جو ہماری آیتوں میں کج بحثی اور استہزاء میں مشغول ہوں تو تم ان سے کنارہ کش ہوجایا کرو یہاں تک کہ وہ کسی دوسری بات میں مشغول ہوجائیں ، اور اگر شیطان تمہیں یہ بات بھلا دے تو یاد آنے کے بعد تم کبھی بھی ظالم قوم کے ساتھ نہ بیٹھا کرو ۔',\n",
              " 'اور لوگوں پر جو پرہیزگاری اختیار کئے ہوئے ہیں ان کافروں کے حساب سے کچھ بھی لازم نہیں ہے مگر انہیں نصیحت کرنا چاہیے تاکہ وہ کفر سے اور قرآن کی مذمت سے بچ جائیں ۔',\n",
              " 'اور آپ ان لوگوں کو چھوڑے رکھیئے جنہوں نے اپنے دین کو کھیل اور تماشا بنا لیا ہے اور جنہیں دنیا کی زندگی نے فریب دے رکھا ہے اور اس قرآن کے ذریعے ان کی آگاہی کی خاطر نصیحت فرماتے رہئے تاکہ کوئی جان اپنے کئے کے بدلے سپردِ ہلاکت نہ کر دی جائے ، پھر اس کے لئے اﷲ کے سوا نہ کوئی مدد گار ہوگا اور نہ کوئی سفارشی , اور اگر وہ جان اپنے گناہوں کا پورا پورا بدلہ یعنی معاوضہ بھی دے تو بھی اس سے قبول نہیں کیا جائے گا ۔ یہی وہ لوگ ہیں جو اپنے کئے کے بدلے ہلاکت میں ڈال دیئے گئے ان کے لئے کھولتے ہوئے پانی کا پینا ہے اور دردناک عذاب ہے اس وجہ سے کہ وہ کفر کیا کرتے تھے ۔',\n",
              " 'فرما دیجئے : کیا ہم اﷲ کے سوا ایسی چیز کی عبادت کریں جو ہمیں نہ تو نفع پہنچا سکے اور نہ ہی ہمیں نقصان دے سکے اور اس کے بعد کہ اﷲ نے ہمیں ہدایت دے دی ہم اس شخص کی طرح اپنے الٹے پاؤں پھر جائیں جسے زمین میں شیطانوں نے راہ بھلا کر درماندہ و حیرت زدہ کر دیا ہو جس کے ساتھی اسے سیدھی راہ کی طرف بلا رہے ہوں کہ ہمارے پاس آجا مگر اسے کچھ سوجھتا نہ ہو ، فرما دیں کہ اﷲ کی ہدایت ہی حقیقی ہدایت ہے ، اور اسی لیے ہمیں یہ حکم دیا گیا ہے کہ ہم تمام جہانوں کے رب کی فرمانبرداری کریں ۔',\n",
              " 'اور یہ بھی حکم ہوا ہے کہ تم نماز قائم رکھو اور اس سے ڈرتے رہو اور وہی اﷲ ہے جس کی طرف تم سب جمع کئے جاؤ گے ۔',\n",
              " 'اور وہی اﷲ ہے جس نے آسمانوں اور زمین کو حق پر مبنی تدبیر کے ساتھ پیدا فرمایا ہے اور جس دن وہ فرمائے گا : ہوجا ، تو وہ روزِ محشر بپا ہو جائے گا ۔ اس کا فرمان حق ہے ، اور اس دن اسی کی بادشاہی ہوگی جب اسرافیل کے ذریعے صور میں پھونک ماری جائے گے ، وہی ہر پوشیدہ اور ظاہر کا جاننے والا ہے ، اور وہی بڑا حکمت والا خبردار ہے ۔',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of English sentences:', len(english_sentences), \n",
        "      '\\nNumber of Urdu sentences:', len(urdu_sentences),'\\n')\n",
        "print('Example/Target pair:\\n')\n",
        "print('  '+english_sentences[2] )\n",
        "print('  '+urdu_sentences[2] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUEF9tUrlxXT",
        "outputId": "d242d8df-8eac-4a0d-89c0-eaeb9511028a"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English sentences: 6415 \n",
            "Number of Urdu sentences: 6415 \n",
            "\n",
            "Example/Target pair:\n",
            "\n",
            "  Master of the Day of Judgment .\n",
            "  روزِ جزا کا مالک ہے ۔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences[2].split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Illu4R_TlxXU",
        "outputId": "3c34ea66-9464-4741-d674-26fda616e2e5"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Master', 'of', 'the', 'Day', 'of', 'Judgment', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_en_length = 0\n",
        "for sentence in english_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_en_length = max(max_en_length, length)\n",
        "print(\"The longest english sentence in our dataset is:\", max_en_length) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NwBmMwFlxXU",
        "outputId": "39090d10-4439-4026-9abe-f014a5aaec10"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest english sentence in our dataset is: 243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_ur_length = 0\n",
        "for sentence in urdu_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_ur_length = max(max_ur_length, length)\n",
        "print(\"The longest urdu sentence in our dataset is:\", max_ur_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlMekFuplxXV",
        "outputId": "7790efbc-b929-4ed1-9c2b-39498d4158f0"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest urdu sentence in our dataset is: 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = max(max_ur_length, max_en_length) + 1\n",
        "seq_length = max_seq_length"
      ],
      "metadata": {
        "id": "amHThA3OlxXW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_word_count = {}\n",
        "ur_word_count = {}\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in en_word_count:\n",
        "            en_word_count[word] +=1\n",
        "        else:\n",
        "            en_word_count[word] = 1\n",
        "            \n",
        "for sentence in urdu_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in ur_word_count:\n",
        "            ur_word_count[word] +=1\n",
        "        else:\n",
        "            ur_word_count[word] = 1"
      ],
      "metadata": {
        "id": "pnJ9aEiWlxXW"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add end of sentence token to word count dict\n",
        "en_word_count[''] = len(english_sentences)\n",
        "ur_word_count[''] = len(urdu_sentences)"
      ],
      "metadata": {
        "id": "QP-LahD4lxXW"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of unique English words:', len(en_word_count))\n",
        "print('Number of unique Urdu words:', len(ur_word_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8XGRqwmlxXW",
        "outputId": "4809d130-2205-4e16-b094-7174db08b831"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique English words: 8948\n",
            "Number of unique Urdu words: 8142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_value(items_tuple):\n",
        "    return items_tuple[1]\n",
        "\n",
        "# Sort the word counts to see what words or most/least common\n",
        "sorted_en_words= sorted(en_word_count.items(), key=get_value, reverse=True)"
      ],
      "metadata": {
        "id": "CVHAur7elxXW"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_en_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oS-PV__lxXX",
        "outputId": "bd853621-bb33-4580-9844-cf04e585ed12"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('(', 12662),\n",
              " (')', 12661),\n",
              " ('.', 11142),\n",
              " ('the', 10838),\n",
              " ('and', 7531),\n",
              " ('of', 6456),\n",
              " ('', 6415),\n",
              " (',', 5632),\n",
              " ('to', 4559),\n",
              " ('you', 4329)]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_ur_words = sorted(ur_word_count.items(), key=get_value, reverse=True)"
      ],
      "metadata": {
        "id": "CiZHTHqWlxXX"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_ur_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOQXrnWplxXX",
        "outputId": "b4e4f7fa-dfdd-4f1b-9d1b-5176732cc655"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('اور', 10086),\n",
              " ('کے', 7212),\n",
              " ('۔', 6858),\n",
              " ('', 6415),\n",
              " ('ہے', 5927),\n",
              " ('سے', 5487),\n",
              " ('کی', 4971),\n",
              " ('میں', 4915),\n",
              " ('،', 4465),\n",
              " ('اس', 3840)]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the dataset is pretty small, we may want to get a bigger data set, but we'll see how this one does.\n",
        "\n",
        "Alternate Dataset Skip this section for now. You can come back and try training on this second dataset later. It is more diverse so it takes longer to train.\n",
        "\n",
        "Download the Urdu-English dataset from here, Although you could train the model on any of the other language pairs. However, you would need different word embeddings or they would need to be trained from scratch."
      ],
      "metadata": {
        "id": "31yIGQw9lxXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/machinetranslation/urd.txt', \"r\",encoding=\"utf8\") as f:\n",
        "    data1 = f.read()"
      ],
      "metadata": {
        "id": "-ztSK3OUlxXX"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = data1.split('\\n')\n",
        "english_sentences = []\n",
        "Urdu_sentences = []\n",
        "for i, pair in enumerate(pairs):\n",
        "    pair_split = pair.split('\\t')\n",
        "    if len(pair_split)!= 2:\n",
        "        continue\n",
        "    english = pair_split[0].lower()\n",
        "    urdu = pair_split[1].lower()\n",
        "    \n",
        "    # Remove punctuation and limit sentence length\n",
        "    max_sent_length = 10\n",
        "    punctuation_table = english.maketrans({i:None for i in string.punctuation})\n",
        "    english = english.translate(punctuation_table)\n",
        "    urdu = urdu.translate(punctuation_table)\n",
        "    if len(english.split()) > max_sent_length or len(urdu.split()) > max_sent_length:\n",
        "        continue\n",
        "       \n",
        "    english_sentences.append(english)\n",
        "    urdu_sentences.append(urdu)"
      ],
      "metadata": {
        "id": "20oAIY8llxXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(english_sentences) , len(urdu_sentences))\n",
        "english_sentences[6200].split()"
      ],
      "metadata": {
        "id": "8p5DWBJYlxXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f61500-487d-46b0-a8bc-933910685180"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6415 6415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'swear', 'by', 'this', 'city', '(', 'Makka', ')', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_sentences[6200].split()"
      ],
      "metadata": {
        "id": "uEAncEqelxXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ee5d28-e734-443d-a55e-1b29bdacb4a3"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['میں', 'اس', 'شہر', 'مکہ', 'کی', 'قَسم', 'کھاتا', 'ہوں', '۔']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(english_sentences[-100].split())\n",
        "urdu_sentences[-100].split()"
      ],
      "metadata": {
        "id": "5X1E950OlxXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c35ada1-a256-4129-c87e-bd216811e307"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Their', 'reward', 'is', 'the', 'Gardens', 'of', 'eternal', 'living', 'in', 'the', 'Presence', 'of', 'their', 'Lord', ',', 'with', 'streams', 'flowing', 'under', 'them', '.', 'They', 'shall', 'live', 'in', 'them', 'forever', '.', 'Allah', 'is', 'pleased', 'with', 'them', 'and', 'they', 'are', 'pleased', 'with', 'Him', '.', 'This', '(', 'status', ')', 'is', 'meant', 'for', 'the', 'one', 'who', 'fears', 'his', 'Lord', '.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ان',\n",
              " 'کی',\n",
              " 'جزا',\n",
              " 'ان',\n",
              " 'کے',\n",
              " 'رب',\n",
              " 'کے',\n",
              " 'حضور',\n",
              " 'دائمی',\n",
              " 'رہائش',\n",
              " 'کے',\n",
              " 'باغات',\n",
              " 'ہیں',\n",
              " 'جن',\n",
              " 'کے',\n",
              " 'نیچے',\n",
              " 'سے',\n",
              " 'نہریں',\n",
              " 'رواں',\n",
              " 'ہیں',\n",
              " '،',\n",
              " 'وہ',\n",
              " 'ان',\n",
              " 'میں',\n",
              " 'ہمیشہ',\n",
              " 'ہمیشہ',\n",
              " 'رہیں',\n",
              " 'گے',\n",
              " '،',\n",
              " 'اﷲ',\n",
              " 'اُن',\n",
              " 'سے',\n",
              " 'راضی',\n",
              " 'ہوگیا',\n",
              " 'ہے',\n",
              " 'اور',\n",
              " 'وہ',\n",
              " 'لوگ',\n",
              " 'اس',\n",
              " 'سے',\n",
              " 'راضی',\n",
              " 'ہیں',\n",
              " '،',\n",
              " 'یہ',\n",
              " 'مقام',\n",
              " 'اس',\n",
              " 'شخص',\n",
              " 'کے',\n",
              " 'لئے',\n",
              " 'ہے',\n",
              " 'جو',\n",
              " 'اپنے',\n",
              " 'رب',\n",
              " 'سے',\n",
              " 'خائف',\n",
              " 'رہا',\n",
              " '۔']"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_en_length = 0\n",
        "for sentence in english_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_en_length = max(max_en_length, length)\n",
        "print(\"The longest english sentence in our dataset is:\", max_en_length)  "
      ],
      "metadata": {
        "id": "NgpWAOaIlxXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f920b0-4577-43c8-a174-8c80e3be791a"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest english sentence in our dataset is: 243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_ur_length = 0\n",
        "for sentence in urdu_sentences:\n",
        "    length = len(sentence.split())\n",
        "    max_ur_length = max(max_ur_length, length)\n",
        "print(\"The longest urdu sentence in our dataset is:\", max_ur_length)  "
      ],
      "metadata": {
        "id": "m1jE8I9KlxXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a46b2a-4925-4cc5-9d17-d0c944cc5651"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest urdu sentence in our dataset is: 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = max(max_ur_length, max_en_length) + 1\n",
        "seq_length = max_seq_length"
      ],
      "metadata": {
        "id": "BAqFOtUalxXZ"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_word_count = {}\n",
        "ur_word_count = {}\n",
        "\n",
        "for sentence in english_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in en_word_count:\n",
        "            en_word_count[word] +=1\n",
        "        else:\n",
        "            en_word_count[word] = 1\n",
        "            \n",
        "for sentence in urdu_sentences:\n",
        "    for word in sentence.split():\n",
        "        if word in ur_word_count:\n",
        "            ur_word_count[word] +=1\n",
        "        else:\n",
        "            ur_word_count[word] = 1"
      ],
      "metadata": {
        "id": "u6MmDwW-lxXZ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_word_count[''] = len(english_sentences)\n",
        "ur_word_count[''] = len(urdu_sentences)"
      ],
      "metadata": {
        "id": "Z2iekHwalxXZ"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of unique English words:', len(en_word_count))\n",
        "print('Number of unique Urdu words:', len(ur_word_count))"
      ],
      "metadata": {
        "id": "9a79F2QQlxXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ec5582-0ee4-4981-e2e6-931e5dd164f8"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique English words: 8948\n",
            "Number of unique Urdu words: 8142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ur_word2idx = {k:v+3 for v, k in enumerate(ur_word_count.keys())}\n",
        "en_word2idx = {k:v+3 for v, k in enumerate(en_word_count.keys())}"
      ],
      "metadata": {
        "id": "KrlxZABKlxXa"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ur_word2idx[''] = 0\n",
        "ur_word2idx[''] = 1\n",
        "ur_word2idx[''] = 2\n",
        "\n",
        "en_word2idx[''] = 0\n",
        "en_word2idx[''] = 1\n",
        "en_word2idx[''] = 2"
      ],
      "metadata": {
        "id": "3jwW6RoOlxXa"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ur_word2idx)"
      ],
      "metadata": {
        "id": "Z1PzDQgmlxXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c0f37b-a9ba-4c2f-bc59-0c948054b397"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8142"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_value(items_tuple):\n",
        "    return items_tuple[1]\n",
        "\n",
        "sorted_en_words= sorted(en_word_count.items(), key=get_value, reverse=True)"
      ],
      "metadata": {
        "id": "9DDCnx0olxXb"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_en_words[-10:]"
      ],
      "metadata": {
        "id": "uBEYIz6zlxXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7297fc-d0cb-48b8-b74a-90df4a0a5919"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fibre', 1),\n",
              " ('uses', 1),\n",
              " ('bunch', 1),\n",
              " ('Superior', 1),\n",
              " ('harmfulness', 1),\n",
              " ('knots', 1),\n",
              " ('slinking', 1),\n",
              " ('whisperer', 1),\n",
              " ('withdrawing', 1),\n",
              " ('whispers', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SKip till now^"
      ],
      "metadata": {
        "id": "suj5PvciADIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Word Embeddings\n",
        "\n",
        "Here we are building an embedding matrix of pretrained word vectors. The word embeddings used here were downloaded from the fastText repository. These embeddings have 300 dimensions. To start we will add a few token embeddings for our specific case. We want a token to signal the start of the sentence, A token for words that we do not have an embedding for, and a token to pad sentences so all the sentences we use have the same length. This will allow us to train the model on batches of sentences that are different lengths, rather than one at a time.\n",
        "\n",
        "After this step we will have a dictionary and an embedding matrix for each language. The dictionary will map words to an index value in the embedding matrix where its' corresponding embedding vector is stored.\n",
        "\n",
        "Load Embeddings for the English data"
      ],
      "metadata": {
        "id": "gFwc6W9hlxXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data file containing the embeddings is very large so once we have the embeddings we want\n",
        "# we will save them as a numpy array. This way we can load this much faster then having to re read from\n",
        "# the large embedding file\n",
        "if os.path.exists('/content/drive/MyDrive/machinetranslation/en_words.npy') and os.path.exists('/content/drive/MyDrive/machinetranslation/en_vectors.npy'):\n",
        "    en_words = np.load('/content/drive/MyDrive/machinetranslation/en_words.npy')\n",
        "    en_vectors = np.load('/content/drive/MyDrive/machinetranslation/en_vectors.npy')\n",
        "    print('Embeddings load from .npy file')\n",
        "else:\n",
        "    # make a dict with the top 100,000 words\n",
        "    en_words = ['', # Padding Token\n",
        "                '', # Start of sentence token\n",
        "                ''# Unknown word token\n",
        "               ]\n",
        "\n",
        "    en_vectors = list(np.random.uniform(-0.1, 0.1, (3, 300)))\n",
        "    en_vectors[0] *= 0 # make the padding vector zeros\n",
        "\n",
        "    with open('wiki.en.vec', \"r\",encoding=\"utf8\") as f:\n",
        "        f.readline()\n",
        "        for _ in range(100000):\n",
        "            en_vecs = f.readline()\n",
        "            word = en_vecs.split()[0]\n",
        "            vector = np.float32(en_vecs.split()[1:])\n",
        "\n",
        "            # skip lines that don't have 300 dim\n",
        "            if len(vector) != 300:\n",
        "                continue\n",
        "\n",
        "            if word not in en_words:\n",
        "                en_words.append(word)\n",
        "                en_vectors.append(vector)\n",
        "        print(word, vector[:10]) # Last word embedding read from the file\n",
        "        en_words = np.array(en_words)\n",
        "        en_vectors = np.array(en_vectors)\n",
        "    # Save the arrays so we don't have to load the full word embedding file\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/en_words.npy', en_words)\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/en_vectors.npy', en_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyKD0UEblxXb",
        "outputId": "aa8267d9-6f4a-4e74-85b6-87a1e6773a71"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings load from .npy file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_word2idx = {word:index for index, word in enumerate(en_words)}"
      ],
      "metadata": {
        "id": "oxVR5sKtlxXc"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hemophilia_idx = en_word2idx['superior']\n",
        "print('index for word superior:', hemophilia_idx, \n",
        "      '\\nvector for word superior:\\n',en_vectors[hemophilia_idx][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni-x3kS-lxXc",
        "outputId": "826bab67-a07b-4799-d0a6-eb6f86203ff8"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index for word superior: 4388 \n",
            "vector for word superior:\n",
            " [-2.32999995e-02  1.71000008e-02 -9.99999975e-05  4.41000015e-02\n",
            " -4.83999997e-02 -3.97999994e-02  4.65999991e-02 -1.18000004e-02\n",
            " -5.99999987e-02  3.97000015e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word embedding for hemophilia matches the one read from the file, so it looks like everything worked properly.\n",
        "\n",
        "Load Embeddings for the Urdu data"
      ],
      "metadata": {
        "id": "O5VWc6A0lxXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/drive/MyDrive/machinetranslation/ur_words.npy') and os.path.exists('/content/drive/MyDrive/machinetranslation/ur_vectors.npy'):\n",
        "    ur_words = np.load('/content/drive/MyDrive/machinetranslation/ur_words.npy')\n",
        "    ur_vectors = np.load('/content/drive/MyDrive/machinetranslation/ur_vectors.npy')\n",
        "    print('Embeddings load from .npy file')\n",
        "else:\n",
        "    # make a dict with the top 100,000 words\n",
        "    ur_words = ['',\n",
        "                '',\n",
        "                '']\n",
        "\n",
        "    ur_vectors = list(np.random.uniform(-0.1, 0.1, (3, 300)))\n",
        "    ur_vectors[0] = np.zeros(300) # make the padding vector zeros\n",
        "\n",
        "    with open('wiki.ur.vec', \"r\",encoding=\"utf8\") as f:\n",
        "        f.readline()\n",
        "        for _ in range(100000):\n",
        "            ur_vecs = f.readline()\n",
        "            word = ur_vecs.split()[0]\n",
        "            try:\n",
        "                vector = np.float32(ur_vecs.split()[1:])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "             # skip lines that don't have 300 dim\n",
        "            if len(vector) != 300:\n",
        "                continue\n",
        "\n",
        "            if word not in ur_words:\n",
        "                ur_words.append(word)\n",
        "                ur_vectors.append(vector)\n",
        "        print(word, vector[:10])\n",
        "        ur_words = np.array(ur_words)\n",
        "        ur_vectors = np.array(ur_vectors)\n",
        "    # Save the arrays so we don't have to load the full word embedding file\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/ur_words.npy', ur_words)\n",
        "    np.save('/content/drive/MyDrive/machinetranslation/ur_vectors.npy', ur_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ximN2On3lxXc",
        "outputId": "12c689d2-242f-441c-c239-9b6e3dd96d89"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings load from .npy file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ur_word2idx = {word:index for index, word in enumerate(ur_words)}"
      ],
      "metadata": {
        "id": "nRTcXo21lxXd"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chabeuil_idx = ur_word2idx['رب']\n",
        "print('index for word رب:', chabeuil_idx, \n",
        "      '\\nvector for word رب:\\n',ur_vectors[chabeuil_idx][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS-ISpNllxXd",
        "outputId": "a68f6131-6c90-44dd-ec57-f9f1b25ecee6"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index for word رب: 1137 \n",
            "vector for word رب:\n",
            " [-0.1596     -0.1416     -0.1035     -0.36809999  0.0841     -0.0548\n",
            "  0.1609     -0.24240001 -0.0877     -0.0433    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ur_word2idx[\"رب\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLv5fJM1lxXe",
        "outputId": "bfeda068-161b-4203-dbb2-6ff364d76dd2"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1137"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word embedding for chabeuil matches as well so everything worked correctly for the french vocab.\n",
        "\n",
        "Ok, so we have all the pieces needed to take words and convert them into word embeddings. These word embeddings already have a lot of useful information about how words relate since we loaded the pre-trained word embeddings. Now we can build the translation model with the embedding matrices built in.\n",
        "\n",
        "Setting up PyTorch Dataset and Dataloader Rather than organizing all the data from a file and storing it in a list or some other data structure, PyTorch allows us to create a dataset object. To get an example from a dataset we just index the dataset object like we would a list. However, all our processing can be contained in the objects initialization or indexing process.\n",
        "\n",
        "This will also make training easier when we want to iterate through batches."
      ],
      "metadata": {
        "id": "5E9j_lBblxXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Urdu2EnglishDataset(Dataset):\n",
        "    '''\n",
        "        Urdu and associated English sentences.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, ur_sentences, en_sentences, ur_word2idx, en_word2idx, seq_length):\n",
        "        self.ur_sentences = ur_sentences\n",
        "        self.en_sentences = en_sentences\n",
        "        self.ur_word2idx = ur_word2idx\n",
        "        self.en_word2idx = en_word2idx\n",
        "        self.seq_length = seq_length\n",
        "        self.unk_en = set()\n",
        "        self.unk_ur = set()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(urdu_sentences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "            Returns a pair of tensors containing word indices\n",
        "            for the specified sentence pair in the dataset.\n",
        "        '''\n",
        "        \n",
        "        # init torch tensors, note that 0 is the padding index\n",
        "        urdu_tensor = torch.zeros(self.seq_length, dtype=torch.long)\n",
        "        english_tensor = torch.zeros(self.seq_length, dtype=torch.long)\n",
        "        \n",
        "        # Get sentence pair\n",
        "        urdu_sentence = self.ur_sentences[idx].split()\n",
        "        english_sentence = self.en_sentences[idx].split()\n",
        "        \n",
        "        # Add  tags\n",
        "        urdu_sentence.append('')\n",
        "        english_sentence.append('')\n",
        "        \n",
        "        # Load word indices\n",
        "        for i, word in enumerate(urdu_sentence):\n",
        "            if word in ur_word2idx and ur_word_count[word] > 5:\n",
        "                urdu_tensor[i] = ur_word2idx[word]\n",
        "            else:\n",
        "                urdu_tensor[i] = ur_word2idx['']\n",
        "                self.unk_ur.add(word)\n",
        "        \n",
        "        for i, word in enumerate(english_sentence):\n",
        "            if word in en_word2idx and en_word_count[word] > 5:\n",
        "                english_tensor[i] = en_word2idx[word]\n",
        "            else:\n",
        "                english_tensor[i] = en_word2idx['']\n",
        "                self.unk_en.add(word)\n",
        "            \n",
        "        sample = {'urdu_tensor': urdu_tensor, 'urdu_sentence': self.ur_sentences[idx],\n",
        "                  'english_tensor': english_tensor, 'english_sentence': self.en_sentences[idx]}\n",
        "        return sample"
      ],
      "metadata": {
        "id": "i6irS8l-lxXf"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urdu_english_dataset = Urdu2EnglishDataset(urdu_sentences,\n",
        "                                               english_sentences,\n",
        "                                               ur_word2idx,\n",
        "                                               en_word2idx,\n",
        "                                               seq_length = seq_length)"
      ],
      "metadata": {
        "id": "voy-lpPWlxXg"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = urdu_english_dataset[-10] # get 10th to last item in dataset"
      ],
      "metadata": {
        "id": "2lNeenrNlxXg"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input example:')\n",
        "print('Sentence:', test_sample['urdu_sentence'])\n",
        "print('Tensor:', test_sample['urdu_tensor'])\n",
        "\n",
        "print('\\nTarget example:')\n",
        "print('Sentence:', test_sample['english_sentence'])\n",
        "print('Tensor:', test_sample['english_tensor'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuRx3v3ylxXg",
        "outputId": "09f2950b-b0b1-49fc-f8b8-2997f72b7833"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input example:\n",
            "Sentence: اور بالخصوص اندھیری رات کے شر سے جب اس کی ظلمت چھا جائے ۔\n",
            "Tensor: tensor([  11,    2,    2,  586,    6, 3832,   12,   80,   17,    8,    2, 7197,\n",
            "          94,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "\n",
            "Target example:\n",
            "Sentence: And ( in particular ) from the evil of murky night when ( its ) darkness prevails .\n",
            "Tensor: tensor([ 162,   19,   11,  930,   17,   36,    4, 2922,    8,    2,  405,   81,\n",
            "          19,  105,   17, 7258,    2,    5,    2,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that both tensors end with the end of sentence token\n",
        "print(ur_word2idx[''])\n",
        "en_word2idx['']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT2IOlcIlxXh",
        "outputId": "a814de32-048b-436d-b6f1-9feb3f2f5099"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataloader to check how the batching works\n",
        "dataloader = DataLoader(urdu_english_dataset, batch_size=2,\n",
        "                        shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "OU2ripUWlxXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f89f9d-f155-486f-8376-e8426895092f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints out 10 batches from the dataloader\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['urdu_tensor'].shape,\n",
        "          sample_batched['english_tensor'].shape)\n",
        "    if i_batch == 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UWewbfQlxXh",
        "outputId": "7d1c0d62-98d9-4ce7-bf48-74306bfc44cf"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([2, 244]) torch.Size([2, 244])\n",
            "1 torch.Size([2, 244]) torch.Size([2, 244])\n",
            "2 torch.Size([2, 244]) torch.Size([2, 244])\n",
            "3 torch.Size([2, 244]) torch.Size([2, 244])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataloader:\n",
        "    batch = i\n",
        "    break\n",
        "\n",
        "for i in range(2):\n",
        "    print('Urdu Sentence:', batch['urdu_sentence'][i])\n",
        "    print('English Sentence:', batch['english_sentence'][i],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfpCzNOwlxXh",
        "outputId": "0efc7667-47f2-48c9-efc4-ebb9c214749b"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Urdu Sentence: بیشک جن لوگوں کے لئے پہلے سے ہی ہماری طرف سے بھلائی مقرر ہو چکی ہے وہ اس جہنم سے دور رکھے جائیں گے ۔\n",
            "English Sentence: Surely those for whom good has already been decreed from Us will be kept away from ( Hell ) . \n",
            "\n",
            "Urdu Sentence: اور یہ کہ مرنے کے بعد دوبارہ زندہ کرنا بھی اسی پر ہے ۔\n",
            "English Sentence: And that it is upon Him alone to raise up alive ( also after death ) . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2: Building the Model\n",
        "Bi-Directional Encoder"
      ],
      "metadata": {
        "id": "PQiZ0pTplxXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBiLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, pretrained_embeddings):\n",
        "        super(EncoderBiLSTM, self).__init__()\n",
        "        \n",
        "        # Model Parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.vocab_size = pretrained_embeddings.shape[0]\n",
        "        self.num_layers = 2\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0\n",
        "        self.bidirectional = True\n",
        "        \n",
        "        \n",
        "        # Construct the layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        \n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings)) #Load the pretrained embeddings\n",
        "        self.embedding.weight.requires_grad = False #Freeze embedding layer\n",
        "        \n",
        "        self.lstm = nn.LSTM(self.embedding_dim,\n",
        "                            self.hidden_size,\n",
        "                            self.num_layers,\n",
        "                            batch_first = True,\n",
        "                            dropout=self.dropout,\n",
        "                            bidirectional=self.bidirectional)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in LSTM to the Identity matrix\n",
        "        # This improves training and prevents exploding gradients\n",
        "        # PyTorch LSTM has the 4 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.hidden_size)\n",
        "        self.lstm.weight_hh_l0.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l0_reverse.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1_reverse.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = self.lstm(embedded, hidden)\n",
        "        return output\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        \n",
        "        hidden_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                   batch_size,\n",
        "                                   self.hidden_size, \n",
        "                                   device=device)\n",
        "        \n",
        "        cell_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                 batch_size,\n",
        "                                 self.hidden_size, \n",
        "                                 device=device)\n",
        "        \n",
        "        return (hidden_state, cell_state)"
      ],
      "metadata": {
        "id": "6a335F7blxXi"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBiGRU(nn.Module):\n",
        "    def __init__(self, hidden_size, pretrained_embeddings):\n",
        "        super(EncoderBiGRU, self).__init__()\n",
        "        \n",
        "        # Model parameters\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.vocab_size = pretrained_embeddings.shape[0]\n",
        "        self.num_layers = 2\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0\n",
        "        self.bidirectional = True\n",
        "        \n",
        "        \n",
        "        # Construct the layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.gru = nn.GRU(self.embedding_dim,\n",
        "                            self.hidden_size,\n",
        "                            self.num_layers,\n",
        "                            batch_first = True,\n",
        "                            dropout=self.dropout,\n",
        "                            bidirectional=self.bidirectional)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in GRU to the Identity matrix\n",
        "        # PyTorch GRU has 3 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.hidden_size)\n",
        "        self.gru.weight_hh_l0.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l0_reverse.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1_reverse.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output = self.gru(embedded, hidden)\n",
        "        return output\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        \n",
        "        hidden_state = torch.zeros(self.num_layers*(2 if self.bidirectional else 1),\n",
        "                                   batch_size,\n",
        "                                   self.hidden_size, \n",
        "                                   device=device)\n",
        "        \n",
        "        return hidden_state"
      ],
      "metadata": {
        "id": "GqWeM4FelxXi"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Encoder"
      ],
      "metadata": {
        "id": "NKCGQbzQlxXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the encoder on a sample input, input tensor has dimensions (batch_size, seq_length)\n",
        "# all the variable have test_ in front of them so they don't reassign variables needed later on with the real models\n",
        "\n",
        "test_batch_size = 1\n",
        "test_seq_length = 3\n",
        "test_hidden_size = 5\n",
        "test_encoder = EncoderBiLSTM(test_hidden_size, ur_vectors).to(device)\n",
        "test_hidden = test_encoder.initHidden(test_batch_size)\n",
        "\n",
        "# Create an input tensor of random indices\n",
        "test_inputs = torch.randint(0, 50, (test_batch_size, test_seq_length), dtype=torch.long, device=device)\n",
        "\n",
        "test_encoder_output, test_encoder_hidden = test_encoder.forward(test_inputs, test_hidden)\n",
        "\n",
        "print(\"The final output of the BiLSTM Encoder on our test input is: \\n\\n\", test_encoder_output.shape)\n",
        "\n",
        "print('\\n\\nEncoder output tensor: \\n\\n', test_encoder_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR-Ta2w2lxXj",
        "outputId": "10d93c41-b7a8-43be-c52d-d3ec325fa3e6"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final output of the BiLSTM Encoder on our test input is: \n",
            "\n",
            " torch.Size([1, 3, 10])\n",
            "\n",
            "\n",
            "Encoder output tensor: \n",
            "\n",
            " tensor([[[-0.0877,  0.1706, -0.0435,  0.0832,  0.0475, -0.1715,  0.2395,\n",
            "          -0.1193, -0.2290,  0.0324],\n",
            "         [-0.1350,  0.3082, -0.0784,  0.1531,  0.0710, -0.1691,  0.1905,\n",
            "          -0.0963, -0.2325,  0.0102],\n",
            "         [-0.1378,  0.4350, -0.0847,  0.2217,  0.0978, -0.1546,  0.1113,\n",
            "          -0.0619, -0.1908, -0.0056]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoder_hidden# Tuple where first item is the hidden states, second item is the cell states.\n",
        "\n",
        "# The lstm has 2 layers, each layer has a forward and backward pass giving 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSbyK6BjlxXj",
        "outputId": "74a8d8db-627f-4f03-d96a-bf8bf8d6ebb6"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.2635,  0.0930,  0.0028, -0.1320,  0.1404]],\n",
              " \n",
              "         [[ 0.4149, -0.1132, -0.1725, -0.0339, -0.0205]],\n",
              " \n",
              "         [[-0.1378,  0.4350, -0.0847,  0.2217,  0.0978]],\n",
              " \n",
              "         [[-0.1715,  0.2395, -0.1193, -0.2290,  0.0324]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>),\n",
              " tensor([[[ 0.5235,  0.2129,  0.0052, -0.4373,  0.2053]],\n",
              " \n",
              "         [[ 0.9865, -0.2116, -0.3602, -0.0613, -0.0365]],\n",
              " \n",
              "         [[-0.3910,  0.8565, -0.1941,  0.5295,  0.1568]],\n",
              " \n",
              "         [[-0.5222,  0.5773, -0.3028, -0.4086,  0.0641]]], device='cuda:0',\n",
              "        grad_fn=<CudnnRnnBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoder_hidden[0][::2] # Hidden states from forward pass for both lstm layers."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f-5tu-9lxXj",
        "outputId": "ae45a6a6-6f19-4fef-8473-06bc1f795b51"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2635,  0.0930,  0.0028, -0.1320,  0.1404]],\n",
              "\n",
              "        [[-0.1378,  0.4350, -0.0847,  0.2217,  0.0978]]], device='cuda:0',\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encoder_gru = EncoderBiGRU(test_hidden_size, ur_vectors).to(device)\n",
        "test_hidden = test_encoder_gru.initHidden(test_batch_size)\n",
        "o,h = test_encoder_gru(test_inputs, test_hidden)"
      ],
      "metadata": {
        "id": "hYWk7KfOlxXj"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWuK5U1HlxXk",
        "outputId": "53aa526b-fcf6-49f1-f073-0ccb3b289e6a"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1891, -0.0096,  0.5434,  0.0281, -0.1182, -0.0436,  0.1947,\n",
              "          -0.1520,  0.0785, -0.3193],\n",
              "         [ 0.3970,  0.1004,  0.7138,  0.0642, -0.2221, -0.0166,  0.1470,\n",
              "          -0.1608,  0.0719, -0.1618],\n",
              "         [ 0.5237,  0.2594,  0.7914,  0.0924, -0.2669, -0.0043,  0.1331,\n",
              "          -0.0239,  0.0167, -0.0367]]], device='cuda:0',\n",
              "       grad_fn=<CudnnRnnBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h)\n",
        "h[1::2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB40wMGGlxXk",
        "outputId": "2f547773-0be9-41f9-eb05-44ad5c13cc14"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0712,  0.3762,  0.3031, -0.2914,  0.1516]],\n",
            "\n",
            "        [[-0.3197, -0.3107, -0.0659,  0.6209, -0.2867]],\n",
            "\n",
            "        [[ 0.5237,  0.2594,  0.7914,  0.0924, -0.2669]],\n",
            "\n",
            "        [[-0.0436,  0.1947, -0.1520,  0.0785, -0.3193]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3197, -0.3107, -0.0659,  0.6209, -0.2867]],\n",
              "\n",
              "        [[-0.0436,  0.1947, -0.1520,  0.0785, -0.3193]]], device='cuda:0',\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention\n",
        "Let's take a moment test how attention is being modeled. Weighted sum of sequence items from encoder output."
      ],
      "metadata": {
        "id": "GRbPOANhlxXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize attention weights to one, note the dimensions\n",
        "attn_weights = torch.ones((test_batch_size, test_seq_length),device=device)\n",
        "\n",
        "# Set all weights except the weights associated with the first sequence item equal to zero\n",
        "# This would represent full attention on the first word in the sequence\n",
        "attn_weights[:, 1:] = 0\n",
        "\n",
        "attn_weights.unsqueeze_(1) # Add dimension for batch matrix multiplication\n",
        "\n",
        "# BMM(Batch Matrix Multiply) muliplies the [1 x seq_length] matrix by the [seq_length x hidden_size] matrix for\n",
        "# each batch. This produces a single vector(for each batch) of length(encoder_hidden_size) that is the weighted\n",
        "# sum of the encoder hidden vectors for each item in the sequence.\n",
        "attn_applied = torch.bmm(attn_weights, test_encoder_output)\n",
        "attn_applied.squeeze_() # Remove extra dimension\n",
        "\n",
        "print('Attention weights:\\n', attn_weights)\n",
        "print('\\nFirst sequence item in Encoder output: \\n', test_encoder_output[:,0,:])\n",
        "print('\\nEncoder Output after attention is applied: \\n', attn_applied)\n",
        "print('\\n', attn_applied.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM16jM8dlxXk",
        "outputId": "cc80535b-8776-4c0d-f2ea-2ed717cdb23c"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:\n",
            " tensor([[[1., 0., 0.]]], device='cuda:0')\n",
            "\n",
            "First sequence item in Encoder output: \n",
            " tensor([[-0.0877,  0.1706, -0.0435,  0.0832,  0.0475, -0.1715,  0.2395, -0.1193,\n",
            "         -0.2290,  0.0324]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "\n",
            "Encoder Output after attention is applied: \n",
            " tensor([-0.0877,  0.1706, -0.0435,  0.0832,  0.0475, -0.1715,  0.2395, -0.1193,\n",
            "        -0.2290,  0.0324], device='cuda:0', grad_fn=<SqueezeBackward2>)\n",
            "\n",
            " torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder with Attention"
      ],
      "metadata": {
        "id": "UaAJ5aKilxXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderLSTM(nn.Module):\n",
        "    def __init__(self, decoder_hidden_size, pretrained_embeddings, seq_length):\n",
        "        super(AttnDecoderLSTM, self).__init__()\n",
        "        # Embedding parameters\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.output_vocab_size = pretrained_embeddings.shape[0]\n",
        "        \n",
        "        # LSTM parameters\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.num_layers = 2 # Potentially add more layers to LSTM later\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0 # Potentially add dropout later\n",
        "        \n",
        "        # Attention parameters\n",
        "        self.seq_length = seq_length\n",
        "        self.encoder_hidden_dim = 2*decoder_hidden_size\n",
        "        \n",
        "        # Construct embedding layer for output language\n",
        "        self.embedding = nn.Embedding(self.output_vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False # we don't want to train the embedding weights\n",
        "        \n",
        "        # Construct layer that calculates attentional weights\n",
        "        self.attn = nn.Linear((self.decoder_hidden_size + self.embedding_dim), self.seq_length)\n",
        "        \n",
        "        # Construct layer that compresses the combined matrix of the input embeddings\n",
        "        # and the encoder inputs after attention has been applied\n",
        "        self.attn_with_input = nn.Linear(self.embedding_dim + self.encoder_hidden_dim, self.embedding_dim)\n",
        "        \n",
        "        # LSTM for Decoder\n",
        "        self.lstm = nn.LSTM(self.embedding_dim,\n",
        "                            self.decoder_hidden_size,\n",
        "                            self.num_layers,\n",
        "                            dropout=self.dropout)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in LSTM to the Identity matrix\n",
        "        # PyTorch LSTM has 4 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.decoder_hidden_size)\n",
        "        self.lstm.weight_hh_l0.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        self.lstm.weight_hh_l1.data.copy_(torch.cat([identity_init]*4, dim=0))\n",
        "        \n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.decoder_hidden_size, self.output_vocab_size)\n",
        "    \n",
        "    def forward(self, input, hidden, encoder_output):\n",
        "        # Input word indices, should have dim(1, batch_size), output will be (1, batch_size, embedding_dim)\n",
        "        embedded = self.embedding(input)\n",
        "        \n",
        "        # Calculate Attention weights\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((hidden[0][1], embedded[0]), 1)), dim=1)\n",
        "        attn_weights = attn_weights.unsqueeze(1) # Add dimension for batch matrix multiplication\n",
        "        \n",
        "        # Apply Attention weights\n",
        "        attn_applied = torch.bmm(attn_weights, encoder_output)\n",
        "        attn_applied = attn_applied.squeeze(1) # Remove extra dimension, dim are now (batch_size, encoder_hidden_size)\n",
        "        \n",
        "        # Prepare LSTM input tensor\n",
        "        attn_combined = torch.cat((embedded[0], attn_applied), 1) # Combine embedding input and attn_applied,\n",
        "        lstm_input = F.relu(self.attn_with_input(attn_combined)) # pass through fully connected with ReLU\n",
        "        lstm_input = lstm_input.unsqueeze(0) # Add seq dimension so tensor has expected dimensions for lstm\n",
        "        \n",
        "        output, hidden = self.lstm(lstm_input, hidden) # Output dim = (1, batch_size, decoder_hidden_size)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1) # softmax over all words in vocab\n",
        "        \n",
        "        \n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "Cd4RGyrilxXl"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderGRU(nn.Module):\n",
        "    def __init__(self, decoder_hidden_size, pretrained_embeddings, seq_length):\n",
        "        super(AttnDecoderGRU, self).__init__()\n",
        "        # Embedding parameters\n",
        "        self.embedding_dim = pretrained_embeddings.shape[1]\n",
        "        self.output_vocab_size = pretrained_embeddings.shape[0]\n",
        "        \n",
        "        # GRU parameters\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.num_layers = 2 # Potentially add more layers to LSTM later\n",
        "        self.dropout = 0.1 if self.num_layers > 1 else 0 # Potentially add dropout later\n",
        "        \n",
        "        # Attention parameters\n",
        "        self.seq_length = seq_length\n",
        "        self.encoder_hidden_dim = 2*decoder_hidden_size\n",
        "        \n",
        "        # Construct embedding layer for output language\n",
        "        self.embedding = nn.Embedding(self.output_vocab_size, self.embedding_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "        self.embedding.weight.requires_grad = False # we don't want to train the embedding weights\n",
        "        \n",
        "        # Construct layer that calculates attentional weights\n",
        "        self.attn = nn.Linear(self.decoder_hidden_size + self.embedding_dim, self.seq_length)\n",
        "        \n",
        "        # Construct layer that compresses the combined matrix of the input embeddings\n",
        "        # and the encoder inputs after attention has been applied\n",
        "        self.attn_with_input = nn.Linear(self.embedding_dim + self.encoder_hidden_dim, self.embedding_dim)\n",
        "        \n",
        "        # gru for Decoder\n",
        "        self.gru = nn.GRU(self.embedding_dim,\n",
        "                            self.decoder_hidden_size,\n",
        "                            self.num_layers,\n",
        "                            dropout=self.dropout)\n",
        "        \n",
        "        # Initialize hidden to hidden weights in GRU to the Identity matrix\n",
        "        # PyTorch GRU has 3 different hidden to hidden weights stacked in one matrix\n",
        "        identity_init = torch.eye(self.decoder_hidden_size)\n",
        "        self.gru.weight_hh_l0.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        self.gru.weight_hh_l1.data.copy_(torch.cat([identity_init]*3, dim=0))\n",
        "        \n",
        "        # Output layer\n",
        "        self.out = nn.Linear(self.decoder_hidden_size, self.output_vocab_size)\n",
        "    \n",
        "    def forward(self, input, hidden, encoder_output):\n",
        "        # Input word indices, should have dim(1, batch_size), output will be (1, batch_size, embedding_dim)\n",
        "        embedded = self.embedding(input)\n",
        "        \n",
        "        # Calculate Attention weights\n",
        "        attn_weights = F.softmax(self.attn(torch.cat((hidden[0], embedded[0]), 1)), dim=1)\n",
        "        attn_weights = attn_weights.unsqueeze(1) # Add dimension for batch matrix multiplication\n",
        "        \n",
        "        # Apply Attention weights\n",
        "        attn_applied = torch.bmm(attn_weights, encoder_output)\n",
        "        attn_applied = attn_applied.squeeze(1) # Remove extra dimension, dim are now (batch_size, encoder_hidden_size)\n",
        "        \n",
        "        # Prepare GRU input tensor\n",
        "\n",
        "        attn_combined = torch.cat((embedded[0], attn_applied), 1) # Combine embedding input and attn_applied,\n",
        "        gru_input = F.relu(self.attn_with_input(attn_combined)) # pass through fully connected with ReLU\n",
        "        gru_input = gru_input.unsqueeze(0) # Add seq dimension so tensor has expected dimensions for lstm\n",
        "        \n",
        "        output, hidden = self.gru(gru_input, hidden) # Output dim = (1, batch_size, decoder_hidden_size)\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1) # softmax over all words in vocab\n",
        "        \n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "D632kDVNlxXm"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Decoder"
      ],
      "metadata": {
        "id": "mMc12plulxXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the decoder on sample inputs to check that the dimensions of everything is correct\n",
        "test_decoder_hidden_size = 5\n",
        "\n",
        "test_decoder = AttnDecoderLSTM(test_decoder_hidden_size, en_vectors, test_seq_length).to(device)"
      ],
      "metadata": {
        "id": "qlfBzhNtlxXm"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_idx = torch.tensor([ur_word2idx['']]*test_batch_size, dtype=torch.long, device=device)"
      ],
      "metadata": {
        "id": "lekJD7S8lxXm"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_idx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fw_gwwulxXn",
        "outputId": "271f93e7-c649-47ac-de36-7760a3e0cfa2"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_idx = input_idx.unsqueeze_(0)\n",
        "test_decoder_hidden = (test_encoder_hidden[0][1::2].contiguous(), test_encoder_hidden[1][1::2].contiguous())"
      ],
      "metadata": {
        "id": "cI-rEHSQlxXn"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_idx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0EhAtcdlxXn",
        "outputId": "5ad33352-fa07-40ec-dae0-75d649f72667"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, hidden, attention = test_decoder.forward(input_idx, test_decoder_hidden, test_encoder_output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL4nHk2TlxXo",
        "outputId": "1d013c19-3a4c-429b-b2f1-acbe6ba605d8"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100003])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_decoder_hidden[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDzkcIJMlxXo",
        "outputId": "54d1fb80-8bde-4036-f64f-92ad5fee4135"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Training the Model\n",
        "Training Function"
      ],
      "metadata": {
        "id": "J-6TGhoVlxXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder,\n",
        "          encoder_optimizer, decoder_optimizer, criterion):\n",
        "    \n",
        "    # Initialize encoder hidden state\n",
        "    encoder_hidden = encoder.initHidden(input_tensor.shape[0])\n",
        "    \n",
        "    # clear the gradients in the optimizers\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "    \n",
        "    # run forward pass through encoder on entire sequence\n",
        "    encoder_output, encoder_hidden = encoder.forward(input_tensor, encoder_hidden)\n",
        "    \n",
        "    # Initialize decoder input(Start of Sentence tag) and hidden state from encoder\n",
        "    decoder_input =  torch.tensor([en_word2idx['']]*input_tensor.shape[0], dtype=torch.long, device=device).unsqueeze(0)\n",
        "    \n",
        "    # Use correct initial hidden state dimensions depending on type of RNN\n",
        "    try:\n",
        "        encoder.lstm\n",
        "        decoder_hidden = (encoder_hidden[0][1::2].contiguous(), encoder_hidden[1][1::2].contiguous())\n",
        "    except AttributeError:\n",
        "        decoder_hidden = encoder_hidden[1::2].contiguous()\n",
        "    \n",
        "    # Initialize loss\n",
        "    loss = 0\n",
        "    \n",
        "    # Implement teacher forcing\n",
        "    use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Step through target output sequence\n",
        "        for di in range(seq_length):\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "            \n",
        "            # Feed target as input to next item in the sequence\n",
        "            decoder_input = target_tensor[di].unsqueeze(0)\n",
        "            loss += criterion(output, target_tensor[di])\n",
        "    else:\n",
        "        # Step through target output sequence\n",
        "        for di in range(seq_length):\n",
        "            \n",
        "            # Forward pass through decoder\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "            \n",
        "            # Feed output as input to next item in the sequence\n",
        "            decoder_input = output.topk(1)[1].view(1,-1).detach()\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss += criterion(output, target_tensor[di])\n",
        "    \n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Clip the gradients\n",
        "    nn.utils.clip_grad_norm_(encoder.parameters(), 25)\n",
        "    nn.utils.clip_grad_norm_(decoder.parameters(), 25)\n",
        "    \n",
        "    # Update the weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "r_sD8wtklxXo"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "MHMIOaDblxXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, dataloader, epochs, print_every_n_batches=100, learning_rate=0.01):\n",
        "    \n",
        "    # keep track of losses\n",
        "    plot_losses = []\n",
        "\n",
        "    # Initialize Encoder Optimizer\n",
        "    encoder_parameters = filter(lambda p: p.requires_grad, encoder.parameters())\n",
        "    encoder_optimizer = optim.Adam(encoder_parameters, lr=learning_rate)\n",
        "    \n",
        "    # Initialize Decoder Optimizer\n",
        "    decoder_parameters = filter(lambda p: p.requires_grad, decoder.parameters())\n",
        "    decoder_optimizer = optim.Adam(decoder_parameters, lr=learning_rate)\n",
        "\n",
        "    # Specify loss function, ignore the  token index so it does not contribute to loss.\n",
        "    criterion = nn.NLLLoss(ignore_index=0)\n",
        "    \n",
        "    # Cycle through epochs\n",
        "    for epoch in range(epochs):\n",
        "        loss_avg = 0\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "        # Cycle through batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            \n",
        "            input_tensor = batch['urdu_tensor'].to(device)\n",
        "            target_tensor = batch['english_tensor'].transpose(1,0).to(device)\n",
        "            \n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder, decoder,\n",
        "                         encoder_optimizer, decoder_optimizer, criterion)\n",
        "            \n",
        "            loss_avg += loss\n",
        "            if i % print_every_n_batches == 0 and i != 0:\n",
        "                loss_avg /= print_every_n_batches\n",
        "                print(f'After {i} batches, average loss/{print_every_n_batches} batches: {loss_avg}')\n",
        "                plot_losses.append(loss)\n",
        "                loss_avg = 0\n",
        "    return plot_losses"
      ],
      "metadata": {
        "id": "HpSBKVv-lxXp"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "s7e0TqC-lxXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters and construct dataloader\n",
        "hidden_size = 256\n",
        "batch_size = 16\n",
        "dataloader = DataLoader(urdu_english_dataset, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=4) "
      ],
      "metadata": {
        "id": "C_T7RughlxXp"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct encoder and decoder instances\n",
        "encoder_lstm = EncoderBiLSTM(hidden_size, ur_vectors).to(device)\n",
        "decoder_lstm = AttnDecoderLSTM(hidden_size, en_vectors, seq_length).to(device)\n",
        "\n",
        "encoder_gru = EncoderBiGRU(hidden_size, ur_vectors).to(device)\n",
        "decoder_gru = AttnDecoderGRU(hidden_size, en_vectors, seq_length).to(device)"
      ],
      "metadata": {
        "id": "HnuSTPZhlxXp"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from_scratch = True # Set to False if you have saved weights and want to load them\n",
        "\n",
        "# if not from_scratch:\n",
        "#     # Load weights from earlier model\n",
        "#     encoder_lstm_state_dict = torch.load('/content/sample_data/encoder1_lstm.pth')\n",
        "#     decoder_lstm_state_dict = torch.load('/content/sample_data/decoder1_lstm.pth')\n",
        "\n",
        "#     encoder_lstm.load_state_dict(encoder_lstm_state_dict)\n",
        "#     decoder_lstm.load_state_dict(decoder_lstm_state_dict)\n",
        "    \n",
        "#         # Load weights from earlier model\n",
        "#     encoder_gru_state_dict = torch.load('/content/sample_data/encoder1_gru.pth')\n",
        "#     decoder_gru_state_dict = torch.load('/content/sample_data/decoder1_gru.pth')\n",
        "\n",
        "#     encoder_gru.load_state_dict(encoder_gru_state_dict)\n",
        "#     decoder_gru.load_state_dict(decoder_gru_state_dict)\n",
        "# else:\n",
        "#     print('Training model from scratch.')"
      ],
      "metadata": {
        "id": "44uyAPN5lxXp"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Load weights from earlier model\n",
        "    encoder_lstm_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/encoder2_ur_lstm.pth')\n",
        "    decoder_lstm_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/decoder2_ur_lstm.pth')\n",
        "\n",
        "    encoder_lstm.load_state_dict(encoder_lstm_state_dict)\n",
        "    decoder_lstm.load_state_dict(decoder_lstm_state_dict)\n",
        "    \n",
        "        # Load weights from earlier model\n",
        "    encoder_gru_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/encoder2_ur_gru.pth')\n",
        "    decoder_gru_state_dict = torch.load('/content/drive/MyDrive/machinetranslation/decoder2_ur_gru.pth')\n",
        "\n",
        "    encoder_gru.load_state_dict(encoder_gru_state_dict)\n",
        "    decoder_gru.load_state_dict(decoder_gru_state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPi83MUSJIFC",
        "outputId": "51d32564-f79e-47cf-9228-f7aeb5c051e9"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For dataset 1, models were trained for 3 epochs\n",
        "# For dataset 2, models were trained for 50 epochs\n",
        "\n",
        "learning_rate = 0.0001\n",
        "encoder_lstm.train() # Set model to training mode\n",
        "decoder_lstm.train() # Set model to training mode\n",
        "\n",
        "lstm_losses_cont = trainIters(encoder_lstm, decoder_lstm, dataloader, epochs=9, learning_rate = learning_rate)\n",
        "\n",
        "\n",
        "# For dataset 1, models were trained for 3 epochs\n",
        "# For dataset 2, models were trained for 50 epochs\n",
        "print('Training GRU based network.')\n",
        "learning_rate = 0.0001\n",
        "encoder_gru.train() # Set model to training mode\n",
        "decoder_gru.train() # Set model to training mode\n",
        "\n",
        "gru_losses = trainIters(encoder_gru, decoder_gru, dataloader, epochs=9, learning_rate = learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBtirnjmlxXq",
        "outputId": "1fd66177-b22e-4c45-d316-996bb2cdd631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 2/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 3/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 4/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 5/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 6/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 7/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 8/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 9/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Training GRU based network.\n",
            "Epoch 1/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 2/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 3/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 4/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 5/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 6/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 7/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 8/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n",
            "Epoch 9/9\n",
            "After 100 batches, average loss/100 batches: nan\n",
            "After 200 batches, average loss/100 batches: nan\n",
            "After 300 batches, average loss/100 batches: nan\n",
            "After 400 batches, average loss/100 batches: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('/content/sample_data/lstm2_ur_losses.npy', lstm_losses_cont)"
      ],
      "metadata": {
        "id": "rkSA6P95VCgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('/content/sample_data/gru2_ur_losses.npy', gru_losses)"
      ],
      "metadata": {
        "id": "A9mY1pjPVKW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_losses = np.load('/content/drive/MyDrive/machinetranslation/lstm2_ur_losses.npy')\n",
        "gru_losses = np.load('/content/drive/MyDrive/machinetranslation/gru2_ur_losses.npy')"
      ],
      "metadata": {
        "id": "h-8AvOriVfG9"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lstm_losses)\n",
        "plt.plot(gru_losses)\n",
        "\n",
        "plt.title('Loss Plots for Dataset 1; Trained on 1 Epoch')\n",
        "plt.xlabel('Batches')\n",
        "plt.xticks([0,20,40,60,80],[0,2000,4000,6000,8000])\n",
        "plt.ylabel('Loss per Batch, MSE')\n",
        "plt.legend(['LSTM', 'GRU'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "FirG9xgsVqEs",
        "outputId": "0ffb861e-093b-41a2-92c0-9cd192287793"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1da8289280>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the model weights to continue later\n",
        "# torch.save(encoder_lstm.state_dict(), '/content/sample_data/encoder2_ur_lstm.pth')\n",
        "# torch.save(decoder_lstm.state_dict(), '/content/sample_data/decoder2_ur_lstm.pth')"
      ],
      "metadata": {
        "id": "FFuEdFemVuIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(encoder_gru.state_dict(), '/content/sample_data/encoder2_ur_gru.pth')\n",
        "# torch.save(decoder_gru.state_dict(), '/content/sample_data/decoder2_ur_gru.pth')"
      ],
      "metadata": {
        "id": "I5bTfQpOWDAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Using the Model for Evaluatio"
      ],
      "metadata": {
        "id": "JrTzBRCCWa8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the idx to word dictionaries to convert predicted indices to words\n",
        "en_idx2word = {k:i for i, k in en_word2idx.items()}\n",
        "ur_idx2word = {k:i for i, k in ur_word2idx.items()}"
      ],
      "metadata": {
        "id": "iKls8tG6WYaJ"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(dataloader):\n",
        "    for batch in dataloader:\n",
        "        return batch"
      ],
      "metadata": {
        "id": "OYPD9zOdWiSG"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_tensor, encoder, decoder):\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden = encoder.initHidden(1)\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor.to(device), encoder_hidden)\n",
        "\n",
        "        decoder_input =  torch.tensor([ur_word2idx['']]*input_tensor.shape[0], dtype=torch.long, device=device).unsqueeze(0)\n",
        "        try:\n",
        "            encoder.lstm\n",
        "            decoder_hidden = (encoder_hidden[0][1::2].contiguous(), encoder_hidden[1][1::2].contiguous())\n",
        "        except AttributeError:\n",
        "            decoder_hidden = encoder_hidden[1::2].contiguous()\n",
        "\n",
        "        output_list = []\n",
        "        attn_weight_list = np.zeros((seq_length, seq_length))\n",
        "        for di in range(seq_length):\n",
        "            output, decoder_hidden, attn_weights = decoder(decoder_input,\n",
        "                                                           decoder_hidden,\n",
        "                                                           encoder_output)\n",
        "\n",
        "            decoder_input = output.topk(1)[1].detach()\n",
        "            output_list.append(output.topk(1)[1])\n",
        "            word = en_idx2word[output.topk(1)[1].item()]\n",
        "\n",
        "            attn_weight_list[di] += attn_weights[0,0,:].cpu().numpy()\n",
        "        return output_list, attn_weight_list"
      ],
      "metadata": {
        "id": "tlWT-DIJWo4L"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = get_batch(dataloader)\n",
        "input_tensor = batch['urdu_tensor'][11].unsqueeze_(0)\n",
        "output_list, attn = evaluate(input_tensor, encoder_lstm, decoder_lstm)\n",
        "gru_output_list, gru_attn = evaluate(input_tensor, encoder_gru, decoder_gru)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bE3VnAeWuoW",
        "outputId": "72acb901-f6a3-4fcb-be62-0beaf41ee2e1"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input Sentence:')\n",
        "input_ur_output = ''\n",
        "for index in input_tensor[0]:\n",
        "    word = ur_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        input_ur_output += ' ' + word\n",
        "    else:\n",
        "        input_ur_output += ' ' + word\n",
        "        print(input_ur_output)\n",
        "        break\n",
        "\n",
        "print('\\nTarget Sentence:')\n",
        "targ_sen_ur = ' ' + batch['english_sentence'][11] + ''\n",
        "print(targ_sen_ur)\n",
        "input_len = len(batch['urdu_sentence'][11].split())\n",
        "\n",
        "print('\\nLSTM model output:')\n",
        "lstm_ur_output = ''\n",
        "for index in output_list:\n",
        "    word = en_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        lstm_ur_output += ' ' + word\n",
        "    else:\n",
        "        lstm_ur_output += ' ' + word\n",
        "        print(lstm_ur_output)\n",
        "        break\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.title('LSTM Model Attention\\n\\n\\n\\n\\n')\n",
        "ax = fig.add_subplot(111)\n",
        "ax.matshow(attn[:len(lstm_ur_output.split()), :input_len])\n",
        "ax.set_xticks(np.arange(0,input_len, step=1))\n",
        "ax.set_yticks(np.arange(0,len(lstm_ur_output.split())))\n",
        "ax.set_xticklabels(batch['urdu_sentence'][11].split(), rotation=90)\n",
        "ax.set_yticklabels(lstm_ur_output.split()+[''])\n",
        "\n",
        "\n",
        "gru_ur_output = ''\n",
        "print('\\nGRU model output:')\n",
        "for index in gru_output_list:\n",
        "    word = en_idx2word[index.item()]\n",
        "    if word != '':\n",
        "        gru_ur_output += ' ' + word\n",
        "    else:\n",
        "        gru_ur_output += ' ' + word\n",
        "        print(gru_ur_output)\n",
        "        break\n",
        "        \n",
        "fig = plt.figure()\n",
        "plt.title('GRU Model Attention\\n\\n\\n\\n\\n')\n",
        "ax2 = fig.add_subplot(111)\n",
        "ax2.matshow(gru_attn[:len(gru_ur_output.split()), :input_len])\n",
        "ax2.set_xticks(np.arange(0,input_len, step=1))\n",
        "ax2.set_yticks(np.arange(0,len(gru_ur_output.split())))\n",
        "ax2.set_xticklabels(batch['urdu_sentence'][11].split(), rotation=90)\n",
        "ax2.set_yticklabels(gru_ur_output.split()+[''])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GAd3diAaOy1g",
        "outputId": "0497fa21-6e2a-41f2-8df5-bf61f3abd5b6"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence:\n",
            " اور بیشک تمہارے لئے مویشیوں میں بھی مقامِ غور ہے ، ہم ان کے جسموں کے اندر کی اس چیز سے جو \n",
            "\n",
            "Target Sentence:\n",
            " And indeed in the cattle ( too ) there is a point for you to ponder . We provide you with pure milk to drink brought forth from that substance of their bellies ( which is produced by ) compounding ( certain ) intestinal contents and blood and which freshens up those who drink it .\n",
            "\n",
            "LSTM model output:\n",
            " And We ( ( the the the the the \n",
            "\n",
            "GRU model output:\n",
            " And ( the the the the the the the the the the the the the the the the \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-190-75e23829bdb4>:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  ax = fig.add_subplot(111)\n",
            "<ipython-input-190-75e23829bdb4>:51: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  ax2 = fig.add_subplot(111)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'And'),\n",
              " Text(0, 0, '('),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the'),\n",
              " Text(0, 0, 'the')]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 1729 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 1746 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 1748 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 1729 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 1746 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 1748 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAADmCAYAAAAwRPUfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5glRfW/38/ORuKSJLMkkeQP+AJKUMCACQQVDKjkoCKoiAEQECWICEgQRCQJoqJgAEGS5JxzzrCEZQVkZZfdZff8/jh1d3p6um+YuTN3pve8z9PPvbcrdnf1uVWnTp2SmREEQRBUkxGdrkAQBEEwcISQD4IgqDAh5IMgCCpMCPkgCIIKE0I+CIKgwoSQD4IgqDAh5IO5FknLSzJJI5uIu5OkGwajXu1C0oOSNut0PYLOEkI+aBlJX5J0q6S3JE1K3/eUpBR+lqQZkv4n6TVJV0haNZP+EEm/L8jXJK1cUuYzKc9Fc+fvTumWb+9Vto6k+dI1/yt3vtefSbv/NNI9Pyx7zszWMLNr2lVGMDwJIR+0hKR9geOBXwBLAIsDXwc2BkZnoh5lZvMBSwMTgdPbUPzTwHaZurwXmKcN+baLbYDpwOaSluh0ZYIAQsgHLSBpQeCnwJ5mdr6ZTTHnbjP7iplNz6cxs2nAn4G121CFc4AdMr93BM7O11HS2ZJelfSspAMljUhhXZKOljRZ0lPAFgVpT5f0kqSJkg6T1NVC/XYETgHuA76aOX9d+nwj9fQ3TPE2TL/fSOWPSfV7TtIrkk6RNC6FbSbpBUn7ptHTS5J2TmF7AF8BfpDyuyidf0bSRzN5HyfpxXQcJ2lMo7yD4U8I+aAVNgTGAP9oNoGkefHe9xNtKP8WYAFJqyXh+yUgr/Y5EVgQWBHYFP9TqAms3YEtgXWA9YBtc2nPAt4BVk5xPgbs1kzFJE0ANgPOTUf2z2iT9DnezOYzs5vx0c/N6ff4FH4ksAr+h7gyPgo6OJPPEunalgZ2BU6StJCZnZrKPCrl9+mCKv4I2CDlvRbwPuDARnk3c+3B0CaEfNAKiwKTzeyd2glJN0l6Q9I0SZtk4n4v9VCnAB8Atm9THWq9+c2Bh3FVUK0uNcG/fxplPAMckyn7C8BxZva8mb0G/CyTdnHgU8B3zOwtM5sE/DLl1wzbA/eZ2UPAn4A1JK3T7EWl+Yw9gH3M7DUzmwIckSt/JvBTM5tpZpcA/wPe02QRX0lpJ5nZq8BP6PlM+pN3MIRpaFUQBBn+AywqaWRN0JvZRgCSXqBnp+FoMztQ0nLApbjAuC+FvQOMymYsqfZ7ZoM6nIOrP1Ygp6rB/4RGAc9mzj2L904BlgKez4XVmJDSvpTmj0nXk41fjx2A3wKY2URJ1+Lqm7ubTL8YPr9wZ6Z8AVl10X+yf7DAVGC+JvNfit73Zak25R0MYaInH7TCzfjE4tbNJjCz54BvA8fX9MvAc8Dyuagr4MJ/InUws2fxCdhPAX/NBU/G/yQmZM4tl8nzJWDZXFiN5/FrW9TMxqdjATNbo159ACRtBLwb2F/Sy5JeBt4PfDlZ1BS5es2fmwxMA9bIlL9gmrxuhkbuZF+k9315scm8g2FMCPmgaczsDXyYf7KkbSXNL2mEpLWBeeukuwIXKHukU5cCq0raXtIoSQvjqokLcr3JMnYFPmxmb+XKmYVP8h6e6jYB+C7devs/A9+StEzSN++XSfsScDlwjKQF0nWtJGnTJuqzI3AFsDqu814bWBMYB3wSeBWYjc8T1HgFWEbS6FT+bHwk8EtJ7wKQtLSkjzdRfi2/FeuE/xE4UNJiyQz1YHrPZwQVJIR80BJmdhQuOH+AC5ZXgN8APwRuqpP0F7j1x5ik7/4k8DVgEvAA8AbwjSbr8KSZ3VESvDfwFvAUcAPwB+CMFPZb4DLgXuAueo8EdsDNQB8CXgfOB5asVxdJY3Fd/4lm9nLmeBpXLe1oZlOBw4Eb0/zFBsBVwIPAy5Imp+x+iE9Q3yLpTeBKmteLnw6snvL/e0H4YcAduMrs/nT9hxXECyqGYtOQIAiC6hI9+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDChJAPgiCoMCHkgyAIKkwI+SAIggoTQj4IgqDCjOx0BQYbSQsAnwaWBl4A/m5mUztbqyAIgoFhbuzJ7wqsDUwFNgHukvTuzlYpCIJgYJCZdboOHUXS5sDXzWybTtclGBpIErCEmb3U6boEQX+Z64U8gKQnzGzlTtcjGBpIWhn4CzAT2MTM3u5wlYKgz8yN6poeSFoGeL3T9QiGDmb2hJmtA1wNfL3T9QmC/jBXCnlJ80r6naSjgUuBYztdp2BIcjbwqU5XIgj6w1yprkk6148BCwP3mtlDHa5SMISQdLaZ7SBpBPCEma3Y6ToFQV+Z60woAczMJF0HjI/JtaCAVwDMbHbqEATBsGVuVdfsDdwLPClpsqSDOl2nYEjx88z3sR2rRRC0gblSyAP7AOsBrwFrAZ+TtENnqxQMFcxssqRlJX0OuL/T9QmC/jC3CvkLgCeBS8xsIrALEEI+yPJL4IfAvp2uSBD0h7ly4hVA0kJm9nr6LuBRM1ulw9UKgiBoK0N64lXSzmZ2ZpvzHAkslp1wTROx+7WznGD4IOlQoLS3Y2YHD2J1gqCtDGkhD2wkaZKZXVw7IanLzGb1I88zgMskzQ/8BPihmZ1lZn/tb2WDYcsTnShU0oLAF4EXzOySTtQhqD5DWl0j6f+Aw8zsU+n3gcC3gP8AG5vZa33I8wlgDeAu4EPAZcCGc9vS9aSi2ojkjdPMbupwleY6JP0FnxvaEm/nf+pwlYIKMqSFPICkm4EDgN2A2cDuwI+B183sqD7kdwGwIHC3mX1f0pHAZWZ2dRurPeSRdDDwXuBZYE18YdhWZvZyRyvWASRdT291zUzgZeAcM7t0gMp9xMxWlbQe8GszW38gyhmqSPoicCgwDvcKe4KZndTZWlWP4SDkPwKcDJxmZr9I51YCbgHOKUsGjDGzPQvyWxDYDPiXmc2QtDMwysxOHYj6DxckbQ98xMx26nRdBhtJEwpOjwRWA34GfNfMrhiAcn8H3GZmJyW15LvaXcZQRtJq+ChyiqQlgQuBR4Cye/26mV00aBWsCENeyJchaaqZzVMn/G9m9tkm8tkPeN7Mzm1rBYch4Y2zN5LeB/zYzLYYgLzfBdwIHAMcbGZLtbuM4UQaUS0BbFsS5XAz23IQq1QJhvrEayGSxlLHGiJRN1zSXsDmwARg4zZVbdgiaSHgf52uR19JfmYWBf7Tz4n5HpjZbZJWbUdekj5ccPoQXMgv1o4yhjlvAIub2b1FgZJmDnJ9KsGwEvLJ/HEJ3DNgf90DnwrcCjxkZm/1t27DEUnj8AU/k/He0xmdrVHfkPQNYH9gErCEpD8C+/VH2KeJ6eWBlXDdfDvYvuT8pcDn21TGsEJSF7As3gZXAG6rE314qh06zLBS16Qe/L/xSbHxQJn9soBvmtnHCvJYB5gPeNnMHh+oug4H0gu2Gz7peo+Z/avDVeoTkhYHJqX1DmOBo/Ee/Y/7kWcX7k9+DLCXmd3entqWlveSmS05kGUMRVJH4ypgIWB+4P+Z2X9K4jalgk1xl2sQZUa7jAySOfaWwE1m9mw78mwnw0rIZ5G0ae5U7UJqXgPfMrM7CtL9BFgRWA54zMx2H7haBp1A0hj8T2u1TtelWSTtZGZndboenUTSqfRUGdbeZUvf32z2j1vS/cBvM3nk2crMPtLXuubKWhL4AfAZfCex59uRb7sYVkI+mf1NwIfPvzGz59L5UcDheI/0DuBMM5veIK8FcCG/xMDWeugiaVvcemQp4BngSDMrs1gaNiS13v39EfJpdLAX8C7clv30sh5m0DckrY2rX6/HLd6uMLMZKWwErp/vkytwSReZ2afrhDc9KmihzG8Ay5jZj9qZb38Zbg7K/gX8AV+hmDWlGoG7Dv4L8H7g2vSi90LSqDSL/xTwm4Gt7pDnSGADfH5jB+BQScPSeiE9180krYm7Cu7vuoe/AhOBrXGd8QNpq8j+1PF5Sc8VHM9Leq6f9W0rkraX9LSkW1NPdSA4BXgROBPYE8hauK0IXJLK74u750a91y5JX5H0A0lfllRqqdcISYukr/8EPpwLW0fSByW9u6/595dhJeSTXvRp4B0yfr7NbLqZnWtml5nZzsDD5Ca5JG2ddvyZCXwN9y643UDUU1Iv+/whys24PvR2M7sTv2fDdU/TEfhzPQZvH6XeIyWtJemPko4q6wzguvh5cNvsvfEtIg/sTwXNbFkzW67gWNbMGumQB5t9gXXwjtPPBqiM8cAsYIVkojq/pKWhxz671zAwbXJ5YG18EdYmwF39EMQHACQ1Tf4P8TPAHsBpkn7bx/z7xbCxrpG0BXA58CfgPcCJdaL/An8ps87NRpL0c2b2kKSlgK6BqS2LSBpnZtMGKP92sSPuT//B9PtGoGM9jv6Q1HPN/mmfjK+03AGfvC+awN8JX129Y/r9G/z+9BlJRdsIzgReHYJuNWbg6s8T8QVKvZB0DuUrhc8zs/salHEKPuKqzYtdhY8sL8jEORt3+3xcK5UHFpN0LOU6+cfN7Pu1H5I2x0e227RYDsAiZQG1OYSaergPefebYaGTT43pdjM7If2eD3jSzBYviS9c395LYCX9/f34cv6l8ca8eTv1rZI+CUw1s2vbledAIGmR/HVL+lbtPg8nki37gbi9+ZPAcWZW+FJJehBX640FbjSz9zRZxjVmtlk/6likQhqJqyauA3ZII82OI+mjeGfpY8AdZtZrVXCB8QP49awKfBfYzszqmUTm89sRmNfMTlYH9tnt72LAJFueMbOlc+euwldPn9Qfi68+Y2bD4gB+kT63wNUMr+MLSXbJHyneiDp5jch8PwJ3mdCo/OXwXoaANRrEFdDV6XvWoI774X92Z3a6Lm26nnuAT+A63n3xXb9WK4n7LeBP6ftzBeHr40vstxmkunfho4sDOn0fc/X6FK76fKUPaT8K/KXJuMvgqptzgc3SuV9kwp/u53X8P3wO70Fc4PZ6rqkOt/ejjC/iprtnpd9bA2en76vjI8LHOvEch41O3tyZ2Ei88bwA3A58D/ggPjGWPTCz2XXyyoYdhnujbMRZwCj8ZTxP0q+ygZnJF8xp26rLAWInXFXTzLUPB97EhdLLZnYM3pPcPx9J0nbmI5WnJF2GP9M8x+HqnCMGsL5zSG3lJ/RNVTCQvIbPTYySdGKLk5NX4TrvZtgQV4W9YGbXpHPt3GfX8Pv7ftzUce80sTyvpN9JOhpfkHZsP8pYGneguE/63UM9jE/ij5G0YtnRj7Lr04l/lnYdwKbA1f3MowsfDjaK9zhuanhf+n09sEj6Pux6xcCvcSdvF3a6Lm26nqXSC7Zi+j0OX82cj7d5+pyAW2S9RK5nB9wJfBO4axDr3wU8VSd8PmD0IN/TpfFe8PuAfwDHNJluHN577df9wztsnwMub/N1LY6bWgv4OD6Xs3qby/gIrlkYhc9pXIavAZiSZMfVueOqgXqOw0InX4TcL/yFwK7A6bngj+KTRn8uSgr8F19hNxFftr6AmW2X8l0B+DLJzzo+5HpB0s/xIdeBZnaapB/httgXSnoEb9RPmdny7b3SgSHNW2wG/Aj35mkAZnZ2B6vVViT93sy+WhK2Hu5Pfyy+6vc4Mzs5ha2Au7PGBtgrZxqdHoyrA2eb2S658Pnx0ePGqa7fMrPzC/Lp1W5xgbKUmT0saT4z67NvorRu4EZ8kvR+M5tc53oewgX97pZz05x5b0XvSVsB65rZJinu+big383M7k/nFgA+nbnOv5vZ1AZ1/z8zuytfDzNbWb7idrw1sMeX9BugzP3JB/D9og/JxF8YuN7M1pA0wpL2QNIRwLvMbLd65bWVgfr3GMgD/ye+CF9I8UBB+EXA3+qk/yveePYE9saFfC1sR7wXtyXeQ38UWC+Fjc/F2zN9H7a9YnyofDJuiXRGp+vTx2tYCbdcaKqnWZD+vRT0OnFzzKn4MHzWANZ/l9QWxxWEfQ/YPn1fEd+LuCiPonZ7bfr9E+BV+qHzB9YDpuPWNvf2I5+LGoSXvrcpfB98Qngv3DrnEeDdTZY9Kn1uA/w9vfuPpWc8GTioL/XGzbqvyJ0T7t02H3ce3GgEvCO6P7D+QLUtMxu2Qv7XeC/luZqgzYVfCPy1Tvp/tFDWuvimIrXf86XPE4AtMg/0Q8CV6WXbAbeU6Pi9GoB7Py++Ovb59Me2cYvp10ifP8JHYN/GLSr6U6cufOLuQuALfczjmU7f25J6jcl8F01OQqZ2OxXfIOcBXLd+OzB/i+V/DTd2eDPl95uMkPpwvaMkv8KOED4H8lN8oven+aNO/TYHLmjiOhZI8uJF4CbcGdpT6fwL+Mjg7rL3tqzetbaTF+j4yP6Okrb6RPq+aGr/T9BmdVH2GDZ28lnM7BtyB0RfMbM3WkmbbGeXk/RZfBHDQVZn5x8zu1O+SUmN7ST9FDd5uyTFMeBqSW/jC4rG4UPRIav6kPQ03kN9ATjUzK5sMulUvOc0U9JmwJ8lbWjJxUQTbIVbOTyJexz8HHB9WvH5VFl1KdkEBuZMXL4h6Sj8pSlS0/XOVFrHzO6WtAo+yVg7vzs+SqzZe7/ZIJ+N8V7leNwk9yQzaziJJ+k9eDu6AfdCeQHeK8zHg3QPcEODhqR2+w6uYjnXzKZLugRX+7Sy09UU4DRcyO+L26zXXAGXedUEb/9XtVBObZ/dt/C20RRmdoWkXzcR701cJTYH+S5xT+Kjh4mSdsFHCa2+tw8Aa0o6EzgJF+QnklEjSzqebvXw7alOk4HjJU3G1WD7MAAMK518EuxL4S6CnwXOp/diBwO+ALwC7FyQTc2Uall8mHwargd8p6TMVYHfmllTL9dwQe5lseZO90rr41yC3F/HsmZ2gKR5rIF+tCSPU4H3m9ladeKU+hqRdKiZHZSWv99rzdu9H4f/yXQBe1vazF3SVri9/XLAR82s7n4DkpbHHeK9Kmkx/EW/2cx+2UQdhAuDm4CtrcTfSrJsuQFfgVoTTKU29bV2i3vQvDed2wkYa2anNKpXJp/R+Mh0Qdxa5gp8845lJX3MzC5vNq+U35P4JG7ReytcNdr0uyZ3NfE3q7N1Yk5urG5mD2bCFjKz19N34eqwVQryuBZX7xRxLL7K+hxcFTQb1yT8IZN+WXwuoQs3s5wiaS0zu1e+ecwlZrZes9fdCsOtJ38WPiF2Mt6zGG1me+UjSar1NNYpyONNfALrVjO7XdJVuPXATZn08+N+KF7Fh727p/PfxoXCsngPuBDrnjiaD9fjl8btFGY2S7714Ya45VBfOQ+4LAnYxyS9QhMjpBzH4j3aetTrjbwOYGZvJ6HUFGb2HeA7AJJWkbS8mT1jPpk+Au/17thEPs9kvr8qaTe8B91QyJuZSToJX/NR7xrPx1Vl++LrRA6RtFF2JFvUbq3nBhwr0d0L74Ea73N7Wop3Et297l0lTTOz6xtdZw0zW6nofKZ8k1RrC4X77EqaF5cBr+JrIw5vUOxZ+EhrL2B9Sbfi93tmyqNWN5PvFFfEGRTLE3Dh/rqZXUhP/ztzMHd5UJvY/5TcOds0vFMySdKiDa6hzww3Ib8s3ovZ2MzWlHR9sk9fAbdQ+J2ZXWBmv6slkO/pOsfCAB9Cfg6oxXkQ15/NEfLpX3YPfGLkUTN7TdLZ+ATd1/GJ23pD1doLdzvwutwfx75m9pc23IOGyL111mNS6s2thr/4L7SQpvbnNcPMZqR7cz3eS1kN12vugvvquNLM3pG0Cf4CTzSzIpXMo7gA6yvZla2jUx0bXc+y1tPN9MLAAZIOwvXCL+DL1Q9pVHiB9cYUYMkGdZiEj152Bu7D791DdeJPwP/Muszs00nteBAZHz1F7TbV7zv4qPZNXMddRJEVUm2f219Imp167VeRLI/wubG9cZNAJH0Vn+R9HPisNXDrkSycDsbfxUblz7LufXan4o4KF8aNBerdN3C58W18XcjtuMpwhRS2YvpT2YG0rkLu5K6ISWZ2SoFMmQ4cnkaAPbzgyvfx3cV6rpu5Du8A3Jy9HQ2uoe8MlLJ/IA58gcTLuEkV+OTdVnivaX0KLA/woWHNwmASOQsDfPXjzpnfI4Elc3G+hjfk/fAJxxty4aNwx0RjS+q9Mj45M2CTK7nyLsEnlBYsOf6eiTsm3dOGafBNHc7BdecvAttm8rkc12Weln7/EtgofT8H+D2ubjgZH/Z/AhfsW+CC+bb0LIuOrWnCVhpfTn9Xg3vwofT5GvCe3DN8Ddgnc24C8GKT93xkij8fLngnNnE/v5tJ/3SDe/Cj1H4/neIvCtxdr93m6rcYST3bh/b0PuBiXOBOyIXdi3cUfob/ASyJq4n2zMVbDTc1XDBzrvS9LSo/83uedsiN9H3OauM6babHe0NvmXIQ8BXc5v5M3CBhZIr7HMk6L1OfLjITtfh78OyAyYOBynjAKlxgxkidxSv40LKXhQHeEz8eX8S0aCb+2emBfR3X6++K907vBv6G9/wfAFZN8fdIDWgSLvj+QFoklavHl4HjB+keNWWmhk8yPY4PWXuZoubTUMecj+7e0vj0e7faS5WJs0C6V7fgi2z+jAuPv+AL22rHDun5fCgdm+ZflIL6XYcL1m3q3QO81z8a763/PHN+QbwnfU76vQa+Gvo56gjPTPr50nU9mtrAZQ3i/w1YO/P7pVbuAS4036nTbneiTSZ6uD57Gt7ReQzfda0W9kV8kc9JdAu299LTIm1+XJf/R3yEtE863/SiM7oteo5N1/hZ/F3+RJPXUGj+nH4vnurS7HtTKFMy8c7ER05npfZwGZk/WHzl7Y3p+/dTexkw2TAk1TVJ5/Yg/o83EVd13AhgZm9kFnasi9/AbfEhZJHXu+sotzB4Gzjaei7s2AjXwd9Faqy43hrcv8UUfJj1Gdxr3f64V8w70+dewBWSNrOeVhkXAsdIqucIbY5KpOCejMF7vTea2St18oDmNzm/CX9plgEul/T1svJTmhOtezOWp0mqEZijczw+E38e/F7V6n8dLphOxgVDzcXs+pIuxc3KJqa4h9K9GnF+M9u6wfWAm9KNydzzsntwKW6uNw+wc5rQvQX/U7razL4pdyp1GN6zvgi4X9JHzCfJCttmao8bZK73wgb1NTO7J81lrIMvpJvj0C53D5azNM+TYX56zmMUtdsrcNXGHyVtZe59tRW1XG1ifl/8+Xww6Y5vw4U6ZnYePi+TvbD7lXHba2ZT8OczZ5GQpJuo/95my8/us1uqFqx3USVyo8ZkuhdH1s0mfdaTKZC84JrZJyRdjN+vy+ULqkbiKrMDUtxncIui01t5Ni0xUP8e/Tnwxl1buLAZfvOXy4Tvjvd8zqPnP+TRZBavAGviw9S1MnF2wnsCK+HC+125si/A7d1rDtGOBD6UCb8/lX9W+n083nM6LxPnh6ReIm5OuWT6/hBNqlEK7snZ+It1TRP371+pnKJjQQrWCeB+u+9rMc0yBefKRkir473Tx/DJzkm4NQm4P5Eip1HL43r8bI/rMNxW+wd0u5UYjc+zfD+VMX+de7AYPlH3KK4quAe31LoyW99cPbYhqQsoaZupbodm6nZlM88AFxjPA5uWlL08PkG4aPr9+UzYs5nvpe0W7+H/Mn1vRZXXlep3K90LArtIveo67W8UddQPuKA+vey9bVB+oVqwrG3kyu0hN+gWuGfhE6uN3ptbKZYpX8MnxvfGVXbCXRmDd2rGpToeiy+w2zhXr3G4mqvpZ9PKMSxMKGtmerhOdyt8SH1jJnwJXD92qZn9LZ27G9/0+3oz+0cm7qF4T2dx/IFNwR/ubmZmaVJlM+BfZjYjWaCMwoeZvcrOlP+K1aSAL5W+k+6JqWVIq+rMbNU611nPTPAJfNXhXVbgdjVZlWyJ6x+fx3vpNRO72kOuTe5MMrNfZ9L+Gx+CfoFuv92FaXLlnEAyB8vktRh+/26x3F6Xcve1v7GchYUyLmYz554jCU4zOyyduxHX7x+Cq3i2xQX1BqnMR/DR1K50m8pm9wmtXc+7ccG8n5nNmXAvQ25u+qQVmJlm2uammbrNxFUltUV7+fIh9wwy+a2Ed1yeyNyDGcCPzOwESZ8ws0slLYQvtlkppStqtyuY2cFZEz21YVs8ZZbp584Lf1duA14ys0+WpB+LT1B+lNx7m4nzKYrf9Zo/m9+Z985r7gF2pqBtmLskKcwr5bcLbm33ebwDMpHiNgM+2juPJFMkrZye0xN4W1sH1w58DPduOrte2an8vemWEV3AYWZ2aMl969uWhX35ZxjsA39hbscn1rbDLWxWzYQvgKtP7gfel87Ni09OLZx+fwefJKpt/bc4LgznwYe13y4pez+8J5Qtu9CFbSbNaLzB5FfU/Zc6K2Gpv0p3V1xgnFkSvi3wK1zveSuua18V36P0INy3d1G6z+OLMM7Bbbupl6ZOOYvh/tzLyqk5abofVyksQoGL2Uz8efAde7K91Ttw75IPp9/fB04pKOuXtThF15Pq+6V8Oyp6jpn29UiDtjmnbnjP7opa3cruJ2liOnduLZKzqsw9mIarJzbJxDsMX79RVvf9SPML6fcz6bNsxWnNVfedlLvvrttbTvWtzfH8OnO+V9vAOxS93ttMeOG7XlDvb+ECvrRtNJNXemY/KWszJTLlYlymvIW/n0+mfI5o9jroKSMup/6q21L5UO8YEKE8EAeu46p934kCPyWpwVxT0Ei3x3WCy+D/yvvg5mg/TulWwf+ds3nthc+i30Nm2X2dsr+JD/uOwoXY93Dd3KvAqSnODbjHuaZVIrkyRuP+SM7Eh5e9fM2khvhIut6r0vf903X0WmqO99zvwwXJB3FTtrppmijnIwXxsz78D8MXoX0e7wEdhU90vj8TZ8v6xNUAABH5SURBVD685/QMaWk/PvI6nu4/8k3wXvNyBXWbgfeM1i67nrJnmQn/Az6EvpP6S+uPzdYtlf9sqlu98h+kQEVEt0Cu3YNpeBut/UnW/jCLVBLZdvv7zPln02eZSuKIdDyC68mzx8Ep7T24GuhlfEXnS2RUdrgA3Bc4FW/3K+K920Zt4zP4CK/o3hY+I7ydHpfux6JlbSMT/3pcRfcCrgKqHdenz1p7LmozR1FfpmyAW499Eh8hXtnCdRyV7tWp6dl8gGIZ0VA+lB1DVl0jaVvcLGsp/EX/uSUPiWn4+S8zWzf93sLMLk5D2IfxYXKW2m41a+EPZl3gJjOrTeYg6XEze3dmgvN2fGn7Q2b2ViZej7LTuTG4nvFl/KE/ar5cXvisfm1F3Xm4C9KinZeEq3zmTKyUTMQskq5hXLontUmy5Sy5FpCv5FwdVyG8z3zCcGvgM+Z22UjaxszmbLOW0qyPv5QbFqXpSzlFSNoOH5auJGk1c3vj5YE/mtmGKc5d+DNYGn9uh1tu0knS6vhq0S0ts8OVfBXkHfif19LAl0vuQa9nmc7PmeRO97vLkhfEFJ5vm/82s2/l8jgTtwCZWFS+pO3xTsARltmJK6uGydyDNXBd70fx0dyblvMoWa/dpsnih8xsgqQfUz4pPacN5ttHyud+fL5jmpmtJun7wEpm9vUU/nFcFfoI3tNfF5+v+mzJ/c++t9dYwYrn9IzuwTsS2fUQi5PUgriV0ddy6VbH9f619jQBf5Zn43MAV6eo8+JmnTdn2nO+zRyCm7xmycqUTS3jxVLSY5ZbNVtra/gfcI8gfDT4Gv4e/Q/X3+dlxGYp7I78PUqUT8r25Z9hMA5cR7wI/s+7Lv4ybZkJr/V2zqKnbfPTdfL8Bt4ATyLnh57uHkDDCc5s2fXS4H84i2R+X57ONTWxQv2JmPH0nCTLljOWnGlaOvdI5vejwBLp+z4pfDt844bCNH0pp+T+PZq5h/vRPaLqtUtT5rm9iZtdjsw97+fS5wKpLRyN95C/mq4nX9/89fR4lrnneXVJffJtcybJtDRX1uSy8nGzyH/TpBoG1wVPocBjIj5pd05JG+xhotegTWVtwee0j0xea6bnUHtXFsDdDhfdo7Hp2V5ddP21dtfkezst5fX7kjpPIdOW820jl9ezeHs/k95eKH/STJspaJu/yp0rnJjGZdgluHqy6Doux1VAXy0J+2ej51ZYbr2XsZNHarT30m2b+kHgn0UPEO8Vlj7YTNg4fBg/npINGvAXuDS8qIx8GuDa9HkG8NVMvIuos/CDnJtVWnTLml66M+kWdF/MN/DM95eBQ9L3NdPn4vkGTYGVRCvl5M5fkl6wqXRvvnIWPnHZq+xMulG4b5CT8YU2veqL94g+gevaS+dM8nUrai+N2kC2beJD+v+Q29qt7Hpyz+ByfOVlTQ3zMOVqmKdwIdHLYyLee/5vUZ1xldg36J5faNim0jXNaR/p/K64GvKt2v1P56/JfH9PQX5P1Ln+Zt/bafgEfFn428205XT++VpeNOmFsqw9p7Bem9Pkrzl7jfXuP3VcpNcLqz23srAhaSef2BEfCtWcCd2IW0WQbHXnLJk2swPT+UVwIV7GWHxY9Dxu8lTEz+qF58vOp5F0CDBD0ga4uuAASX82s9qfSz0/MflhdNmwuiz8f3iPbyF8qPpwpt4r42aLNe4BPi73Rnl2siA5Eu9JlKXpSzlZDsCHnc8A05JVzc7ACFxHf3FJulH40vF1cHXYx10TxsLA7GSFAi7ozcyWK8okX7eSZwkN2gA92+YE0gKmdD1np+vpcS+LyscnI180s48n65jZlrFUyvEPfJLxdOvtMfFhvDf7GjA1cz+g2zJkf1xf3EybOj9dU619zIOr8p7C78tppDUB1nNj87w11Wq43r7w+pt5b9MzmmVmB9Wp8xs0aMuZvKZm8mrohbJBewaXKV2Z+BPwP/2i65hG/ftvdcLrhVEvbMgKeXMTrbuzvyWdJPcFsQLek5yDpBPwHs05+byS2d+VuJA9Btd3XZ70ppby3yV9ni7p90XhZWVn0+CTZW/hCyNex825bpF0JfB/wBfku9v0qiY9G8siwLJyPxpFbnx7xM/cs/xOPPPhE1Jr4r3gbPotcYF2KG6jfBlwYJ00fSknm+4e4B5Jn8Ytln6aLzuX5934pNiq+HD61/ik14opzbnAd6yxj5RedSt7lqmepW0gc/21tvm43JnZT/EFMb2up+zemNltme//Lal79h6cbmZ7pKB76HaduxVuCfIHvA0+la9zhlEl7Q+YswF97Zq2wtcUbIGrpC7DrdQeLUpsZlMljcf115NxVdZu9dpGg/e29owmNqjzCErackFec563+b7RR1iaMyNzTxu155xMqTlvOwVXKZ5Vch1n4p2BsmsZh3cQi8LrhfWSBT0CU1e/o0h6nuJ/ol49M7kP8zFmdlmPiN5zXtjMLikpY6WU7qH0eyG6JzCxjFOzsvCysuulSefXwUchG+G9rTJnRHNsp+XbqF2MvygnFsT9Lr7gK7+lW9E92xyfnLo6c24C7j+jcMPzWhq8V9Pss2kqDa56e9HquMpN+b0Lv2fT8bmU5/BJ4Rvqpat3PbV70OhZpjgL4SOv2vPKbv825/rTvZxodVZdpvLPxVULvYKheASSuweXW8bRlaTPmdlfk0DeyMxuaKJd/5hut75F1NZDFF5T6iV/xnKTsrk4q+KjvEes2+igVxtM50vf29ozwkcN9er8DvCzsraczave807xPmfdLqcL65yJm5cpH8B397oiF29O2Q3u/6Z4GyuaXK0XBiXrLmCICPkgCIJgYBjR6QoEQRAEA8eQFPJyn9hNn69amk6X35c0nS5/sNJ0uvzBStPp8vuSptPlD1aaenkVUmZ208mDgg1w652vWppOlz+31Dmuc+iWP7fUud3XWXQMyZ58EARB0B6amniV9Bl8kcRqZvZI05n7rPL3zGzLRnFHa4yNTTvAzWQ6oxjTK07Z+aql6XT5c0ud+5Km0+X3ClO3kcZMe5tRGpuJaZmw6YxSLb+SNBlZkC9fI7st9GbMfpvRIzyNzeo2aOldPoVhytR5hr3N6EyarDzKppm1cvfWve/8dyojF5xnzu+uJ2YUlq/Ro7rLmTWV0V2exqZ3m+R37HmWPLesyc0MpjM6k6Z2b/J5TeH1yWa2WGGFaN5OfjvcudZ2dO/v2FbGMi/v10cGIusgGDhUYtXXROepHeVo5KjC816HEovCrmKTaps+vfA8QNdCixSenz0lb8HbGI0u32vd3i6uwxsnFK5vA2D81kXLSKBrmaUKz7/z1DPllRtRam5eTtl9rtMGNKr4HqirXLky++0i61u40s5/trxyTUy8pkUBH8CXNX8pndtM0jWSzpf0iKRzlf6eJX0inbsL9/scBEEQdIhmdPJb4079HwP+I6nmsW8dfPXb6vgKxI3lmwH8FvfIuC7uDS8IgiDoEM0I+e2AP6Xvf0q/AW4zsxfMV5ndg29TtiruTe5xcwXS7+tlLGkPSXdIumMm5UPFIAiCoG/U1cnLN939MPBeSYb7RzB8uX1WKs9qlFcRZnYq7iyfBbRwLL0NgiBoM40E87b4FmJzHPJLuhb3PVLEI8DyklYysyfp7vUHQTVp9wRri+XYzHpOV0t4p9TFTimz/1vsHLMv5duMOmlKrvOWtcscgsLHZ65dnNXrhT7f6jN7VuHpEfPMU3geYPbUqa2XUzJZO3t6HXdOpZP89YtqpK7ZDjedzHIBJcLbzN4G9gAuThOvk7xuGifp2uTcKAiCIBgk6vbkzexDBedOILc1lZntlfl+Ka6bn4Okb+Kb0Bb/TQZBEAQDwmCteP0Kvfc2DIIgCAaYAd80JDnXX9HMnikI2wNX7zCWcp1XEARB0DcGoye/KL49Vy/M7FQzW8/M1itbJhwEQRD0ncEQ8tPwfRCDIAiCQaYldY18/8Yvm9nJzTofM7PXJXVJGpusb4IgGG6U76xXTpnJn+r0LUtsMza4Z9vSJAvqyeKAWSV2HvX805Rc58z3rVp4HqDr2ruLA+r5rinx32PTyrcr7lp4oeKAyaVJgNZ78uOBPVtMA7658Af6kC4IgiDoB61OvB4JrCTpHnz39rcknY/vaH4n8FUzs+Tf5lhgPvx/5hhgR3x38yAIgmCQaFXI7wesaWZrJ3XNP4A1gBeBG3EnZbcCJwJbm9mrkr6Ie6+8WlJX2MoHQRAMHv01obzNzF4ASL375XFLmjWBK5L34S7gJTM7I584TCiDIAgGlv4K+SInZQIeNLMNGyUOB2VBEAQDS6tCfgowf4M4jwKLSdrQzG6WNApYxcwe7FMNgyBoL33ZzarMIqYsr3rFl+xM5VUotm6Z9HTxzlQAC+rp4oBRxeJNI8rrbLOLr7Nraj3HYSX3pp5mui+WR32419C6kJ8FTJL0QErby6bHzGZI2hY4QdKCKd5xQAj5IAiCQaZVIT8eGGdma9bs5GsBOSdl9wCbtKWGQRAEQZ8ZLBPKnczspTbWOwiCIGiCVhdD7Qc8aWZrA9+neJ/XUbgJ5bZmti5wBnB4UWax/V8QBMHAMmgmlEWJw7omCIJgYOmoCWUQBEEwsLQq5AUsmb6vDaxfECdMKIOgavTFQVkb6ZoyWPsbFWNd5eWXGjbWM3kc0YfrqWN6Wo9WhbwBXRkTyt4RwoQyCIJgyNDq38mRwBjgHXxh1MOSzpf0CG4z/7sUrwv/Q3gHeAH4Z3uqGwRBELRCWNcEQRBUmLCuCYIgqDBhXRMEQVBhWlXXtGRdAyBplKQ1+l7FIAjmdrqmq/QYFFTnGCQkFR6NCOuaIAiCChPWNUEQBBWmo9Y1QRAEwcDSUeua2P4vCIJgYInt/4IgCCpMq+qalrb/g7CuCYIg6CSx/V8QBEOerootiG/G9LEgUZ/Kiu3/giAIKkxs/xcEQVBhwkFZEARBhQkHZUEQBBUmHJQFQRBUmHBQFgTBkGfEzPJjUJDKj8FixIjiowHhoCwIgqDChIOyIAiCChMOyoIgCCpMOCgLgiCoMOGgLAiCoMKEg7IgCIIKEw7KgiAY8oyY0YdEs0uUA6rXt53Vh4KGNuGgLAiCoMKEg7IgCIIKEw7KgiAIKkw4KAuCIKgw4aAsCIKgwoSDsiAIhjwj3ik/Oo1GqPBof0F9c5AWDsqCIAgqTDgoC4IgqDDhoCwIgqDChIOyIAiCChMOyoIgCCpMOCgLgmBwsdnlRwkj3rHSI6hPOCgLgiCoMOGgLAiCoMKEg7IgCIIKEw7KgiAIKkw4KAuCIKgw4aAsCIKgwoSDsiAIhjyaVX4MCmblxxAnHJQFQRBUmHBQFgRBUGHCuiYIgqDChHVNEARBhQnrmiAIggoT1jVBEAx5+mRd06ITtCFPbP8XBEEQ5AnrmiAIggoT2/8FQRBUmNj+LwiCoMLE9n9BEAQVJrb/C4IgqDCx/V8QBEOHEodfGsaWj50mtv8LgiCoMLH9XxAEQYUJB2VBEAQVJhyUBUEQVJhwUBYEQVBhwkFZEMxtDMNt7DS7/AjqEw7KgiAIKkw4KAuCIKgw4aAsCIKgwoSDsiAIggoTDsqCIAgqTDgoC4IgqDDhoCwIgiGPZnd4oD+M9QzhoCwIgqDChIOyIAiCChMOyoIgCCpMOCgLgiCoMOGgLAiCoMKEg7IgCIY8fXJQNtuKj7mMcFAWBEFQYcJBWRAEQYUJB2VBEAQVJhyUBUEQVJhwUBYEQVBhwkFZEARBhQkHZUEQDHliL9e+Ew7KgiAIKkw4KAuCIKgw4aAsCIKgwoSDsiAIggoTDsqCIAgqTKtCviUTSjO7OalvVjGzutY1U3h98pV2/rPp56K4Lj9P2fmqpel0+X1J0+nyBytNp8sfrDQ9z89sY/mzS87XS/On81sv/79trPNN57Wept11e640/oSSujhm1tIB/AF4ALgd+Gfm/K/wCVZwD5XXAffippO7t1jGHa2cr1qaTpc/t9Q5rnPolj+31Lnd11l0tKyuMbMvl5wPE8ogCIIhRqvWNUEQBMEwYqgK+VNbPF+1NJ0uvy9pOl3+YKXpdPmDlabT5fclTafLH6w09fLqhZKOJwiCIKggQ7UnHwRBELSBEPJBEAQVJoR8EARBhQkhHwRBUGFCyAdBEFSY/w+mS8z4rjf/UwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINDING BLEU SCORE OF URDU TO ENGLISH:"
      ],
      "metadata": {
        "id": "EZEjvZoQ3AWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR LSTM:"
      ],
      "metadata": {
        "id": "xmy9a5rf3s56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# two references for one document\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "references = [targ_sen_ur.split()]\n",
        "canidates = [lstm_ur_output.split()]"
      ],
      "metadata": {
        "id": "1uCrfVb2Bawn"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = corpus_bleu(references, canidates)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77_xQpYXLbCz",
        "outputId": "aa1bc21f-b84f-4ce0-f2fc-0dc3e9e082ef"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0518351895246305e-231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.8/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOR GRU:"
      ],
      "metadata": {
        "id": "73VWqeEP3UzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "references = [targ_sen_ur.split()]\n",
        "canidates = [gru_ur_output.split()]"
      ],
      "metadata": {
        "id": "EQMeKiYPNLgf"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = corpus_bleu(references, canidates)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEhwdA6t3Nmg",
        "outputId": "95386864-9fb4-441b-90ee-6b99fc57de68"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.844844403089351e-232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IUk0CqN3gnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}