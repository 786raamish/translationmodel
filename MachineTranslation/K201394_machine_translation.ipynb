{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Onf8XEcJYBCm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jYlZAgk4Y5oA"
   },
   "outputs": [],
   "source": [
    "lines1=pd.read_table('/content/Quran-EN.txt', names=['eng'])\n",
    "lines2=pd.read_table('/content/Quran-UR.txt', names=['urdu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZZOc8_f13515"
   },
   "outputs": [],
   "source": [
    "lines1['c'] = np.arange(len(lines1))\n",
    "lines2['c'] = np.arange(len(lines2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wFHVdqpIaZmm"
   },
   "outputs": [],
   "source": [
    "lines = pd.merge(lines1, lines2, on='c', how='outer', suffixes=('en', 'urd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ORGO_-msMDPC"
   },
   "outputs": [],
   "source": [
    "del lines['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RXHUkU4PEUJE",
    "outputId": "25350138-9ea1-4293-98ff-e264566013e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a288abf6-4cc6-4975-99d6-a242eae54e64\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All praise be to Allah alone , the Sustainer o...</td>\n",
       "      <td>سب تعریفیں اللہ ہی کے لئے ہیں جو تمام جہانوں ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most Compassionate , Ever - Merciful .</td>\n",
       "      <td>نہایت مہربان بہت رحم فرمانے والا ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Master of the Day of Judgment .</td>\n",
       "      <td>روزِ جزا کا مالک ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( O Allah ! ) You alone do we worship and to Y...</td>\n",
       "      <td>اے اللہ ! ہم تیری ہی عبادت کرتے ہیں اور ہم تجھ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Show us the straight path .</td>\n",
       "      <td>ہمیں سیدھا راستہ دکھا ۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a288abf6-4cc6-4975-99d6-a242eae54e64')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a288abf6-4cc6-4975-99d6-a242eae54e64 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a288abf6-4cc6-4975-99d6-a242eae54e64');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "0  All praise be to Allah alone , the Sustainer o...   \n",
       "1             Most Compassionate , Ever - Merciful .   \n",
       "2                    Master of the Day of Judgment .   \n",
       "3  ( O Allah ! ) You alone do we worship and to Y...   \n",
       "4                        Show us the straight path .   \n",
       "\n",
       "                                                urdu  \n",
       "0  سب تعریفیں اللہ ہی کے لئے ہیں جو تمام جہانوں ک...  \n",
       "1              نہایت مہربان بہت رحم فرمانے والا ہے ۔  \n",
       "2                              روزِ جزا کا مالک ہے ۔  \n",
       "3  اے اللہ ! ہم تیری ہی عبادت کرتے ہیں اور ہم تجھ...  \n",
       "4                            ہمیں سیدھا راستہ دکھا ۔  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "gDONYtOeab4c",
    "outputId": "41ef4763-99d1-4df8-a809-51c799a642ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-db4b6ae1-f477-46cf-ba06-68d8fd304660\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>these are the revelations of allah which we re...</td>\n",
       "      <td>START_ یہ اللہ کی آیتیں ہیں جنہیں ہم آپ پر حق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>and he is the one who provides me with food an...</td>\n",
       "      <td>START_ اور وہی ہے جو مجھے کھلاتا اور پلاتا ہے ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>that is how we pay back those who are committe...</td>\n",
       "      <td>START_ بے شک ہم نیکو کاروں کو اسی طرح صِلہ دیا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>and when souls will be united with their bodies</td>\n",
       "      <td>START_ اور جب روحیں بدنوں سے ملا دی جائیں گی ۔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>and he is the one who has created firm mountai...</td>\n",
       "      <td>START_ اور اسی نے زمین میں مختلف مادوں کو باہم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>so be steadfast verily the promise of allah is...</td>\n",
       "      <td>START_ پس آپ صبر کیجئے ، بیشک اﷲ کا وعدہ سچا ہ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>have you seen him who denies din religion</td>\n",
       "      <td>START_ کیا آپ نے اس شخص کو دیکھا جو دین کو جھٹ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>and a man came running from the far end of the...</td>\n",
       "      <td>START_ اور شہر کے آخری کنارے سے ایک شخص دوڑتا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>receiving those blessings in ecstatic delight ...</td>\n",
       "      <td>START_ اُن نعمتوں کو کیف و سرور سے لیتے ہوں گے...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>do you build a monument on every high point me...</td>\n",
       "      <td>START_ کیا تم ہر اونچی جگہ پر ایک یادگار تعمیر...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db4b6ae1-f477-46cf-ba06-68d8fd304660')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-db4b6ae1-f477-46cf-ba06-68d8fd304660 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-db4b6ae1-f477-46cf-ba06-68d8fd304660');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                    eng  \\\n",
       "536   these are the revelations of allah which we re...   \n",
       "3162  and he is the one who provides me with food an...   \n",
       "4075  that is how we pay back those who are committe...   \n",
       "5983    and when souls will be united with their bodies   \n",
       "2053  and he is the one who has created firm mountai...   \n",
       "3620  so be steadfast verily the promise of allah is...   \n",
       "6375          have you seen him who denies din religion   \n",
       "3423  and a man came running from the far end of the...   \n",
       "4855  receiving those blessings in ecstatic delight ...   \n",
       "3211  do you build a monument on every high point me...   \n",
       "\n",
       "                                                   urdu  \n",
       "536   START_ یہ اللہ کی آیتیں ہیں جنہیں ہم آپ پر حق ...  \n",
       "3162  START_ اور وہی ہے جو مجھے کھلاتا اور پلاتا ہے ...  \n",
       "4075  START_ بے شک ہم نیکو کاروں کو اسی طرح صِلہ دیا...  \n",
       "5983  START_ اور جب روحیں بدنوں سے ملا دی جائیں گی ۔...  \n",
       "2053  START_ اور اسی نے زمین میں مختلف مادوں کو باہم...  \n",
       "3620  START_ پس آپ صبر کیجئے ، بیشک اﷲ کا وعدہ سچا ہ...  \n",
       "6375  START_ کیا آپ نے اس شخص کو دیکھا جو دین کو جھٹ...  \n",
       "3423  START_ اور شہر کے آخری کنارے سے ایک شخص دوڑتا ...  \n",
       "4855  START_ اُن نعمتوں کو کیف و سرور سے لیتے ہوں گے...  \n",
       "3211  START_ کیا تم ہر اونچی جگہ پر ایک یادگار تعمیر...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.urdu=lines.urdu.apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.urdu=lines.urdu.apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.urdu=lines.urdu.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.urdu=lines.urdu.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.urdu=lines.urdu.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "# Add start and end tokens to target sequences\n",
    "lines.urdu = lines.urdu.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_hJtEj8bab-d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Vocabulary of English\n",
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "# Vocabulary of Urdu \n",
    "all_urdu_words=set()\n",
    "for urdu in lines.urdu:\n",
    "    for word in urdu.split():\n",
    "        if word not in all_urdu_words:\n",
    "            all_urdu_words.add(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqWDH72lacBM",
    "outputId": "ce20d603-cbf7-410d-af68-c9e49ae1ad34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Source Length: 200\n",
      "Max Target Lenght: 234\n"
     ]
    }
   ],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_src = np.max(lenght_list)\n",
    "print('Max Source Length:',max_length_src)\n",
    "\n",
    "# Max Length of target sequence\n",
    "lenght_list=[]\n",
    "for l in lines.urdu:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "max_length_tar = np.max(lenght_list)\n",
    "print('Max Target Lenght:',max_length_tar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACVsAs6mb8JR",
    "outputId": "2b68a29a-2a3c-40ac-be83-9f784839ecbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8117, 8136)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_urdu_words))\n",
    "num_encoder_tokens = len(all_eng_words)+1\n",
    "num_decoder_tokens = len(all_urdu_words)+1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QOZtqsCcIzR",
    "outputId": "4fcb2e6a-73fd-477a-9e21-55d44d350341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8137"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "NcswIoyNcMJI",
    "outputId": "8a937943-42ca-4a10-a3cb-856e49bb9c56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b29034ca-83e1-4abd-91e7-06b48f042de6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>well can you save him for whom the command of ...</td>\n",
       "      <td>START_ بھلا جس شخص پر عذاب کا حکم ثابت ہو چکا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>say just answer if allah prolongs the night ov...</td>\n",
       "      <td>START_ فرما دیجئے ذرا اتنا بتاؤ کہ اگر اللہ تم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>say he allah has sent down this quran who know...</td>\n",
       "      <td>START_ فرما دیجئے اِس قرآن کو اُس اللہ نے نازل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>it will be said yes this is the same day of ju...</td>\n",
       "      <td>START_ کہا جائے گا ہاں یہ وہی فیصلہ کا دن ہے ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>and each one of them has to appear before his ...</td>\n",
       "      <td>START_ اور ان میں سے ہر ایک قیامت کے دن اس کے ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>say that day of rising is the tremendous piece...</td>\n",
       "      <td>START_ فرما دیجئے وہ قیامت بہت بڑی خبر ہے ۔ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>surely you and the idols you worship besides a...</td>\n",
       "      <td>START_ بیشک تم اور وہ بت جن کی تم اﷲ کے سوا پر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>the day when they will see the angels there wi...</td>\n",
       "      <td>START_ جس دن وہ فرشتوں کو دیکھیں گے تو اس دن م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>and we shall certainly try you till we bring t...</td>\n",
       "      <td>START_ اور ہم ضرور تمہاری آزمائش کریں گے یہاں ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>the rebellious and arrogant chiefs and the cap...</td>\n",
       "      <td>START_ ان کی قوم کے سرداروں اور رئیسوں نے جو س...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b29034ca-83e1-4abd-91e7-06b48f042de6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b29034ca-83e1-4abd-91e7-06b48f042de6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b29034ca-83e1-4abd-91e7-06b48f042de6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                    eng  \\\n",
       "4233  well can you save him for whom the command of ...   \n",
       "3474  say just answer if allah prolongs the night ov...   \n",
       "3012  say he allah has sent down this quran who know...   \n",
       "3965  it will be said yes this is the same day of ju...   \n",
       "2482  and each one of them has to appear before his ...   \n",
       "4193  say that day of rising is the tremendous piece...   \n",
       "2718  surely you and the idols you worship besides a...   \n",
       "3028  the day when they will see the angels there wi...   \n",
       "4740  and we shall certainly try you till we bring t...   \n",
       "1179  the rebellious and arrogant chiefs and the cap...   \n",
       "\n",
       "                                                   urdu  \n",
       "4233  START_ بھلا جس شخص پر عذاب کا حکم ثابت ہو چکا ...  \n",
       "3474  START_ فرما دیجئے ذرا اتنا بتاؤ کہ اگر اللہ تم...  \n",
       "3012  START_ فرما دیجئے اِس قرآن کو اُس اللہ نے نازل...  \n",
       "3965  START_ کہا جائے گا ہاں یہ وہی فیصلہ کا دن ہے ج...  \n",
       "2482  START_ اور ان میں سے ہر ایک قیامت کے دن اس کے ...  \n",
       "4193   START_ فرما دیجئے وہ قیامت بہت بڑی خبر ہے ۔ _END  \n",
       "2718  START_ بیشک تم اور وہ بت جن کی تم اﷲ کے سوا پر...  \n",
       "3028  START_ جس دن وہ فرشتوں کو دیکھیں گے تو اس دن م...  \n",
       "4740  START_ اور ہم ضرور تمہاری آزمائش کریں گے یہاں ...  \n",
       "1179  START_ ان کی قوم کے سرداروں اور رئیسوں نے جو س...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I3jdPSgy5Su"
   },
   "source": [
    "**Creating training and test dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5ngV0e8cMGR",
    "outputId": "9a2b4ada-892d-4609-de3a-212569189195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5772,), (642,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng, lines.urdu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DiFwOxV9cMDg"
   },
   "outputs": [],
   "source": [
    "#Save the train and test dataframes for reproducing the results later, as they are shuffled.\n",
    "\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7xcAcM-vcL4o"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 64):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyaJMwiCdMip",
    "outputId": "3f75614d-c4d7-4aec-e5e2-76414ead0ed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "print(train_samples//batch_size)\n",
    "print(val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9-y-7GCKc8Aq"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jcHySeMYCOcG"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jSlbY-2UCRj1"
   },
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4hRLXQCXdH1I"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQHwZGgudTLY",
    "outputId": "41f8e01f-ec21-4469-a7e2-feef2c43e74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 53s 404ms/step - loss: 1.0061 - acc: 0.0639 - val_loss: 0.9559 - val_acc: 0.0858\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 34s 372ms/step - loss: 0.8858 - acc: 0.1187 - val_loss: 0.8800 - val_acc: 0.1431\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 37s 413ms/step - loss: 0.8215 - acc: 0.1560 - val_loss: 0.8322 - val_acc: 0.1723\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 36s 403ms/step - loss: 0.7771 - acc: 0.1891 - val_loss: 0.7997 - val_acc: 0.1978\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 37s 407ms/step - loss: 0.7424 - acc: 0.2116 - val_loss: 0.7747 - val_acc: 0.2120\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 37s 408ms/step - loss: 0.7141 - acc: 0.2280 - val_loss: 0.7543 - val_acc: 0.2255\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 36s 406ms/step - loss: 0.6903 - acc: 0.2427 - val_loss: 0.7375 - val_acc: 0.2396\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 37s 412ms/step - loss: 0.6680 - acc: 0.2584 - val_loss: 0.7236 - val_acc: 0.2539\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 36s 406ms/step - loss: 0.6494 - acc: 0.2721 - val_loss: 0.7118 - val_acc: 0.2596\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 35s 388ms/step - loss: 0.6300 - acc: 0.2855 - val_loss: 0.7002 - val_acc: 0.2707\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 36s 407ms/step - loss: 0.6118 - acc: 0.2983 - val_loss: 0.6896 - val_acc: 0.2794\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 36s 406ms/step - loss: 0.5966 - acc: 0.3099 - val_loss: 0.6830 - val_acc: 0.2841\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 37s 412ms/step - loss: 0.5810 - acc: 0.3215 - val_loss: 0.6747 - val_acc: 0.2926\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 36s 405ms/step - loss: 0.5673 - acc: 0.3322 - val_loss: 0.6680 - val_acc: 0.2996\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 35s 390ms/step - loss: 0.5537 - acc: 0.3418 - val_loss: 0.6633 - val_acc: 0.3038\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 36s 403ms/step - loss: 0.5408 - acc: 0.3522 - val_loss: 0.6573 - val_acc: 0.3077\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 37s 406ms/step - loss: 0.5274 - acc: 0.3617 - val_loss: 0.6555 - val_acc: 0.3111\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 38s 418ms/step - loss: 0.5148 - acc: 0.3714 - val_loss: 0.6537 - val_acc: 0.3123\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 37s 406ms/step - loss: 0.5039 - acc: 0.3800 - val_loss: 0.6502 - val_acc: 0.3160\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 37s 409ms/step - loss: 0.4927 - acc: 0.3892 - val_loss: 0.6484 - val_acc: 0.3194\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 34s 377ms/step - loss: 0.4822 - acc: 0.3982 - val_loss: 0.6464 - val_acc: 0.3217\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 34s 377ms/step - loss: 0.4717 - acc: 0.4068 - val_loss: 0.6458 - val_acc: 0.3226\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 37s 411ms/step - loss: 0.4614 - acc: 0.4153 - val_loss: 0.6449 - val_acc: 0.3237\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 36s 398ms/step - loss: 0.4506 - acc: 0.4243 - val_loss: 0.6472 - val_acc: 0.3227\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 34s 377ms/step - loss: 0.4407 - acc: 0.4329 - val_loss: 0.6470 - val_acc: 0.3249\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.4319 - acc: 0.4410 - val_loss: 0.6483 - val_acc: 0.3247\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 36s 397ms/step - loss: 0.4217 - acc: 0.4495 - val_loss: 0.6483 - val_acc: 0.3240\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 37s 407ms/step - loss: 0.4123 - acc: 0.4582 - val_loss: 0.6493 - val_acc: 0.3244\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 34s 378ms/step - loss: 0.4041 - acc: 0.4670 - val_loss: 0.6499 - val_acc: 0.3243\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 34s 378ms/step - loss: 0.3941 - acc: 0.4764 - val_loss: 0.6514 - val_acc: 0.3267\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 34s 377ms/step - loss: 0.3865 - acc: 0.4853 - val_loss: 0.6530 - val_acc: 0.3242\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.3775 - acc: 0.4934 - val_loss: 0.6537 - val_acc: 0.3253\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.3688 - acc: 0.5035 - val_loss: 0.6562 - val_acc: 0.3238\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 37s 410ms/step - loss: 0.3609 - acc: 0.5123 - val_loss: 0.6595 - val_acc: 0.3186\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.3529 - acc: 0.5211 - val_loss: 0.6648 - val_acc: 0.3194\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 35s 391ms/step - loss: 0.3431 - acc: 0.5314 - val_loss: 0.6648 - val_acc: 0.3220\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 37s 416ms/step - loss: 0.3373 - acc: 0.5398 - val_loss: 0.6668 - val_acc: 0.3211\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 37s 407ms/step - loss: 0.3295 - acc: 0.5487 - val_loss: 0.6691 - val_acc: 0.3210\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 35s 384ms/step - loss: 0.3219 - acc: 0.5588 - val_loss: 0.6732 - val_acc: 0.3213\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 35s 386ms/step - loss: 0.3145 - acc: 0.5677 - val_loss: 0.6754 - val_acc: 0.3225\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 35s 385ms/step - loss: 0.3073 - acc: 0.5769 - val_loss: 0.6798 - val_acc: 0.3192\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 35s 387ms/step - loss: 0.3006 - acc: 0.5855 - val_loss: 0.6813 - val_acc: 0.3202\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.2933 - acc: 0.5951 - val_loss: 0.6861 - val_acc: 0.3215\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 37s 409ms/step - loss: 0.2866 - acc: 0.6043 - val_loss: 0.6912 - val_acc: 0.3175\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 37s 409ms/step - loss: 0.2801 - acc: 0.6122 - val_loss: 0.6930 - val_acc: 0.3170\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 37s 410ms/step - loss: 0.2736 - acc: 0.6209 - val_loss: 0.6956 - val_acc: 0.3168\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 35s 387ms/step - loss: 0.2675 - acc: 0.6291 - val_loss: 0.6983 - val_acc: 0.3152\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 36s 397ms/step - loss: 0.2619 - acc: 0.6370 - val_loss: 0.7023 - val_acc: 0.3142\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 35s 386ms/step - loss: 0.2555 - acc: 0.6458 - val_loss: 0.7056 - val_acc: 0.3117\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 37s 410ms/step - loss: 0.2500 - acc: 0.6546 - val_loss: 0.7095 - val_acc: 0.3142\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 37s 408ms/step - loss: 0.2445 - acc: 0.6624 - val_loss: 0.7148 - val_acc: 0.3115\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 35s 386ms/step - loss: 0.2386 - acc: 0.6703 - val_loss: 0.7173 - val_acc: 0.3090\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 35s 387ms/step - loss: 0.2323 - acc: 0.6790 - val_loss: 0.7255 - val_acc: 0.3094\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 34s 383ms/step - loss: 0.2273 - acc: 0.6866 - val_loss: 0.7267 - val_acc: 0.3097\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 36s 404ms/step - loss: 0.2225 - acc: 0.6934 - val_loss: 0.7293 - val_acc: 0.3089\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 35s 386ms/step - loss: 0.2176 - acc: 0.7004 - val_loss: 0.7357 - val_acc: 0.3053\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 35s 387ms/step - loss: 0.2121 - acc: 0.7082 - val_loss: 0.7410 - val_acc: 0.3069\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 35s 394ms/step - loss: 0.2067 - acc: 0.7159 - val_loss: 0.7459 - val_acc: 0.3059\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 37s 410ms/step - loss: 0.2024 - acc: 0.7226 - val_loss: 0.7484 - val_acc: 0.3059\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 37s 409ms/step - loss: 0.1986 - acc: 0.7295 - val_loss: 0.7538 - val_acc: 0.3041\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 37s 409ms/step - loss: 0.1931 - acc: 0.7355 - val_loss: 0.7572 - val_acc: 0.3031\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 35s 389ms/step - loss: 0.1889 - acc: 0.7420 - val_loss: 0.7595 - val_acc: 0.3074\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 37s 413ms/step - loss: 0.1844 - acc: 0.7485 - val_loss: 0.7683 - val_acc: 0.3019\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 37s 410ms/step - loss: 0.1804 - acc: 0.7548 - val_loss: 0.7714 - val_acc: 0.3011\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 35s 390ms/step - loss: 0.1758 - acc: 0.7623 - val_loss: 0.7747 - val_acc: 0.3011\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 37s 416ms/step - loss: 0.1717 - acc: 0.7676 - val_loss: 0.7798 - val_acc: 0.3011\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 35s 391ms/step - loss: 0.1676 - acc: 0.7730 - val_loss: 0.7833 - val_acc: 0.3021\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 35s 394ms/step - loss: 0.1640 - acc: 0.7797 - val_loss: 0.7870 - val_acc: 0.2996\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 37s 412ms/step - loss: 0.1603 - acc: 0.7844 - val_loss: 0.7935 - val_acc: 0.2969\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 35s 392ms/step - loss: 0.1561 - acc: 0.7907 - val_loss: 0.7982 - val_acc: 0.2987\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 35s 392ms/step - loss: 0.1526 - acc: 0.7955 - val_loss: 0.8038 - val_acc: 0.2981\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 35s 391ms/step - loss: 0.1487 - acc: 0.8020 - val_loss: 0.8094 - val_acc: 0.2965\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 36s 396ms/step - loss: 0.1454 - acc: 0.8067 - val_loss: 0.8102 - val_acc: 0.2993\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 35s 393ms/step - loss: 0.1415 - acc: 0.8116 - val_loss: 0.8174 - val_acc: 0.2977\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 35s 393ms/step - loss: 0.1386 - acc: 0.8162 - val_loss: 0.8192 - val_acc: 0.2976\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 35s 394ms/step - loss: 0.1353 - acc: 0.8224 - val_loss: 0.8272 - val_acc: 0.2980\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 35s 393ms/step - loss: 0.1325 - acc: 0.8262 - val_loss: 0.8271 - val_acc: 0.2960\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.1294 - acc: 0.8310 - val_loss: 0.8320 - val_acc: 0.2963\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 36s 397ms/step - loss: 0.1258 - acc: 0.8363 - val_loss: 0.8383 - val_acc: 0.2950\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 35s 392ms/step - loss: 0.1230 - acc: 0.8396 - val_loss: 0.8452 - val_acc: 0.2945\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 37s 415ms/step - loss: 0.1198 - acc: 0.8449 - val_loss: 0.8474 - val_acc: 0.2925\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 35s 392ms/step - loss: 0.1169 - acc: 0.8485 - val_loss: 0.8527 - val_acc: 0.2934\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 37s 414ms/step - loss: 0.1142 - acc: 0.8525 - val_loss: 0.8583 - val_acc: 0.2948\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 36s 398ms/step - loss: 0.1120 - acc: 0.8563 - val_loss: 0.8643 - val_acc: 0.2935\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 35s 395ms/step - loss: 0.1088 - acc: 0.8610 - val_loss: 0.8728 - val_acc: 0.2890\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 36s 397ms/step - loss: 0.1055 - acc: 0.8666 - val_loss: 0.8724 - val_acc: 0.2886\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 35s 394ms/step - loss: 0.1036 - acc: 0.8687 - val_loss: 0.8781 - val_acc: 0.2905\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 36s 395ms/step - loss: 0.1010 - acc: 0.8728 - val_loss: 0.8844 - val_acc: 0.2893\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.0987 - acc: 0.8770 - val_loss: 0.8896 - val_acc: 0.2894\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 36s 399ms/step - loss: 0.0961 - acc: 0.8803 - val_loss: 0.8964 - val_acc: 0.2885\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 36s 400ms/step - loss: 0.0941 - acc: 0.8834 - val_loss: 0.8989 - val_acc: 0.2884\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 35s 389ms/step - loss: 0.0924 - acc: 0.8866 - val_loss: 0.9059 - val_acc: 0.2865\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 36s 387ms/step - loss: 0.0892 - acc: 0.8904 - val_loss: 0.9095 - val_acc: 0.2869\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.0871 - acc: 0.8936 - val_loss: 0.9142 - val_acc: 0.2888\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 36s 400ms/step - loss: 0.0853 - acc: 0.8969 - val_loss: 0.9194 - val_acc: 0.2850\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 36s 400ms/step - loss: 0.0829 - acc: 0.9001 - val_loss: 0.9249 - val_acc: 0.2859\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.0807 - acc: 0.9032 - val_loss: 0.9268 - val_acc: 0.2839\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 38s 420ms/step - loss: 0.0786 - acc: 0.9069 - val_loss: 0.9330 - val_acc: 0.2828\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.0767 - acc: 0.9095 - val_loss: 0.9373 - val_acc: 0.2844\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 36s 401ms/step - loss: 0.0752 - acc: 0.9113 - val_loss: 0.9431 - val_acc: 0.2843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21d0cb97f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bGoxmP2Oig5T"
   },
   "outputs": [],
   "source": [
    "#Always remember to save the weights\n",
    "\n",
    "model.save_weights('etu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "149l-Dqmiqea"
   },
   "outputs": [],
   "source": [
    "#Load the weights, if you close the application\n",
    "\n",
    "model.load_weights('etu_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "d7g55h0Yiqbj"
   },
   "outputs": [],
   "source": [
    "#Inference Setup\n",
    "\n",
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "d4939gUQiqYz"
   },
   "outputs": [],
   "source": [
    "#Decode sample sequeces\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_iTpwhGjEhK"
   },
   "source": [
    "**Evaluation on Train Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BoiZ8xxGiqNL"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kK9d0Uv4jJSK",
    "outputId": "7ba164c8-38d3-426e-87ba-11dd2890a2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Input English sentence: he gets upset and worried when some hardship or financial loss afflicts him\n",
      "Actual Urdu Translation:  جب اسے مصیبت یا مالی نقصان پہنچے تو گھبرا جاتا ہے ۔ \n",
      "Predicted Urdu Translation:  جب اسے مصیبت یا مالی نقصان پہنچے تو گھبرا جاتا ہے ۔\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YG4XqkEajVNP",
    "outputId": "bfb9e973-5831-4db1-9b90-cd0750fc8e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Input English sentence: and all their evil works will be exposed which they used to do and that torment will beset them which they used to make fun of\n",
      "Actual Urdu Translation:  اور اُن کے لئے وہ سب برائیاں ظاہر ہو جائیں گی جو وہ انجام دیتے تھے اور وہ عذاب انہیں گھیر لے گا جِس کا وہ مذاق اڑایا کرتے تھے ۔ \n",
      "Predicted Urdu Translation:  اور اُن کے لئے وہ سب برائیاں ظاہر ہو وہ جو ہمیشہ رہے\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqWe40StjVKB",
    "outputId": "007d3550-cfe2-4181-d338-4e378f9753b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input English sentence: o believers when you whisper among yourselves whisper not sin injustice revolt and disobedience to the holy prophet blessings and peace be upon him but whisper piety and godwariness and keep fearing allah towards whom you all will be gathered\n",
      "Actual Urdu Translation:  اے ایمان والو جب تم آپس میں سرگوشی کرو تو گناہ اور ظلم و سرکشی اور نافرمانئ رسالت مآب صلی اللہ علیہ وآلہ وسلم کی سرگوشی نہ کیا کرو اور نیکی اور پرہیزگاری کی بات ایک دوسرے کے کان میں کہہ لیا کرو ، اور اللہ سے ڈرتے رہو جس کی طرف تم سب جمع کئے جاؤ گے ۔ \n",
      "Predicted Urdu Translation:  اے ایمان والو جب تم آپس میں سرگوشی کرو تو گناہ\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QnsdBKjjmpH"
   },
   "source": [
    "**Evaluation on Validation Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ByfeI2RajVHB"
   },
   "outputs": [],
   "source": [
    "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maXNVej9jVBp",
    "outputId": "58ae7b81-1299-4c5e-cd13-bf88d4334742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Input English sentence: and that he alone is the lord of sirius a star that was worshipped in the days of ignorance\n",
      "Actual Urdu Translation:  اور یہ کہ وہی شِعرٰی ستارے کا رب ہے جس کی دورِ جاہلیت میں پوجا کی جاتی تھی ۔ \n",
      "Predicted Urdu Translation:  اور یہ کہ اسی نے ہر نفس کے ساتھ آرام کر لیا او\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYRN0nMhjvD3",
    "outputId": "a9b95f4a-c2e2-4138-8e89-6764e4a70909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input English sentence: indeed those who believe and keep doing pious actions it is they who are the best of the creation\n",
      "Actual Urdu Translation:  بیشک جو لوگ ایمان لائے اور نیک عمل کرتے رہے وہی لوگ ساری مخلوق سے بہتر ہیں ۔ \n",
      "Predicted Urdu Translation:  بیشک جو لوگ ایمان لائے اور نیک عمل کرتے رہے ان ل\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFTGMBMxjyfV",
    "outputId": "dcad99f9-1d67-4663-b171-644b4acbb155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Input English sentence: so which of your lords blessings will you both deny\n",
      "Actual Urdu Translation:  پس تم دونوں اپنے رب کی کن کن نعمتوں کو جھٹلاؤ گے ۔ \n",
      "Predicted Urdu Translation:  پس تم دونوں اپنے رب کی کن کن نعمتوں کو جھٹلاؤ \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Urdu Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Urdu Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Bb_XlzxOMMVY"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzccltzcNIuu",
    "outputId": "4f6ea6b4-a1ec-43a4-a061-43ede2d6f217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['پس', 'تم', 'دونوں', 'اپنے', 'رب', 'کی', 'کن', 'کن', 'نعمتوں', 'کو', 'جھٹلاؤ', 'گے', '۔']]\n"
     ]
    }
   ],
   "source": [
    "reference = [\n",
    "    y_test[k:k+1].values[0][6:-4].split()\n",
    "]\n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmcRvYq1MN8X",
    "outputId": "737f3dff-2866-4172-e260-72ba02974dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 0.8337529180751805\n"
     ]
    }
   ],
   "source": [
    "candidate = decoded_sentence[:-4].split()\n",
    "print('BLEU score -> {}'.format(sentence_bleu(reference, candidate)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Machine Translation  Word-level model (English to Urdu).ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
